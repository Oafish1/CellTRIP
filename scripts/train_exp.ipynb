{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import celltrip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/utility/processing.py:97: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = None\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Construct dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = celltrip.policy.PPO(6, [m.shape[1] for m in modalities], 3, device='cuda')\n",
    "env = celltrip.environment.EnvironmentBase(*[torch.from_numpy(m).to('cuda') for m in modalities], dim=3, device='cuda')\n",
    "\n",
    "# from collections import defaultdict\n",
    "# memory = defaultdict(lambda: [])\n",
    "# for _ in range(1000):\n",
    "#     state = env.get_state(include_modalities=True).to('cuda')\n",
    "#     state_split, action, action_log, state_val = policy.act_macro(state)\n",
    "#     rewards, finished = env.step(action.to('cpu'))\n",
    "#     memory['states'].append([s.detach() for s in state_split])\n",
    "#     memory['actions'].append(action.detach())\n",
    "#     memory['action_logs'].append(action_log.detach())\n",
    "#     memory['state_vals'].append(state_val.detach())\n",
    "#     memory['rewards'].append(rewards.detach())\n",
    "\n",
    "# Append\n",
    "# for k, v in memory.items():\n",
    "#     if k == 'states': memory[k] = [torch.concat([s[i] for s in v], dim=0) for i in range(2)]\n",
    "#     else: memory[k] = torch.concat(v, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(80):\n",
    "    loss = policy.backward(**memory)[0]\n",
    "    loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    state = env.get_state(include_modalities=True)\n",
    "    state_split, action, action_log, state_val = policy.act_macro(state)\n",
    "    rewards, finished = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = celltrip.policy.PPO(6, [m.shape[1] for m in modalities], 3, device='cuda')\n",
    "env = celltrip.environment.EnvironmentBase(*[torch.from_numpy(m).to('cpu') for m in modalities], dim=3, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    state = env.get_state(include_modalities=True).to('cuda')\n",
    "    state_split, action, action_log, state_val = policy.act_macro(state)\n",
    "    rewards, finished = env.step(action.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 23:06:34,339\tINFO client_builder.py:244 -- Passing the following kwargs to ray.init() on the server: log_to_driver\n",
      "SIGTERM handler is not set because current thread is not the main thread.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000d2d8ef1d749309f262b5f4690ff08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.16</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.43.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://100.64.246.20:8265\" target=\"_blank\">http://100.64.246.20:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='100.64.246.20:8265', python_version='3.10.16', ray_version='2.43.0', ray_commit='ecdcdc6a6e63dc4bcd6ea16aae256ce4d32a7e2c', _num_clients=3, _context_to_restore=<ray.util.client._ClientContext object at 0x7fe53b16a410>, protocol_version=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "import ray.util.collective as col\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "class Actor:\n",
    "    def __init__(self, world_size, rank):\n",
    "        # Environment\n",
    "        self.env = celltrip.environment.EnvironmentBase(*[torch.from_numpy(m) for m in modalities], dim=3)\n",
    "\n",
    "        # Rewards\n",
    "        self.rewards_buffer = []\n",
    "        \n",
    "        # Group\n",
    "        col.init_collective_group(world_size, rank, 'nccl')\n",
    "        self.actions = torch.empty([modalities[0].shape[0], 3], device='cuda')\n",
    "\n",
    "        # Main loop\n",
    "        self.loop()\n",
    "\n",
    "    def observe(self):\n",
    "        obs = self.env.get_state(include_modalities=True)\n",
    "        col.send(obs.to('cuda'), 0)\n",
    "\n",
    "    def act(self):\n",
    "        col.recv(self.actions, 0)\n",
    "        rewards, finished = self.env.step(self.actions.to('cpu'))\n",
    "        # col.send(rewards, 0)\n",
    "        # col.send(finished, 0)\n",
    "\n",
    "    def loop(self):\n",
    "        while True:\n",
    "            self.observe()\n",
    "            self.act()\n",
    "\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "class Learner:\n",
    "    def __init__(self, world_size):\n",
    "        self.world_size = world_size\n",
    "        self.policy = celltrip.policy.PPO(6, [m.shape[1] for m in modalities], 3, device='cuda')\n",
    "\n",
    "        # Group\n",
    "        col.init_collective_group(world_size, 0, 'nccl')\n",
    "        self.obs = torch.empty([modalities[0].shape[0], 6+sum([m.shape[1] for m in modalities])], device='cuda')\n",
    "\n",
    "    def act(self, rank):\n",
    "        col.recv(self.obs, rank)\n",
    "        actions = self.policy.act_macro(self.obs)[0]\n",
    "        col.send(actions, rank)\n",
    "\n",
    "    def loop(self):\n",
    "        for _ in range(1000):\n",
    "            for i in range(self.world_size-1):\n",
    "                self.act(i+1)\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(\n",
    "    address='ray://100.64.246.20:10001',\n",
    "    runtime_env={\n",
    "        'env_vars': {\n",
    "            # NOTE: Important, NCCL will timeout if network device is non-standard\n",
    "            'NCCL_SOCKET_IFNAME': 'tailscale',\n",
    "            # 'NCCL_DEBUG': 'WARN',\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner.remote(2)\n",
    "actors = [Actor.remote(2, i+1) for i in range(1)]\n",
    "ray.get(learner.loop.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:100.64.246.20': 1.0,\n",
       " 'accelerator_type:G': 1.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'node:100.85.187.118': 1.0,\n",
       " 'CPU': 46.0,\n",
       " 'memory': 155214666958.0,\n",
       " 'accelerator_type:RTX': 1.0,\n",
       " 'VRAM': 57291112448.0,\n",
       " 'GPU': 2.0,\n",
       " 'object_store_memory': 67043780472.0}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.814697265625"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([2000, 500]).nbytes / 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def large(world_size, rank):\n",
    "    pol = celltrip.policy.PPO(6, [256, 3], 3).to('cuda')\n",
    "    t1 = time.perf_counter()\n",
    "    col.init_collective_group(world_size, rank, 'nccl')\n",
    "    col.barrier()\n",
    "    t2 = time.perf_counter()\n",
    "    for k, w in pol.state_dict().items():\n",
    "        col.allreduce(w)\n",
    "        w /= world_size\n",
    "    t3 = time.perf_counter()\n",
    "    col.destroy_collective_group()\n",
    "    t4 = time.perf_counter()\n",
    "    print(f'{t2-t1}, {t3-t2}, {t4-t3}')\n",
    "\n",
    "ray.get([large.remote(2, 0), large.remote(2, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('actor.action_var', tensor([0.3600, 0.3600, 0.3600])),\n",
       "             ('actor.scale_tril',\n",
       "              tensor([[[0.6000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.6000, 0.0000],\n",
       "                       [0.0000, -0.0000, 0.6000]]])),\n",
       "             ('actor.layer_norm.self embedding.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('actor.layer_norm.self embedding.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('actor.layer_norm.node embedding.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('actor.layer_norm.node embedding.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('actor.layer_norm.residual self attention.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('actor.layer_norm.residual self attention.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('actor.feature_embed.0.weight',\n",
       "              tensor([[-0.0462, -0.0084,  0.0356,  ..., -0.0195,  0.0108,  0.0288],\n",
       "                      [-0.0282,  0.0132,  0.0582,  ..., -0.0026, -0.0218, -0.0150],\n",
       "                      [ 0.0446, -0.0369, -0.0271,  ...,  0.0327, -0.0166, -0.0570],\n",
       "                      ...,\n",
       "                      [ 0.0230,  0.0566,  0.0529,  ..., -0.0354, -0.0397, -0.0275],\n",
       "                      [ 0.0235,  0.0413,  0.0117,  ...,  0.0428,  0.0401, -0.0368],\n",
       "                      [-0.0566,  0.0225,  0.0577,  ..., -0.0440, -0.0583, -0.0618]])),\n",
       "             ('actor.feature_embed.0.bias',\n",
       "              tensor([-0.0404, -0.0488, -0.0100,  0.0064, -0.0178,  0.0040,  0.0235,  0.0034,\n",
       "                      -0.0183, -0.0008,  0.0573, -0.0045,  0.0385, -0.0483,  0.0341,  0.0561,\n",
       "                       0.0012, -0.0439,  0.0197, -0.0230,  0.0370, -0.0621, -0.0571, -0.0155,\n",
       "                      -0.0009, -0.0580,  0.0585, -0.0191, -0.0079, -0.0501,  0.0088,  0.0170])),\n",
       "             ('actor.feature_embed.1.weight',\n",
       "              tensor([[ 0.1626, -0.0363,  0.1738],\n",
       "                      [-0.0762,  0.4613,  0.5568],\n",
       "                      [ 0.4965, -0.3529, -0.2466],\n",
       "                      [ 0.1854, -0.4278, -0.5296],\n",
       "                      [ 0.0139,  0.1481, -0.3947],\n",
       "                      [ 0.3142, -0.3452, -0.4592],\n",
       "                      [ 0.3482, -0.5411, -0.3691],\n",
       "                      [ 0.3157, -0.3167, -0.4657],\n",
       "                      [ 0.5686, -0.1876,  0.3768],\n",
       "                      [ 0.4167,  0.4636,  0.2650],\n",
       "                      [ 0.0640,  0.2766, -0.1045],\n",
       "                      [ 0.1394,  0.0990, -0.3248],\n",
       "                      [ 0.1468,  0.3135, -0.2610],\n",
       "                      [-0.0583,  0.5419, -0.1587],\n",
       "                      [-0.3768,  0.1298,  0.5618],\n",
       "                      [ 0.2283, -0.5441,  0.5621],\n",
       "                      [-0.2757,  0.0456,  0.4294],\n",
       "                      [-0.2661, -0.1851,  0.2770],\n",
       "                      [ 0.3724, -0.0056, -0.1071],\n",
       "                      [-0.1488,  0.3901,  0.2893],\n",
       "                      [ 0.2326, -0.4611,  0.1881],\n",
       "                      [-0.4569,  0.1472,  0.0221],\n",
       "                      [-0.5738, -0.4183, -0.1497],\n",
       "                      [-0.0903, -0.5442, -0.4718],\n",
       "                      [ 0.0459, -0.1346, -0.4395],\n",
       "                      [-0.0731,  0.1079,  0.0288],\n",
       "                      [ 0.5223,  0.5293, -0.0085],\n",
       "                      [ 0.2219, -0.5304,  0.0274],\n",
       "                      [ 0.5081, -0.1649,  0.1293],\n",
       "                      [ 0.3774, -0.5312, -0.5416],\n",
       "                      [-0.2106, -0.1025, -0.4015],\n",
       "                      [ 0.3154,  0.4712,  0.4001]])),\n",
       "             ('actor.feature_embed.1.bias',\n",
       "              tensor([ 0.2714, -0.1114, -0.2194,  0.4515, -0.4356, -0.0649,  0.1487, -0.0626,\n",
       "                      -0.1408, -0.1408,  0.3798, -0.1159, -0.5440,  0.2477,  0.0768,  0.3194,\n",
       "                      -0.1432,  0.3281,  0.2673,  0.5148, -0.4672,  0.0690, -0.5689, -0.4192,\n",
       "                      -0.0728, -0.2663,  0.1083, -0.3744, -0.5600, -0.3115,  0.2267,  0.1575])),\n",
       "             ('actor.self_embed.weight',\n",
       "              tensor([[-0.1161, -0.0951, -0.0012,  ..., -0.0597, -0.0387,  0.0026],\n",
       "                      [-0.0401, -0.0998,  0.0659,  ...,  0.0184, -0.1192, -0.0979],\n",
       "                      [ 0.1040,  0.1149, -0.1140,  ..., -0.0451,  0.0318,  0.0302],\n",
       "                      ...,\n",
       "                      [ 0.0102,  0.0385,  0.0804,  ..., -0.0151, -0.0193, -0.0891],\n",
       "                      [-0.1040, -0.0995,  0.0848,  ...,  0.0451, -0.0685, -0.0563],\n",
       "                      [-0.0577, -0.0503,  0.0092,  ..., -0.0589, -0.0506, -0.0900]])),\n",
       "             ('actor.self_embed.bias',\n",
       "              tensor([ 0.0338, -0.1192,  0.1079, -0.0607, -0.0971, -0.0257,  0.0085,  0.0460,\n",
       "                       0.0981, -0.0416,  0.0510, -0.0415,  0.1174, -0.0064, -0.0258, -0.0702,\n",
       "                       0.1127, -0.0510, -0.1074, -0.0781, -0.0489, -0.0655, -0.0741,  0.0719,\n",
       "                       0.0982,  0.0866,  0.0997, -0.0207,  0.0080,  0.1072,  0.0478,  0.0809,\n",
       "                      -0.0537,  0.1174,  0.0133,  0.0219, -0.0958, -0.0132, -0.0407,  0.0580,\n",
       "                       0.0238, -0.1167,  0.0083, -0.0489, -0.0903,  0.0587,  0.0134,  0.0296,\n",
       "                      -0.1068, -0.0267, -0.0644,  0.1027,  0.0891,  0.0768,  0.0338,  0.1066,\n",
       "                       0.1128, -0.0992,  0.0695, -0.0200,  0.0054,  0.0855,  0.0672,  0.0365])),\n",
       "             ('actor.node_embed.weight',\n",
       "              tensor([[-0.0825,  0.0682,  0.0384,  ...,  0.0673,  0.0612, -0.0367],\n",
       "                      [-0.0099,  0.0662,  0.0694,  ...,  0.0801,  0.0257, -0.0683],\n",
       "                      [ 0.0233,  0.0188,  0.0384,  ...,  0.0622,  0.0430,  0.0278],\n",
       "                      ...,\n",
       "                      [-0.0742, -0.0433,  0.0176,  ...,  0.0185,  0.0229, -0.0676],\n",
       "                      [ 0.0372, -0.0135, -0.0734,  ..., -0.0683, -0.0853,  0.0603],\n",
       "                      [ 0.0087, -0.0363,  0.0605,  ..., -0.0649, -0.0268, -0.0638]])),\n",
       "             ('actor.node_embed.bias',\n",
       "              tensor([-0.0463,  0.0787,  0.0232, -0.0225, -0.0805, -0.0652, -0.0242,  0.0203,\n",
       "                      -0.0083, -0.0742, -0.0700,  0.0169,  0.0274, -0.0123,  0.0667,  0.0434,\n",
       "                      -0.0092, -0.0677, -0.0301,  0.0843,  0.0601, -0.0130, -0.0322,  0.0634,\n",
       "                      -0.0323,  0.0277, -0.0857,  0.0761,  0.0298, -0.0474,  0.0365,  0.0099,\n",
       "                      -0.0149,  0.0506,  0.0120, -0.0041,  0.0676, -0.0362, -0.0636,  0.0297,\n",
       "                      -0.0859,  0.0553, -0.0010, -0.0197, -0.0846,  0.0151, -0.0285, -0.0654,\n",
       "                      -0.0139,  0.0421,  0.0197, -0.0862, -0.0861,  0.0162,  0.0531,  0.0287,\n",
       "                       0.0698, -0.0036,  0.0227, -0.0117,  0.0274,  0.0431,  0.0155, -0.0229])),\n",
       "             ('actor.residual_self_attention.attention.in_proj_weight',\n",
       "              tensor([[-0.1257,  0.0942, -0.1267,  ..., -0.0897, -0.1441,  0.0152],\n",
       "                      [ 0.0503, -0.0563,  0.0416,  ...,  0.1273, -0.0307,  0.0963],\n",
       "                      [-0.1331,  0.0623,  0.0204,  ...,  0.0192,  0.0849, -0.1330],\n",
       "                      ...,\n",
       "                      [ 0.0629,  0.1463, -0.0325,  ..., -0.0929, -0.1407, -0.1368],\n",
       "                      [ 0.1240, -0.0504,  0.0651,  ...,  0.1128,  0.1074,  0.0655],\n",
       "                      [-0.1042,  0.0307,  0.0615,  ...,  0.0187, -0.1509, -0.0815]])),\n",
       "             ('actor.residual_self_attention.attention.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('actor.residual_self_attention.attention.out_proj.weight',\n",
       "              tensor([[ 0.1205, -0.0045,  0.1209,  ..., -0.0537, -0.0136,  0.0894],\n",
       "                      [ 0.0304, -0.0777,  0.0676,  ..., -0.0215, -0.0558, -0.0623],\n",
       "                      [ 0.0774,  0.0032, -0.1132,  ...,  0.0040,  0.0350,  0.0924],\n",
       "                      ...,\n",
       "                      [ 0.0942,  0.0950, -0.0209,  ...,  0.0212,  0.0599, -0.0658],\n",
       "                      [ 0.0799, -0.1089,  0.0081,  ..., -0.0606, -0.0765,  0.0923],\n",
       "                      [-0.1232,  0.0073, -0.0713,  ..., -0.0746, -0.1142, -0.0293]])),\n",
       "             ('actor.residual_self_attention.attention.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('actor.residual_self_attention.mlps.0.weight',\n",
       "              tensor([[ 0.0479,  0.0944,  0.0849,  ..., -0.0381,  0.0044,  0.0498],\n",
       "                      [ 0.0490, -0.0160,  0.0924,  ..., -0.0307,  0.0422,  0.1215],\n",
       "                      [-0.0113, -0.1228,  0.0602,  ...,  0.0268,  0.0340, -0.0464],\n",
       "                      ...,\n",
       "                      [ 0.1042, -0.1132,  0.1024,  ..., -0.0055,  0.1134, -0.1128],\n",
       "                      [-0.1194, -0.0205, -0.0900,  ..., -0.0717, -0.1131, -0.0981],\n",
       "                      [ 0.0020, -0.0291,  0.0573,  ...,  0.1001, -0.1114,  0.0605]])),\n",
       "             ('actor.residual_self_attention.mlps.0.bias',\n",
       "              tensor([ 0.1203,  0.0894, -0.0062, -0.0907, -0.0906, -0.1171,  0.0874, -0.1068,\n",
       "                       0.0928, -0.0620, -0.0567, -0.1222, -0.0240, -0.1019, -0.0218,  0.0769,\n",
       "                      -0.0484, -0.1155, -0.0145, -0.0101, -0.0256, -0.0654,  0.0051,  0.0324,\n",
       "                       0.0339, -0.0769,  0.0788, -0.1128, -0.0936, -0.0228,  0.0880, -0.0754,\n",
       "                       0.0575, -0.0784, -0.1120, -0.0970,  0.0192, -0.0305,  0.0409,  0.1118,\n",
       "                      -0.1052,  0.1049, -0.1113,  0.1244, -0.0534, -0.0471, -0.0202,  0.0812,\n",
       "                      -0.0885,  0.1082, -0.0277, -0.0696, -0.0194,  0.1113,  0.0375,  0.1165,\n",
       "                       0.0323,  0.0068,  0.0101, -0.0251,  0.1228, -0.1052, -0.0076, -0.0692])),\n",
       "             ('actor.decider.weight',\n",
       "              tensor([[-0.0048,  0.0484,  0.0781,  0.0801,  0.0130, -0.0583, -0.0086,  0.0719,\n",
       "                       -0.0018,  0.0839, -0.0364,  0.0413,  0.0505,  0.0230,  0.0838,  0.0098,\n",
       "                        0.0634, -0.0101, -0.0355, -0.0816,  0.0274,  0.0382, -0.0335,  0.0041,\n",
       "                       -0.0211,  0.0253,  0.0464, -0.0374,  0.0133, -0.0008,  0.0728,  0.0501,\n",
       "                        0.0205,  0.0609, -0.0573,  0.0582, -0.0688, -0.0411, -0.0114,  0.0825,\n",
       "                       -0.0102, -0.0392,  0.0280,  0.0507,  0.0129, -0.0040, -0.0355, -0.0710,\n",
       "                        0.0426, -0.0165, -0.0494,  0.0529,  0.0578,  0.0353, -0.0026, -0.0411,\n",
       "                        0.0245,  0.0241, -0.0300, -0.0789,  0.0090,  0.0356, -0.0805, -0.0733,\n",
       "                       -0.0096, -0.0413,  0.0506,  0.0321,  0.0371,  0.0595, -0.0411, -0.0252,\n",
       "                        0.0627,  0.0721, -0.0812, -0.0477,  0.0566, -0.0860,  0.0677,  0.0237,\n",
       "                        0.0520, -0.0282, -0.0756, -0.0614, -0.0400,  0.0863, -0.0061, -0.0066,\n",
       "                        0.0745,  0.0342,  0.0091,  0.0386, -0.0109,  0.0410, -0.0522, -0.0605,\n",
       "                       -0.0010, -0.0579, -0.0476, -0.0312, -0.0159,  0.0544,  0.0425,  0.0848,\n",
       "                       -0.0820,  0.0073, -0.0380,  0.0478, -0.0537, -0.0358,  0.0611, -0.0175,\n",
       "                        0.0854, -0.0211, -0.0180,  0.0737, -0.0087,  0.0721, -0.0091,  0.0753,\n",
       "                        0.0109, -0.0517, -0.0662,  0.0293,  0.0384,  0.0669, -0.0692, -0.0043],\n",
       "                      [ 0.0850, -0.0716,  0.0127, -0.0026, -0.0034,  0.0236,  0.0078, -0.0208,\n",
       "                        0.0104,  0.0625,  0.0581,  0.0461,  0.0728, -0.0740,  0.0229, -0.0407,\n",
       "                       -0.0465, -0.0865,  0.0230, -0.0145,  0.0026, -0.0258,  0.0501, -0.0216,\n",
       "                       -0.0021, -0.0332,  0.0227, -0.0057, -0.0546, -0.0432, -0.0705,  0.0233,\n",
       "                        0.0097,  0.0316, -0.0769, -0.0526,  0.0131,  0.0787, -0.0323, -0.0764,\n",
       "                       -0.0550, -0.0183, -0.0746,  0.0702, -0.0094, -0.0784,  0.0834, -0.0341,\n",
       "                       -0.0446, -0.0309, -0.0835, -0.0208, -0.0281, -0.0056,  0.0651,  0.0105,\n",
       "                        0.0666,  0.0746,  0.0657,  0.0833,  0.0640, -0.0100,  0.0464,  0.0546,\n",
       "                        0.0083, -0.0595,  0.0855,  0.0620,  0.0370, -0.0828, -0.0824, -0.0499,\n",
       "                       -0.0828,  0.0101, -0.0508,  0.0430, -0.0533, -0.0349,  0.0217, -0.0001,\n",
       "                       -0.0772,  0.0744,  0.0301, -0.0246,  0.0160,  0.0265,  0.0665,  0.0637,\n",
       "                       -0.0723,  0.0228,  0.0076,  0.0071,  0.0175, -0.0748, -0.0142, -0.0097,\n",
       "                        0.0120, -0.0158, -0.0309,  0.0207,  0.0811, -0.0646, -0.0053,  0.0338,\n",
       "                        0.0109, -0.0436, -0.0070,  0.0088, -0.0312, -0.0527, -0.0535,  0.0791,\n",
       "                       -0.0396,  0.0399,  0.0180,  0.0467,  0.0873,  0.0832,  0.0361, -0.0495,\n",
       "                       -0.0231, -0.0650,  0.0408, -0.0429,  0.0052,  0.0862, -0.0235,  0.0817],\n",
       "                      [-0.0642, -0.0094, -0.0487, -0.0273,  0.0554,  0.0648, -0.0085, -0.0501,\n",
       "                        0.0494, -0.0364,  0.0347,  0.0758, -0.0720, -0.0613, -0.0634, -0.0604,\n",
       "                       -0.0538,  0.0149, -0.0511, -0.0553,  0.0703, -0.0579, -0.0194, -0.0863,\n",
       "                        0.0677,  0.0666,  0.0664, -0.0260, -0.0766, -0.0432,  0.0474,  0.0842,\n",
       "                        0.0802, -0.0608, -0.0380, -0.0525,  0.0016,  0.0228, -0.0524, -0.0069,\n",
       "                       -0.0433,  0.0843, -0.0687, -0.0713,  0.0025,  0.0218, -0.0232, -0.0781,\n",
       "                        0.0035,  0.0845,  0.0281,  0.0373,  0.0198,  0.0393, -0.0136, -0.0451,\n",
       "                        0.0412,  0.0751,  0.0242,  0.0039, -0.0816, -0.0591,  0.0587, -0.0186,\n",
       "                       -0.0717, -0.0753,  0.0024,  0.0196, -0.0798,  0.0613, -0.0847,  0.0810,\n",
       "                       -0.0185, -0.0136,  0.0214,  0.0794,  0.0099,  0.0457,  0.0319,  0.0311,\n",
       "                       -0.0417, -0.0645,  0.0277, -0.0278,  0.0512,  0.0126, -0.0500,  0.0275,\n",
       "                        0.0536,  0.0714, -0.0408, -0.0323, -0.0008,  0.0674, -0.0382,  0.0641,\n",
       "                        0.0392, -0.0153,  0.0092,  0.0555,  0.0328, -0.0755,  0.0142,  0.0347,\n",
       "                        0.0031,  0.0301, -0.0266, -0.0016,  0.0148, -0.0654, -0.0854, -0.0607,\n",
       "                        0.0741, -0.0257, -0.0303,  0.0206,  0.0150,  0.0400, -0.0089,  0.0633,\n",
       "                        0.0175,  0.0057, -0.0338, -0.0700, -0.0078,  0.0859,  0.0218,  0.0821]])),\n",
       "             ('actor.decider.bias', tensor([-0.0072,  0.0306, -0.0674])),\n",
       "             ('critic.action_var', tensor([0.3600])),\n",
       "             ('critic.scale_tril', tensor([[[0.6000]]])),\n",
       "             ('critic.layer_norm.self embedding.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('critic.layer_norm.self embedding.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('critic.layer_norm.node embedding.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('critic.layer_norm.node embedding.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('critic.layer_norm.residual self attention.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('critic.layer_norm.residual self attention.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('critic.feature_embed.0.weight',\n",
       "              tensor([[-2.8074e-02,  6.0067e-02, -6.4246e-05,  ...,  5.4294e-02,\n",
       "                       -4.2425e-02, -6.9181e-03],\n",
       "                      [-5.7692e-02, -5.7949e-02, -5.8121e-02,  ..., -2.1161e-02,\n",
       "                        3.9016e-02,  5.5923e-02],\n",
       "                      [-1.8652e-02, -6.9414e-03,  1.2083e-02,  ..., -6.2160e-02,\n",
       "                       -3.6772e-03,  5.2096e-02],\n",
       "                      ...,\n",
       "                      [-5.4096e-02,  5.7904e-02, -1.0635e-02,  ..., -5.0988e-02,\n",
       "                       -4.0889e-02, -6.1996e-02],\n",
       "                      [-4.3120e-02,  3.1611e-02, -6.2243e-02,  ..., -5.0826e-02,\n",
       "                       -6.1902e-04, -4.9514e-02],\n",
       "                      [-3.8091e-02,  4.5082e-02,  3.7738e-02,  ..., -5.4446e-02,\n",
       "                        3.7606e-02,  1.9524e-02]])),\n",
       "             ('critic.feature_embed.0.bias',\n",
       "              tensor([-0.0362,  0.0117, -0.0427,  0.0125,  0.0296, -0.0181, -0.0130,  0.0614,\n",
       "                       0.0267, -0.0013,  0.0532,  0.0314, -0.0037, -0.0029, -0.0133,  0.0303,\n",
       "                      -0.0600, -0.0517, -0.0391,  0.0189,  0.0280, -0.0537,  0.0076, -0.0315,\n",
       "                       0.0181,  0.0026, -0.0188, -0.0341, -0.0311,  0.0329, -0.0087, -0.0345])),\n",
       "             ('critic.feature_embed.1.weight',\n",
       "              tensor([[-0.3484,  0.0778,  0.0123],\n",
       "                      [-0.2146, -0.4571,  0.0245],\n",
       "                      [ 0.2016,  0.3441,  0.0684],\n",
       "                      [-0.1075, -0.3132, -0.5447],\n",
       "                      [-0.1077, -0.4365, -0.4442],\n",
       "                      [ 0.3852,  0.3168, -0.1995],\n",
       "                      [-0.3078, -0.4346,  0.2901],\n",
       "                      [-0.5072, -0.4925, -0.0747],\n",
       "                      [ 0.3018, -0.3022, -0.0779],\n",
       "                      [ 0.4296,  0.0999, -0.0659],\n",
       "                      [ 0.5387, -0.3247, -0.1145],\n",
       "                      [ 0.0218, -0.0139, -0.0242],\n",
       "                      [ 0.2238, -0.5521,  0.0793],\n",
       "                      [-0.2908,  0.3235,  0.0085],\n",
       "                      [-0.3426,  0.3508,  0.2157],\n",
       "                      [ 0.0038,  0.0474,  0.1042],\n",
       "                      [-0.1221, -0.5642, -0.4350],\n",
       "                      [-0.0368,  0.0481,  0.5062],\n",
       "                      [ 0.1584, -0.0022,  0.0378],\n",
       "                      [-0.0152, -0.2120, -0.4527],\n",
       "                      [ 0.0607,  0.3081, -0.3156],\n",
       "                      [-0.5698,  0.4218,  0.1720],\n",
       "                      [ 0.3607,  0.1781,  0.5602],\n",
       "                      [ 0.1271, -0.2265,  0.1714],\n",
       "                      [-0.0090,  0.2702,  0.5721],\n",
       "                      [-0.1863,  0.0152,  0.3705],\n",
       "                      [ 0.1906,  0.4511, -0.1231],\n",
       "                      [-0.1216, -0.3767,  0.3446],\n",
       "                      [ 0.4101,  0.1644, -0.0971],\n",
       "                      [ 0.0820, -0.0084,  0.4234],\n",
       "                      [-0.1472,  0.4168, -0.1521],\n",
       "                      [ 0.0353,  0.0694,  0.4427]])),\n",
       "             ('critic.feature_embed.1.bias',\n",
       "              tensor([ 0.1297, -0.4982,  0.2267,  0.0308, -0.4152, -0.5170,  0.2497, -0.2370,\n",
       "                      -0.1743, -0.0279, -0.5723,  0.2840,  0.1536,  0.5198, -0.4849, -0.1983,\n",
       "                      -0.2980,  0.1374,  0.3809, -0.3667, -0.4440, -0.5652, -0.2787, -0.0133,\n",
       "                      -0.0723,  0.2305,  0.1836, -0.2090, -0.4070,  0.2599,  0.1482,  0.3562])),\n",
       "             ('critic.self_embed.weight',\n",
       "              tensor([[ 0.0600, -0.0672,  0.0345,  ..., -0.0540,  0.0037, -0.0908],\n",
       "                      [ 0.0527,  0.0883, -0.0484,  ..., -0.1148, -0.0547, -0.0576],\n",
       "                      [-0.0509,  0.0296,  0.0653,  ..., -0.0861,  0.0342, -0.0795],\n",
       "                      ...,\n",
       "                      [ 0.0633,  0.0182, -0.0847,  ...,  0.0576, -0.0835, -0.0752],\n",
       "                      [ 0.0931,  0.1085, -0.0284,  ...,  0.0343, -0.0245, -0.0649],\n",
       "                      [ 0.0031, -0.0200,  0.0729,  ...,  0.0957, -0.0459, -0.0930]])),\n",
       "             ('critic.self_embed.bias',\n",
       "              tensor([-0.0255,  0.0542, -0.0913,  0.0693, -0.0077,  0.0504, -0.0539, -0.1069,\n",
       "                      -0.0110, -0.0319,  0.0496, -0.0235,  0.0653, -0.0650,  0.0894,  0.0691,\n",
       "                      -0.0948, -0.1035, -0.0605, -0.0381,  0.0407,  0.0583, -0.0173,  0.0291,\n",
       "                       0.0880,  0.0660, -0.0420, -0.0054,  0.0851,  0.0786, -0.0722, -0.0578,\n",
       "                       0.0469, -0.0905,  0.0758, -0.0294, -0.1056,  0.0575, -0.0738, -0.0942,\n",
       "                       0.0494,  0.0476,  0.0862,  0.0685,  0.0710, -0.0878, -0.1116, -0.1002,\n",
       "                      -0.0337,  0.1131,  0.0809, -0.0153,  0.0789,  0.0723,  0.0972,  0.1019,\n",
       "                       0.0608,  0.1154,  0.0087, -0.0553, -0.0060, -0.0167, -0.0147,  0.0185])),\n",
       "             ('critic.node_embed.weight',\n",
       "              tensor([[-0.0030, -0.0299, -0.0366,  ...,  0.0696, -0.0647,  0.0717],\n",
       "                      [ 0.0011,  0.0514, -0.0057,  ...,  0.0827,  0.0047, -0.0177],\n",
       "                      [-0.0029,  0.0669,  0.0710,  ...,  0.0757, -0.0857,  0.0254],\n",
       "                      ...,\n",
       "                      [-0.0686,  0.0566, -0.0810,  ..., -0.0211, -0.0563, -0.0539],\n",
       "                      [ 0.0659, -0.0513,  0.0206,  ...,  0.0164,  0.0215, -0.0238],\n",
       "                      [-0.0197, -0.0287,  0.0429,  ..., -0.0587, -0.0134, -0.0149]])),\n",
       "             ('critic.node_embed.bias',\n",
       "              tensor([ 0.0816, -0.0820, -0.0319,  0.0595,  0.0277,  0.0699, -0.0177, -0.0569,\n",
       "                      -0.0351, -0.0501,  0.0840, -0.0325,  0.0018,  0.0244,  0.0014,  0.0818,\n",
       "                      -0.0567, -0.0668, -0.0159,  0.0071, -0.0419, -0.0652,  0.0744,  0.0598,\n",
       "                       0.0350, -0.0154, -0.0701, -0.0126,  0.0028, -0.0027, -0.0418, -0.0112,\n",
       "                      -0.0213, -0.0146, -0.0665,  0.0550,  0.0683, -0.0739,  0.0658,  0.0386,\n",
       "                       0.0229, -0.0750,  0.0516,  0.0094, -0.0247,  0.0443, -0.0632, -0.0774,\n",
       "                      -0.0185,  0.0032, -0.0023,  0.0717, -0.0086,  0.0220,  0.0447, -0.0426,\n",
       "                       0.0660,  0.0617,  0.0301,  0.0258,  0.0468, -0.0415,  0.0606,  0.0317])),\n",
       "             ('critic.residual_self_attention.attention.in_proj_weight',\n",
       "              tensor([[-0.1425, -0.0792, -0.1219,  ...,  0.0729, -0.0685, -0.0482],\n",
       "                      [-0.0414,  0.0730,  0.0114,  ..., -0.0121,  0.0568,  0.1089],\n",
       "                      [-0.0436,  0.0568,  0.1247,  ..., -0.0409, -0.1482,  0.0588],\n",
       "                      ...,\n",
       "                      [ 0.1022,  0.1375,  0.0124,  ...,  0.0720, -0.0351, -0.0595],\n",
       "                      [ 0.1520,  0.0119,  0.0245,  ..., -0.0010, -0.0826,  0.1523],\n",
       "                      [ 0.0991,  0.1203,  0.1002,  ...,  0.0318, -0.0145, -0.1139]])),\n",
       "             ('critic.residual_self_attention.attention.in_proj_bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('critic.residual_self_attention.attention.out_proj.weight',\n",
       "              tensor([[ 0.0160,  0.0654, -0.0662,  ..., -0.1248,  0.0378, -0.0027],\n",
       "                      [ 0.0035,  0.0676, -0.0631,  ..., -0.0784,  0.0741, -0.0959],\n",
       "                      [-0.0543,  0.0268, -0.1119,  ..., -0.0363, -0.1130,  0.0550],\n",
       "                      ...,\n",
       "                      [ 0.0648,  0.0486,  0.0079,  ..., -0.1113, -0.0523, -0.0718],\n",
       "                      [ 0.0579, -0.1064,  0.1218,  ..., -0.0873,  0.0562,  0.1101],\n",
       "                      [ 0.0131,  0.1180, -0.0600,  ..., -0.0187, -0.0144,  0.0883]])),\n",
       "             ('critic.residual_self_attention.attention.out_proj.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('critic.residual_self_attention.mlps.0.weight',\n",
       "              tensor([[ 0.0412, -0.1062, -0.0281,  ...,  0.0235, -0.0283, -0.0969],\n",
       "                      [-0.1038, -0.1216,  0.0394,  ...,  0.0059,  0.0396,  0.0936],\n",
       "                      [ 0.1199, -0.1093, -0.0080,  ...,  0.1151,  0.1235, -0.0290],\n",
       "                      ...,\n",
       "                      [-0.0734,  0.0952, -0.1115,  ...,  0.1081, -0.0397,  0.0410],\n",
       "                      [-0.0825, -0.0800,  0.0143,  ..., -0.0655,  0.1053, -0.0985],\n",
       "                      [ 0.0032, -0.0370,  0.0130,  ..., -0.1011,  0.0659, -0.1187]])),\n",
       "             ('critic.residual_self_attention.mlps.0.bias',\n",
       "              tensor([-0.0745,  0.0310, -0.0175,  0.0769,  0.0182,  0.0373,  0.0581,  0.0445,\n",
       "                       0.0156,  0.0480,  0.0620,  0.0021,  0.0714,  0.0526,  0.1196, -0.0792,\n",
       "                      -0.0940,  0.0849, -0.0979,  0.1170,  0.0387,  0.0630, -0.0293, -0.0401,\n",
       "                       0.0081, -0.0280, -0.1128, -0.0065, -0.0999, -0.0355,  0.0396,  0.0989,\n",
       "                       0.0912,  0.0908, -0.1016, -0.1022, -0.0384, -0.0130, -0.0327, -0.1021,\n",
       "                       0.0820,  0.0579,  0.0173, -0.0826, -0.0203, -0.0372,  0.0330,  0.0547,\n",
       "                      -0.0247, -0.0289, -0.0728,  0.0233,  0.0950, -0.0089, -0.0827,  0.0416,\n",
       "                      -0.1019, -0.0182, -0.0452, -0.0029,  0.0136,  0.0832,  0.0259,  0.0273])),\n",
       "             ('critic.decider.weight',\n",
       "              tensor([[ 0.0598,  0.0544,  0.0750,  0.0445,  0.0751, -0.0560, -0.0106, -0.0807,\n",
       "                        0.0565,  0.0016,  0.0455, -0.0641, -0.0533, -0.0463,  0.0844, -0.0592,\n",
       "                        0.0836, -0.0537, -0.0346, -0.0631, -0.0451,  0.0048, -0.0122, -0.0512,\n",
       "                       -0.0378,  0.0287, -0.0020, -0.0129,  0.0412, -0.0083,  0.0862,  0.0088,\n",
       "                       -0.0366,  0.0607,  0.0036,  0.0101,  0.0838,  0.0549, -0.0757, -0.0046,\n",
       "                        0.0621, -0.0463,  0.0545, -0.0269, -0.0438,  0.0177, -0.0393,  0.0844,\n",
       "                       -0.0051, -0.0244, -0.0569, -0.0179, -0.0852,  0.0627, -0.0771,  0.0808,\n",
       "                        0.0389, -0.0338,  0.0792,  0.0437, -0.0226, -0.0868, -0.0511, -0.0577,\n",
       "                        0.0734,  0.0016,  0.0278, -0.0788, -0.0025, -0.0883,  0.0398, -0.0718,\n",
       "                       -0.0214,  0.0354, -0.0236,  0.0313, -0.0302,  0.0757, -0.0136,  0.0489,\n",
       "                       -0.0068, -0.0700, -0.0157,  0.0609,  0.0324, -0.0539, -0.0785, -0.0171,\n",
       "                        0.0153, -0.0368,  0.0856, -0.0647,  0.0023, -0.0838,  0.0881,  0.0187,\n",
       "                       -0.0644, -0.0621,  0.0374,  0.0024,  0.0044,  0.0554, -0.0055,  0.0415,\n",
       "                        0.0673,  0.0345, -0.0691,  0.0372,  0.0299, -0.0107, -0.0081,  0.0241,\n",
       "                       -0.0299,  0.0582, -0.0412, -0.0720, -0.0442, -0.0573,  0.0875,  0.0546,\n",
       "                       -0.0173, -0.0030, -0.0367, -0.0286,  0.0821,  0.0676, -0.0608, -0.0665]])),\n",
       "             ('critic.decider.bias', tensor([0.0516]))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ray.remote(\n",
    "    # memory=32*2**30,\n",
    "    resources={'node:100.64.246.20': 1.0},\n",
    "    max_calls=1,\n",
    ")\n",
    "def large():\n",
    "    pol = celltrip.policy.PPO(6, [256 ,3], 3)\n",
    "    return pol.state_dict()\n",
    "\n",
    "ray.get(large.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 136])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory['states'][0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
