{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High priority\n",
    "  - Move to long-running ray instances which pull from a central data class, maybe also have a manager which tracks running jobs?\n",
    "  - Auto set max GPUs for update (?)\n",
    "  - Add node to event log\n",
    "  - Implement stages\n",
    "  - Add checkpoints\n",
    "  - Add model loading\n",
    "  - Add train/val to dataloader\n",
    "  - Partition detection in `train_policy`\n",
    "  - Script arguments, including address for ray\n",
    "- Medium priority\n",
    "  - Add uncompressed memory buffer option\n",
    "  - Eliminate passing of persistent storage for memory objects\n",
    "  - Add hook for wandb, etc.\n",
    "  - Add state manager to env and then parallelize in analysis, maybe make `analyze` function\n",
    "- Low priority\n",
    "  - Seed policy initialization and unseed update, add reproducibility tag to wait for all rollouts before updating\n",
    "  - Verify worker timeout\n",
    "  - Subtract working memory on host node\n",
    "  - Local data loading per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# # TODO: Figure out how to format arguments for appending h5ad files\n",
    "# parser.add_argument('datasets', type=str, required=False, help='.h5ad files to use for data')\n",
    "# parser.add_argument('--concatenate', type=str, required=False, help=\n",
    "#     '.h5ad files to concatenate as a single modality, may be used multiple times')\n",
    "\n",
    "# group = parser.add_argument_group('General')\n",
    "# group.add_argument('--seed', default=42, type=int, help='**Seed for random calls during training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = None\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Construct dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.shutdown(); ray.init(\n",
    "    address='ray://127.0.0.1:10001',\n",
    "    runtime_env={\n",
    "        'env_vars': {\n",
    "            # NOTE: Important, NCCL will timeout if network device is non-standard\n",
    "            'NCCL_SOCKET_IFNAME': 'tailscale',\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "        }})\n",
    "\n",
    "# Initialize distributed manager\n",
    "policy_init, memory_init = celltrip.train.get_train_initializers(\n",
    "    3, [m.shape[1] for m in modalities], policy_kwargs={'epochs': 80})\n",
    "distributed_manager = celltrip.train.DistributedManager(\n",
    "    policy_init=policy_init, memory_init=memory_init,\n",
    "    max_jobs_per_gpu=1, update_gpus=2)\n",
    "\n",
    "# Perform training\n",
    "celltrip.train.train_policy(distributed_manager, dataloader, rollout_kwargs={'dummy': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End timer\n",
    "print(f'Ran for {time.perf_counter() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update remote policy\n",
    "distributed_manager.policy_manager.release_locks.remote()\n",
    "ray.get(distributed_manager.update())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear locks\n",
    "distributed_manager.policy_manager.release_locks.remote()\n",
    "\n",
    "# Get policy\n",
    "device = 'cuda'\n",
    "policy = policy_init().to(device)\n",
    "celltrip.train.set_policy_state(policy, ray.get(distributed_manager.policy_manager.get_policy_state.remote()))\n",
    "\n",
    "# Get memory\n",
    "ray.get(distributed_manager.policy_manager.normalize_memory.remote())\n",
    "memory = memory_init(policy)\n",
    "memory.append_memory(\n",
    "    *ray.get(distributed_manager.policy_manager.get_memory_storage.remote()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(\n",
    "    # memory=32*2**30,\n",
    "    resources={'node:100.64.246.20': 1.0},\n",
    "    max_calls=1,\n",
    ")\n",
    "def large():\n",
    "    return memory.storage\n",
    "\n",
    "ray.get(large.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = policy.to('cpu').share_memory()\n",
    "state = memory._append_suffix(memory.storage['states'][0], keys=memory.storage['keys'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = pol.share_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.set_num_threads(4)\n",
    "for _ in range(20):\n",
    "    with torch.inference_mode():\n",
    "        # max_batch = 20\n",
    "        # state_split = celltrip.utility.processing.split_state(state, **pol.split_args)\n",
    "        # with torch.multiprocessing.Pool(7) as p:\n",
    "        #     p.map(pol.act_spread, [\n",
    "        #         [state_split[i][start_idx:start_idx+max_batch] for i in range(2)]\n",
    "        #         for start_idx in range(0, state.shape[0], max_batch)])\n",
    "        pol.act_macro(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "with multiprocessing.Pool(5) as p:\n",
    "    res = p.map(lambda mem: mem.fast_sample(2_000), memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['states'][1].nbytes / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.perf_counter()\n",
    "\n",
    "# # Perform Rollout\n",
    "# env_init = lambda policy, modalities: celltrip.environment.EnvironmentBase(\n",
    "#     *modalities,\n",
    "#     dim=policy.output_dim,\n",
    "#     # max_timesteps=1e2,\n",
    "#     penalty_bound=1,\n",
    "#     device=policy.device)\n",
    "# future = distributed_manager.rollout(\n",
    "#     modalities=modalities,\n",
    "#     keys=adata_obs[0].index.to_numpy(),\n",
    "#     env_init=env_init,\n",
    "#     dummy=False)\n",
    "# time.sleep(1)\n",
    "# print(ray.available_resources())\n",
    "# ret = ray.get(future)\n",
    "\n",
    "# time.perf_counter() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform Rollout\n",
    "# env_init = lambda policy, modalities: celltrip.environment.EnvironmentBase(\n",
    "#     *modalities,\n",
    "#     dim=policy.output_dim,\n",
    "#     # max_timesteps=1e2,\n",
    "#     penalty_bound=1,\n",
    "#     device=policy.device)\n",
    "# ray.get(distributed_manager.rollout(\n",
    "#     modalities=modalities,\n",
    "#     keys=adata_obs[0].index.to_numpy(),\n",
    "#     env_init=env_init,\n",
    "#     dummy=False))\n",
    "\n",
    "# # Get state of job from ObjectRef\n",
    "# import ray.util.state\n",
    "# object_id = dm.futures['simulation'][0].hex()\n",
    "# object_state = ray.util.state.get_objects(object_id)[0]\n",
    "# object_state.task_status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
