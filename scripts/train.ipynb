{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train/test\n",
    "- Save preprocessing\n",
    "- Early stopping for `train_celltrip` based on action_std and/or KL\n",
    "- Maybe [this](https://arxiv.org/abs/2102.09430) but probably not\n",
    "- [EFS on clusters maybe](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/aws.html#start-ray-with-the-ray-cluster-launcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython is not active\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py s3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad --backed --target_modalities 1 --dim 3 --train_split .8 --num_gpus 3 --num_learners 3 --num_runners 3 --update_timesteps 100_000 --max_timesteps 100_000_000 --dont_sync_across_nodes --logfile s3://nkalafut-celltrip/logs/Noise.log --checkpoint_iterations 100 --checkpoint_dir s3://nkalafut-celltrip/checkpoints --checkpoint_name Noise\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "# NOTE: It is not recommended to use s3 with credentials unless the creds are permanent, the bucket is public, or this is run on AWS\n",
    "parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Reading\n",
    "group = parser.add_argument_group('Input')\n",
    "group.add_argument('input_files', type=str, nargs='*', help='h5ad files to be used for input')\n",
    "group.add_argument('--merge_files', type=str, action='append', nargs='+', help='h5ad files to merge as input')\n",
    "group.add_argument('--partition_cols', type=str, action='append', nargs='+', help='Columns for data partitioning, found in `adata.obs` DataFrame')\n",
    "group.add_argument('--backed', action='store_true', help='Read data directly from disk or s3, saving memory at the cost of time')\n",
    "group.add_argument('--input_modalities', type=int, nargs='+', help='Input modalities to give to CellTRIP')\n",
    "group.add_argument('--target_modalities', type=int, nargs='+', help='Target modalities to emulate, dictates environment reward')\n",
    "# Algorithm\n",
    "group = parser.add_argument_group('Algorithm')\n",
    "group.add_argument('--dim', type=int, default=16, help='Dimensions in the output latent space')\n",
    "group.add_argument('--train_split', type=float, default=1., help='Fraction of input data to use as training')\n",
    "# Computation\n",
    "group = parser.add_argument_group('Computation')\n",
    "group.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use during computation')\n",
    "group.add_argument('--num_learners', type=int, default=1, help='Number of learners used in backward computation, cannot exceed GPUs')\n",
    "group.add_argument('--num_runners', type=int, default=1, help='Number of workers for environment simulation')\n",
    "# Training\n",
    "group = parser.add_argument_group('Training')\n",
    "group.add_argument('--update_timesteps', type=int, default=int(1e6), help='Number of timesteps recorded before each update')\n",
    "group.add_argument('--max_timesteps', type=int, default=int(2e9), help='Maximum number of timesteps to compute before exiting')\n",
    "group.add_argument('--dont_sync_across_nodes', action='store_true', help='Avoid memory sync across nodes, saving overhead time at the cost of stability')\n",
    "# File saves\n",
    "group = parser.add_argument_group('Logging')\n",
    "group.add_argument('--logfile', type=str, default='cli', help='Location for log file, can be `cli`, `<local_file>`, or `<s3 location>`')\n",
    "group.add_argument('--flush_iterations', type=int, help='Number of iterations to wait before flushing logs')\n",
    "group.add_argument('--checkpoint', type=str, help='Checkpoint to use for initializing model')\n",
    "group.add_argument('--checkpoint_iterations', type=int, default=50, help='Number of updates to wait before recording checkpoints')\n",
    "group.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory for checkpoints')\n",
    "group.add_argument('--checkpoint_name', type=str, help='Run name, for checkpointing')\n",
    "\n",
    "# Notebook defaults and script handling\n",
    "if not celltrip.utility.notebook.is_notebook():\n",
    "    # ray job submit -- python train.py...\n",
    "    config = parser.parse_args()\n",
    "else:\n",
    "    experiment_name = 'Noise'\n",
    "    command = (\n",
    "        f's3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad '\n",
    "        # f'/home/nck/repos/INEPT/data/MERFISH/expression.h5ad /home/nck/repos/INEPT/data/MERFISH/spatial.h5ad '\n",
    "        f'--backed '\n",
    "        f'--target_modalities 1 '\n",
    "        f'--dim 3 '\n",
    "        f'--train_split .8 '\n",
    "        f'--num_gpus 3 --num_learners 3 --num_runners 3 '\n",
    "        f'--update_timesteps 100_000 '\n",
    "        f'--max_timesteps 100_000_000 '\n",
    "        f'--dont_sync_across_nodes '\n",
    "        f'--logfile s3://nkalafut-celltrip/logs/{experiment_name}.log '\n",
    "        # f'--checkpoint s3://nkalafut-celltrip/checkpoints/Partial-L2-VelLinear-ClampLog-0500.weights '\n",
    "        f'--checkpoint_iterations 100 '\n",
    "        f'--checkpoint_dir s3://nkalafut-celltrip/checkpoints '\n",
    "        f'--checkpoint_name {experiment_name}')\n",
    "    config = parser.parse_args(command.split(' '))\n",
    "    print(f'python train.py {command}')\n",
    "    \n",
    "# Defaults\n",
    "if config.checkpoint_name is None:\n",
    "    config.checkpoint_name = f'RUN_{random.randint(0, 2**32):0>10}'\n",
    "    print(f'Run Name: {config.checkpoint_name}')\n",
    "# print(config)  # CLI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start Ray\n",
    "# ray.shutdown()\n",
    "# a = ray.init(\n",
    "#     # address='ray://100.85.187.118:10001',\n",
    "#     address='ray://localhost:10001',\n",
    "#     runtime_env={\n",
    "#         'py_modules': [celltrip],\n",
    "#         'pip': '../requirements.txt',\n",
    "#         'env_vars': {\n",
    "#             # **access_keys,\n",
    "#             'RAY_DEDUP_LOGS': '0'}},\n",
    "#         # 'NCCL_SOCKET_IFNAME': 'tailscale',  # lo,en,wls,docker,tailscale\n",
    "#     _system_config={'enable_worker_prestart': True})  # Doesn't really work for scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote(num_cpus=1e-4)\n",
    "# def train(config):\n",
    "#     import celltrip\n",
    "\n",
    "#     # Initialization\n",
    "#     dataloader_kwargs = {'mask': config.train_split}  # {'num_nodes': 20, 'pca_dim': 128}\n",
    "#     environment_kwargs = {\n",
    "#         'input_modalities': config.input_modalities,\n",
    "#         'target_modalities': config.target_modalities, 'dim': config.dim}\n",
    "#     initializers = celltrip.train.get_initializers(\n",
    "#         input_files=config.input_files, merge_files=config.merge_files,\n",
    "#         backed=config.backed, dataloader_kwargs=dataloader_kwargs,\n",
    "#         environment_kwargs=environment_kwargs)\n",
    "\n",
    "#     stage_functions = [\n",
    "#         # lambda w: w.env.set_rewards(penalty_velocity=1, penalty_action=1),\n",
    "#         # lambda w: w.env.set_rewards(reward_origin=1),\n",
    "#         # lambda w: w.env.set_rewards(reward_origin=0, reward_distance=1),\n",
    "#         # lambda w: w.env.dataloader.preprocessing.set_num_nodes(500),\n",
    "#         # lambda w: w.env.dataloader.preprocessing.set_num_nodes(1000),\n",
    "#         # lambda w: w.env.dataloader.preprocessing.set_num_nodes(2000),\n",
    "#         # lambda w: w.env.dataloader.preprocessing.set_num_nodes(3000),\n",
    "#     ]\n",
    "\n",
    "#     # Run function\n",
    "#     celltrip.train.train_celltrip(\n",
    "#         initializers=initializers,\n",
    "#         num_gpus=config.num_gpus, num_learners=config.num_learners,\n",
    "#         num_runners=config.num_runners, max_timesteps=config.max_timesteps,\n",
    "#         update_timesteps=config.update_timesteps, sync_across_nodes=not config.dont_sync_across_nodes,\n",
    "#         checkpoint_iterations=config.checkpoint_iterations, checkpoint_dir=config.checkpoint_dir,\n",
    "#         checkpoint=config.checkpoint, checkpoint_name=config.checkpoint_name,\n",
    "#         stage_functions=stage_functions, logfile=config.logfile)\n",
    "\n",
    "# ray.get(train.remote(config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get AWS keys\n",
    "# import boto3\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# session = boto3.Session()\n",
    "# creds = session.get_credentials()\n",
    "# access_keys = {\n",
    "#     'AWS_ACCESS_KEY_ID': creds.access_key,\n",
    "#     'AWS_SECRET_ACCESS_KEY': creds.secret_key,\n",
    "#     'AWS_DEFAULT_REGION': 'us-east-2'}\n",
    "\n",
    "# # Check s3\n",
    "# import os\n",
    "# import s3fs\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n",
    "# s3.ls('s3://nkalafut-celltrip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize locally\n",
    "os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "\n",
    "dataloader_kwargs = {'mask': config.train_split}  # {'num_nodes': 20, 'pca_dim': 128}\n",
    "environment_kwargs = {\n",
    "    'input_modalities': config.input_modalities,\n",
    "    'target_modalities': config.target_modalities, 'dim': config.dim}\n",
    "env_init, policy_init, memory_init = celltrip.train.get_initializers(\n",
    "    input_files=config.input_files, merge_files=config.merge_files,\n",
    "    backed=config.backed, dataloader_kwargs=dataloader_kwargs,   # policy_kwargs={'minibatch_size': 2_000},\n",
    "    environment_kwargs=environment_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/utility/processing.py:109: RuntimeWarning: Modality 0 too small for PCA (253 features), skipping\n",
      "  warnings.warn(\n",
      "/home/thema/repos/inept/celltrip/utility/processing.py:109: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "try: env\n",
    "except: env = env_init().to('cuda')\n",
    "# policy.split_args['max_nodes'] = 2000\n",
    "# policy.forward_batch_size = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy_init(env).to('cuda')\n",
    "policy.minibatch_size = 10_000\n",
    "# policy.update_iterations = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = memory_init(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: -1.845, distance: -0.973, origin: 0.000, bound: -0.011, velocity: -0.555, action: -0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/policy.py:1192: UserWarning: No group \"learners\" found.\n",
      "  warnings.warn(f'No group \"{group}\" found.')\n",
      "/home/thema/repos/inept/celltrip/policy.py:1192: UserWarning: No group \"default\" found.\n",
      "  warnings.warn(f'No group \"{group}\" found.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 - Total (0.34580) + PPO (0.00000) + critic (0.77674) + entropy (-4.25682) + KL (-0.00000) :: Moving Return Mean (0.00000), Moving Return STD (1.00000), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-0.68350), Return STD (1.13307), Advantage Mean (-0.44031), Advantage STD (1.08031), Log STD (0.00000), Explained Variance (0.09120)\n",
      "Iteration 05 - Total (0.32016) + PPO (-0.00596) + critic (0.73744) + entropy (-4.26002) + KL (0.00452) :: Moving Return Mean (-0.00082), Moving Return STD (1.00044), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-0.68824), Return STD (1.13111), Advantage Mean (-0.44465), Advantage STD (1.07799), Log STD (0.00107), Explained Variance (0.11273)\n",
      "total: -2.099, distance: -0.834, origin: 0.000, bound: -1.738, velocity: 0.779, action: -0.305\n",
      "Iteration 01 - Total (0.42807) + PPO (0.00000) + critic (0.94134) + entropy (-4.26052) + KL (-0.00000) :: Moving Return Mean (-0.00102), Moving Return STD (1.00056), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-0.76769), Return STD (1.35273), Advantage Mean (-0.51963), Advantage STD (1.29504), Log STD (0.00123), Explained Variance (0.08367)\n",
      "Iteration 05 - Total (0.37845) + PPO (-0.00802) + critic (0.85821) + entropy (-4.26344) + KL (0.00206) :: Moving Return Mean (-0.00194), Moving Return STD (1.00139), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-0.73779), Return STD (1.32672), Advantage Mean (-0.48671), Advantage STD (1.26790), Log STD (0.00221), Explained Variance (0.09418)\n",
      "total: -2.592, distance: -0.187, origin: 0.000, bound: -2.470, velocity: 0.370, action: -0.306\n",
      "Iteration 01 - Total (0.48645) + PPO (0.00000) + critic (1.05818) + entropy (-4.26424) + KL (-0.00000) :: Moving Return Mean (-0.00216), Moving Return STD (1.00159), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-1.63732), Return STD (1.48987), Advantage Mean (-0.58673), Advantage STD (1.42146), Log STD (0.00247), Explained Variance (0.09001)\n",
      "Iteration 05 - Total (0.42172) + PPO (-0.00425) + critic (0.93727) + entropy (-4.26717) + KL (0.00294) :: Moving Return Mean (-0.00409), Moving Return STD (1.00384), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-1.62371), Return STD (1.47375), Advantage Mean (-0.57131), Advantage STD (1.40375), Log STD (0.00345), Explained Variance (0.11810)\n",
      "total: -2.354, distance: 0.229, origin: 0.000, bound: -1.535, velocity: -0.741, action: -0.306\n",
      "Iteration 01 - Total (0.38981) + PPO (0.00000) + critic (0.86498) + entropy (-4.26792) + KL (-0.00000) :: Moving Return Mean (-0.00458), Moving Return STD (1.00441), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.09466), Return STD (1.37201), Advantage Mean (-0.36705), Advantage STD (1.27176), Log STD (0.00370), Explained Variance (0.14082)\n",
      "Iteration 05 - Total (0.37694) + PPO (-0.00074) + critic (0.84079) + entropy (-4.27114) + KL (0.00586) :: Moving Return Mean (-0.00710), Moving Return STD (1.00755), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.08695), Return STD (1.37376), Advantage Mean (-0.36125), Advantage STD (1.27437), Log STD (0.00477), Explained Variance (0.16959)\n",
      "total: -1.059, distance: 0.351, origin: 0.000, bound: -0.859, velocity: -0.244, action: -0.306\n",
      "Iteration 01 - Total (0.35412) + PPO (0.00000) + critic (0.79368) + entropy (-4.27190) + KL (0.00000) :: Moving Return Mean (-0.00772), Moving Return STD (1.00833), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.18273), Return STD (1.38365), Advantage Mean (-0.04868), Advantage STD (1.22369), Log STD (0.00503), Explained Variance (0.21790)\n",
      "Iteration 05 - Total (0.32709) + PPO (-0.00265) + critic (0.74498) + entropy (-4.27552) + KL (0.00087) :: Moving Return Mean (-0.01033), Moving Return STD (1.01168), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.18812), Return STD (1.36285), Advantage Mean (-0.04685), Advantage STD (1.20228), Log STD (0.00623), Explained Variance (0.25820)\n",
      "total: -0.664, distance: 0.111, origin: 0.000, bound: -0.807, velocity: 0.338, action: -0.306\n",
      "Iteration 01 - Total (0.33136) + PPO (-0.00000) + critic (0.74824) + entropy (-4.27652) + KL (0.00000) :: Moving Return Mean (-0.01098), Moving Return STD (1.01251), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.01173), Return STD (1.39846), Advantage Mean (-0.01488), Advantage STD (1.19272), Log STD (0.00657), Explained Variance (0.27331)\n",
      "Iteration 05 - Total (0.35194) + PPO (-0.00227) + critic (0.79404) + entropy (-4.28061) + KL (0.00411) :: Moving Return Mean (-0.01339), Moving Return STD (1.01549), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.01598), Return STD (1.45727), Advantage Mean (-0.01747), Advantage STD (1.25775), Log STD (0.00793), Explained Variance (0.27908)\n",
      "total: -1.083, distance: -0.160, origin: 0.000, bound: -0.967, velocity: 0.351, action: -0.307\n",
      "Iteration 01 - Total (0.32674) + PPO (-0.00000) + critic (0.73911) + entropy (-4.28151) + KL (0.00000) :: Moving Return Mean (-0.01399), Moving Return STD (1.01624), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.18516), Return STD (1.45877), Advantage Mean (-0.14399), Advantage STD (1.17802), Log STD (0.00823), Explained Variance (0.34835)\n",
      "Iteration 05 - Total (0.33987) + PPO (-0.00077) + critic (0.76699) + entropy (-4.28508) + KL (0.00116) :: Moving Return Mean (-0.01659), Moving Return STD (1.01968), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.17657), Return STD (1.52219), Advantage Mean (-0.15239), Advantage STD (1.23964), Log STD (0.00942), Explained Variance (0.35911)\n",
      "total: -1.953, distance: -0.133, origin: 0.000, bound: -1.280, velocity: -0.231, action: -0.308\n",
      "Iteration 01 - Total (0.36700) + PPO (0.00000) + critic (0.81973) + entropy (-4.28592) + KL (-0.00000) :: Moving Return Mean (-0.01724), Moving Return STD (1.02056), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.50437), Return STD (1.56056), Advantage Mean (-0.32065), Advantage STD (1.25088), Log STD (0.00970), Explained Variance (0.35832)\n",
      "Iteration 05 - Total (0.34673) + PPO (-0.00501) + critic (0.78927) + entropy (-4.28926) + KL (0.00206) :: Moving Return Mean (-0.02022), Moving Return STD (1.02498), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.50196), Return STD (1.56120), Advantage Mean (-0.32170), Advantage STD (1.25033), Log STD (0.01081), Explained Variance (0.36826)\n",
      "total: -1.188, distance: -0.312, origin: 0.000, bound: -0.630, velocity: 0.062, action: -0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/policy.py:1192: UserWarning: No group \"learners\" found.\n",
      "  warnings.warn(f'No group \"{group}\" found.')\n",
      "/home/thema/repos/inept/celltrip/policy.py:1192: UserWarning: No group \"default\" found.\n",
      "  warnings.warn(f'No group \"{group}\" found.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 - Total (0.28390) + PPO (0.00000) + critic (0.65360) + entropy (-4.29006) + KL (-0.00000) :: Moving Return Mean (-0.02097), Moving Return STD (1.02609), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.21979), Return STD (1.45160), Advantage Mean (-0.10257), Advantage STD (1.08375), Log STD (0.01108), Explained Variance (0.44263)\n",
      "Iteration 05 - Total (0.26638) + PPO (-0.00341) + critic (0.62543) + entropy (-4.29259) + KL (0.00776) :: Moving Return Mean (-0.02369), Moving Return STD (1.02976), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.26669), Return STD (1.44408), Advantage Mean (-0.09958), Advantage STD (1.06809), Log STD (0.01193), Explained Variance (0.46080)\n",
      "total: -1.198, distance: -0.950, origin: 0.000, bound: -0.255, velocity: 0.315, action: -0.309\n",
      "Iteration 01 - Total (0.29602) + PPO (0.00000) + critic (0.67789) + entropy (-4.29284) + KL (0.00000) :: Moving Return Mean (-0.02436), Moving Return STD (1.03064), Moving Reward Mean (0.00000), Moving Reward STD (1.00000), Return Mean (-2.29851), Return STD (1.34784), Advantage Mean (-0.24302), Advantage STD (1.08038), Log STD (0.01201), Explained Variance (0.35742)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Forward\n",
    "    import line_profiler\n",
    "    memory.mark_sampled()\n",
    "    memory.cleanup()\n",
    "    prof = line_profiler.LineProfiler(\n",
    "        celltrip.train.simulate_until_completion,\n",
    "        celltrip.policy.PPO.forward, celltrip.policy.EntitySelfAttentionLite.forward, celltrip.policy.ResidualAttention.forward,\n",
    "        celltrip.environment.EnvironmentBase.step)\n",
    "    ret = prof.runcall(celltrip.train.simulate_until_completion, env, policy, memory, max_memories=policy.epoch_size, reset_on_finish=True)\n",
    "    print(f'total: {ret[2]:.3f}, ' + ', '.join([f'{k}: {v:.3f}' for k, v in ret[3].items()]))\n",
    "    # memory.feed_new(policy.reward_standardization)\n",
    "    memory.compute_advantages()  # moving_standardization=policy.reward_standardization\n",
    "    # prof.print_stats(output_unit=1)\n",
    "\n",
    "    # # Pull from memory\n",
    "    # import line_profiler\n",
    "    # prof = line_profiler.LineProfiler(\n",
    "    #     celltrip.memory.AdvancedMemoryBuffer.fast_sample,\n",
    "    #     celltrip.memory.AdvancedMemoryBuffer._concat_states)\n",
    "    # ret = prof.runcall(memory.fast_sample, 512, shuffle=False, max_samples_per_state=np.inf)\n",
    "    # # prof.print_stats(output_unit=1)\n",
    "\n",
    "    # Update\n",
    "    import line_profiler\n",
    "    prof = line_profiler.LineProfiler(policy.update, memory.fast_sample, celltrip.utility.processing.split_state)\n",
    "    ret = prof.runcall(policy.update, memory, verbose=True)\n",
    "    # print(', '.join([f'{k}: {v:.3f}' for k, v in ret[1].items()]))\n",
    "    # prof.print_stats(output_unit=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
