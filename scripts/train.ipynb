{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython is not active\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shlex\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py s3://nkalafut-celltrip/VirtualCell/vcc_flt_data.h5ad --partition_cols target_gene --backed --dim 4 --train_split .8 --num_gpus 2 --num_learners 2 --num_runners 2 --update_timesteps 1_000_000 --max_timesteps 800_000_000 --dont_sync_across_nodes --logfile s3://nkalafut-celltrip/logs/VCC-250818.log --flush_iterations 1 --checkpoint_iterations 100 --checkpoint_dir s3://nkalafut-celltrip/checkpoints --checkpoint_name VCC-250818\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "# NOTE: It is not recommended to use s3 with credentials unless the creds are permanent, the bucket is public, or this is run on AWS\n",
    "parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Reading\n",
    "group = parser.add_argument_group('Input')\n",
    "group.add_argument('input_files', type=str, nargs='*', help='h5ad files to be used for input')\n",
    "group.add_argument('--merge_files', type=str, action='append', nargs='+', help='h5ad files to merge as input')\n",
    "group.add_argument('--partition_cols', type=str, nargs='+', help='Columns for data partitioning, found in `adata.obs` DataFrame')\n",
    "group.add_argument('--backed', action='store_true', help='Read data directly from disk or s3, saving memory at the cost of time')\n",
    "group.add_argument('--input_modalities', type=int, nargs='+', help='Input modalities to give to CellTRIP')\n",
    "group.add_argument('--target_modalities', type=int, nargs='+', help='Target modalities to emulate, dictates environment reward')\n",
    "# Algorithm\n",
    "group = parser.add_argument_group('Algorithm')\n",
    "group.add_argument('--dim', type=int, default=16, help='Dimensions in the output latent space')\n",
    "group.add_argument('--discrete', action='store_true', help='Use the discrete model rather than continuous')\n",
    "group.add_argument('--train_split', type=float, default=1., help='Fraction of input data to use as training')\n",
    "group.add_argument('--train_partitions', action='store_true', help='Split training/validation data across partitions rather than samples')\n",
    "# Computation\n",
    "group = parser.add_argument_group('Computation')\n",
    "group.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use during computation')\n",
    "group.add_argument('--num_learners', type=int, default=1, help='Number of learners used in backward computation, cannot exceed GPUs')\n",
    "group.add_argument('--num_runners', type=int, default=1, help='Number of workers for environment simulation')\n",
    "# Training\n",
    "group = parser.add_argument_group('Training')\n",
    "group.add_argument('--update_timesteps', type=int, default=int(1e6), help='Number of timesteps recorded before each update')\n",
    "group.add_argument('--max_timesteps', type=int, default=int(2e9), help='Maximum number of timesteps to compute before exiting')\n",
    "group.add_argument('--dont_sync_across_nodes', action='store_true', help='Avoid memory sync across nodes, saving overhead time at the cost of stability')\n",
    "# File saves\n",
    "group = parser.add_argument_group('Logging')\n",
    "group.add_argument('--logfile', type=str, default='cli', help='Location for log file, can be `cli`, `<local_file>`, or `<s3 location>`')\n",
    "group.add_argument('--flush_iterations', default=25, type=int, help='Number of iterations to wait before flushing logs')\n",
    "group.add_argument('--checkpoint', type=str, help='Checkpoint to use for initializing model')\n",
    "group.add_argument('--checkpoint_iterations', type=int, default=100, help='Number of updates to wait before recording checkpoints')\n",
    "group.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory for checkpoints')\n",
    "group.add_argument('--checkpoint_name', type=str, help='Run name, for checkpointing')\n",
    "\n",
    "# Notebook defaults and script handling\n",
    "if not celltrip.utility.notebook.is_notebook():\n",
    "    # ray job submit -- python train.py...\n",
    "    config = parser.parse_args()\n",
    "else:\n",
    "    experiment_name = 'VCC-250818'\n",
    "    bucket_name = 'nkalafut-celltrip'\n",
    "    # bucket_name = 'arn:aws:s3:us-east-2:245432013314:accesspoint/ray-nkalafut-celltrip'\n",
    "    command = (\n",
    "        # MERFISH\n",
    "        # f's3://{bucket_name}/MERFISH/expression.h5ad s3://{bucket_name}/MERFISH/spatial.h5ad --target_modalities 1 '\n",
    "        # scGLUE\n",
    "        # f's3://{bucket_name}/scGLUE/Chen-2019-RNA.h5ad s3://{bucket_name}/scGLUE/Chen-2019-ATAC.h5ad '\n",
    "        # f's3://{bucket_name}/scGLUE/Chen-2019-RNA.h5ad s3://{bucket_name}/scGLUE/Chen-2019-ATAC.h5ad --input_modalities 0 --target_modalities 0 '\n",
    "        # f'../data/scglue/Chen-2019-RNA.h5ad ../data/scglue/Chen-2019-ATAC.h5ad --input_modalities 0 --target_modalities 0 '\n",
    "        # Flysta3D\n",
    "        # f' '.join([f'--merge_files ' + ' ' .join([f's3://{bucket_name}/Flysta3D/{p}_{m}.h5ad' for p in ('E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b')]) for m in ('expression', 'spatial')]) + ' '\n",
    "        # f'--target_modalities 1 '\n",
    "        # f'--partition_cols development '\n",
    "        # Particular stage Flysta\n",
    "        # f' '.join([f'--merge_files ' + ' ' .join([f's3://{bucket_name}/Flysta3D/{p}_{m}.h5ad' for p in ('L3_b',)]) for m in ('expression', 'spatial')]) + ' '\n",
    "        # f'--target_modalities 1 '\n",
    "        # f'--partition_cols development '\n",
    "        # Tahoe-100M\n",
    "        # f'--merge_files ' + ' '.join([f's3://{bucket_name}/Tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)]) + ' '\n",
    "        # f'--partition_cols sample '\n",
    "        # scMultiSim\n",
    "        # f's3://{bucket_name}/scMultiSim/expression.h5ad s3://{bucket_name}/scMultiSim/peaks.h5ad '\n",
    "        # MERFISH Bench\n",
    "        # f's3://{bucket_name}/MERFISH_Bench/expression.h5ad s3://{bucket_name}/MERFISH_Bench/spatial.h5ad '\n",
    "        # f'--target_modalities 1 '\n",
    "        # TemporalBrain\n",
    "        # f's3://{bucket_name}/TemporalBrain/expression.h5ad s3://{bucket_name}/TemporalBrain/peaks.h5ad '\n",
    "        # f'--partition_cols \"Donor ID\" '\n",
    "        # Virtual Cell Challenge\n",
    "        f's3://{bucket_name}/VirtualCell/vcc_flt_data.h5ad '\n",
    "        f'--partition_cols target_gene '\n",
    "\n",
    "        f'--backed '\n",
    "        # f'--dim 2 '\n",
    "        # f'--dim 8 '\n",
    "        f'--dim 4 '\n",
    "        # f'--discrete '\n",
    "\n",
    "        # Sample split\n",
    "        f'--train_split .8 '\n",
    "        # Partition split\n",
    "        # f'--train_split .6 '\n",
    "        # f'--train_partitions '\n",
    "        # Single slice\n",
    "        # f'--train_split .0001 '\n",
    "        # f'--train_partitions '\n",
    "\n",
    "        f'--num_gpus 2 --num_learners 2 --num_runners 2 '\n",
    "        f'--update_timesteps 1_000_000 '\n",
    "        f'--max_timesteps 800_000_000 '\n",
    "        # f'--update_timesteps 100_000 '\n",
    "        # f'--max_timesteps 100_000_000 '\n",
    "        f'--dont_sync_across_nodes '\n",
    "        f'--logfile s3://{bucket_name}/logs/{experiment_name}.log '\n",
    "        f'--flush_iterations 1 '\n",
    "        # f'--checkpoint s3://nkalafut-celltrip/checkpoints/MERFISH_Bench-250805-2-0800.weights '\n",
    "        f'--checkpoint_iterations 100 '\n",
    "        f'--checkpoint_dir s3://{bucket_name}/checkpoints '\n",
    "        f'--checkpoint_name {experiment_name}')\n",
    "    config = parser.parse_args(shlex.split(command))\n",
    "    print(f'python train.py {command}')\n",
    "    \n",
    "# Defaults\n",
    "if config.checkpoint_name is None:\n",
    "    config.checkpoint_name = f'RUN_{random.randint(0, 2**32):0>10}'\n",
    "    print(f'Run Name: {config.checkpoint_name}')\n",
    "# print(config)  # CLI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ray\n",
    "ray.shutdown()\n",
    "a = ray.init(\n",
    "    # address='ray://100.85.187.118:10001',\n",
    "    address='ray://localhost:10001',\n",
    "    runtime_env={\n",
    "        'py_modules': [celltrip],\n",
    "        'pip': '../requirements.txt',\n",
    "        'env_vars': {\n",
    "            # **access_keys,\n",
    "            'RAY_DEDUP_LOGS': '0'}},\n",
    "        # 'NCCL_SOCKET_IFNAME': 'tailscale',  # lo,en,wls,docker,tailscale\n",
    "    _system_config={'enable_worker_prestart': True})  # Doesn't really work for scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1e-4)\n",
    "def train(config):\n",
    "    import celltrip\n",
    "\n",
    "    # Initialization\n",
    "    dataloader_kwargs = {\n",
    "        'num_nodes': [2**9, 2**11], 'mask': config.train_split,\n",
    "        'mask_partitions': config.train_partitions}  # {'num_nodes': 20, 'pca_dim': 128}\n",
    "    environment_kwargs = {\n",
    "        'input_modalities': config.input_modalities,\n",
    "        'target_modalities': config.target_modalities, 'dim': config.dim,\n",
    "        'discrete': config.discrete}  # , 'spherical': config.discrete\n",
    "    policy_kwargs = {'discrete': config.discrete}\n",
    "    memory_kwargs = {'device': 'cuda:0'}\n",
    "    initializers = celltrip.train.get_initializers(\n",
    "        input_files=config.input_files, merge_files=config.merge_files,\n",
    "        backed=config.backed, partition_cols=config.partition_cols,\n",
    "        dataloader_kwargs=dataloader_kwargs,\n",
    "        environment_kwargs=environment_kwargs,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        memory_kwargs=memory_kwargs)  # Skips casting, cutting time significantly for relatively small batch sizes\n",
    "\n",
    "    # Stages\n",
    "    stage_functions = [\n",
    "        # lambda w: w.env.set_delta(.1),\n",
    "        # lambda w: w.env.set_delta(.05),\n",
    "        # lambda w: w.env.set_delta(.01),\n",
    "        # lambda w: w.env.set_delta(.005),\n",
    "    ]\n",
    "\n",
    "    # Run function\n",
    "    celltrip.train.train_celltrip(\n",
    "        initializers=initializers,\n",
    "        num_gpus=config.num_gpus, num_learners=config.num_learners,\n",
    "        num_runners=config.num_runners, max_timesteps=config.max_timesteps,\n",
    "        update_timesteps=config.update_timesteps, sync_across_nodes=not config.dont_sync_across_nodes,\n",
    "        flush_iterations=config.flush_iterations,\n",
    "        checkpoint_iterations=config.checkpoint_iterations, checkpoint_dir=config.checkpoint_dir,\n",
    "        checkpoint=config.checkpoint, checkpoint_name=config.checkpoint_name,\n",
    "        stage_functions=stage_functions, logfile=config.logfile)\n",
    "\n",
    "ray.get(train.remote(config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# torch.random.manual_seed(42)\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # Initialize locally\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# config.update_timesteps = 100_000\n",
    "# config.max_timesteps = 20_000_000\n",
    "\n",
    "# dataloader_kwargs = {'num_nodes': [2**9, 2**11], 'mask': config.train_split}  # {'num_nodes': [2**9, 2**11], 'pca_dim': 128}\n",
    "# environment_kwargs = {\n",
    "#     'input_modalities': config.input_modalities,\n",
    "#     'target_modalities': config.target_modalities, 'dim': config.dim}\n",
    "# env_init, policy_init, memory_init = celltrip.train.get_initializers(\n",
    "#     input_files=config.input_files, merge_files=config.merge_files,\n",
    "#     partition_cols=config.partition_cols,\n",
    "#     backed=config.backed, dataloader_kwargs=dataloader_kwargs,\n",
    "#     policy_kwargs={'minibatch_size': 10_000},\n",
    "#     # memory_kwargs={'device': 'cuda:0'},  # Skips casting, cutting time significantly for relatively small batch sizes\n",
    "#     environment_kwargs=environment_kwargs)\n",
    "\n",
    "# # Environment\n",
    "# # os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "# try: env\n",
    "# except: env = env_init().to('cuda')\n",
    "\n",
    "# # Policy\n",
    "# policy = policy_init(env).to('cuda')\n",
    "\n",
    "# # Memory\n",
    "# memory = memory_init(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23.3764, 34.5881, 67.3236,  ..., 28.3253, 24.7067, 43.3550],\n",
      "       device='cuda:0')\n",
      "tensor([23.4403, 34.5967, 67.3538,  ..., 28.3907, 24.7294, 43.4552],\n",
      "       device='cuda:0')\n",
      "tensor([23.3492, 34.6029, 67.5473,  ..., 28.3453, 24.7068, 43.4087],\n",
      "       device='cuda:0')\n",
      "tensor([23.5119, 34.5351, 67.5567,  ..., 28.3330, 24.6583, 43.2891],\n",
      "       device='cuda:0')\n",
      "tensor([23.3925, 34.5835, 67.2903,  ..., 28.4343, 24.7068, 43.4626],\n",
      "       device='cuda:0')\n",
      "tensor([23.4300, 34.5289, 67.3157,  ..., 28.3361, 24.7067, 43.4820],\n",
      "       device='cuda:0')\n",
      "tensor([23.3340, 34.6085, 67.2487,  ..., 28.3315, 24.6761, 43.4621],\n",
      "       device='cuda:0')\n",
      "tensor([23.4502, 34.5984, 67.2822,  ..., 28.4285, 24.7070, 43.3872],\n",
      "       device='cuda:0')\n",
      "tensor([23.4115, 34.6331, 67.4580,  ..., 28.3361, 24.7655, 43.4114],\n",
      "       device='cuda:0')\n",
      "tensor([23.3178, 34.5520, 67.2211,  ..., 28.3614, 24.7184, 43.6287],\n",
      "       device='cuda:0')\n",
      "tensor([23.3612, 34.5404, 67.1771,  ..., 28.3285, 24.6666, 43.5539],\n",
      "       device='cuda:0')\n",
      "tensor([23.3785, 34.6030, 67.3038,  ..., 28.3117, 24.7029, 43.5596],\n",
      "       device='cuda:0')\n",
      "tensor([23.4096, 34.5185, 67.4852,  ..., 28.3927, 24.7614, 43.4811],\n",
      "       device='cuda:0')\n",
      "tensor([23.4419, 34.5967, 67.5828,  ..., 28.3888, 24.7595, 43.4137],\n",
      "       device='cuda:0')\n",
      "tensor([23.4029, 34.5620, 67.6251,  ..., 28.3293, 24.7138, 43.6712],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23.4561, 34.5837, 67.3328,  ..., 28.3716, 24.7132, 43.3648],\n",
      "       device='cuda:0')\n",
      "tensor([23.3126, 34.5459, 67.5058,  ..., 28.3377, 24.6027, 43.6120],\n",
      "       device='cuda:0')\n",
      "tensor([23.3556, 34.5437, 67.4349,  ..., 28.3498, 24.6632, 43.3484],\n",
      "       device='cuda:0')\n",
      "tensor([23.3647, 34.5711, 67.4977,  ..., 28.3324, 24.7125, 43.5646],\n",
      "       device='cuda:0')\n",
      "tensor([23.3789, 34.5903, 67.4968,  ..., 28.3450, 24.5565, 43.3904],\n",
      "       device='cuda:0')\n",
      "tensor([23.3890, 34.6002, 67.3328,  ..., 28.3406, 24.6291, 43.4824],\n",
      "       device='cuda:0')\n",
      "tensor([23.3859, 34.5525, 67.4654,  ..., 28.3473, 24.6278, 43.4824],\n",
      "       device='cuda:0')\n",
      "tensor([23.4802, 34.5198, 67.4215,  ..., 28.3514, 24.6294, 43.4554],\n",
      "       device='cuda:0')\n",
      "tensor([23.4312, 34.5192, 67.7230,  ..., 28.3354, 24.5486, 43.7063],\n",
      "       device='cuda:0')\n",
      "tensor([23.4369, 34.6252, 67.7474,  ..., 28.3750, 24.6333, 43.5159],\n",
      "       device='cuda:0')\n",
      "tensor([23.5438, 34.5236, 67.5900,  ..., 28.3349, 24.5526, 43.4814],\n",
      "       device='cuda:0')\n",
      "tensor([23.3752, 34.4906, 67.4103,  ..., 28.3284, 24.6881, 43.6243],\n",
      "       device='cuda:0')\n",
      "tensor([23.4327, 34.5650, 67.5483,  ..., 28.3447, 24.6288, 43.5261],\n",
      "       device='cuda:0')\n",
      "tensor([23.3863, 34.4417, 67.4022,  ..., 28.2919, 24.6487, 43.3618],\n",
      "       device='cuda:0')\n",
      "tensor([23.3233, 34.5799, 67.4938,  ..., 28.3518, 24.7052, 43.4329],\n",
      "       device='cuda:0')\n",
      "tensor([23.3340, 34.5246, 67.4385,  ..., 28.3257, 24.6800, 43.4471],\n",
      "       device='cuda:0')\n",
      "tensor([23.3336, 34.5456, 67.5042,  ..., 28.2682, 24.6794, 43.3819],\n",
      "       device='cuda:0')\n",
      "tensor([23.4182, 34.5267, 67.5036,  ..., 28.3699, 24.7011, 43.4999],\n",
      "       device='cuda:0')\n",
      "tensor([23.4403, 34.4859, 67.6200,  ..., 28.3337, 24.5358, 43.5077],\n",
      "       device='cuda:0')\n",
      "tensor([23.4563, 34.5318, 67.5562,  ..., 28.3769, 24.6380, 43.6197],\n",
      "       device='cuda:0')\n",
      "tensor([23.3775, 34.5451, 67.4103,  ..., 28.3668, 24.6777, 43.4857],\n",
      "       device='cuda:0')\n",
      "tensor([23.3604, 34.5713, 67.4189,  ..., 28.3489, 24.7038, 43.7696],\n",
      "       device='cuda:0')\n",
      "tensor([23.4209, 34.5527, 67.4121,  ..., 28.3977, 24.6384, 43.5471],\n",
      "       device='cuda:0')\n",
      "tensor([23.4360, 34.5738, 67.6024,  ..., 28.3289, 24.6402, 43.2616],\n",
      "       device='cuda:0')\n",
      "tensor([23.5622, 34.5671, 67.3224,  ..., 28.3338, 24.5664, 43.5905],\n",
      "       device='cuda:0')\n",
      "tensor([23.5240, 34.5734, 67.6199,  ..., 28.3880, 24.5813, 43.5294],\n",
      "       device='cuda:0')\n",
      "tensor([23.3942, 34.5142, 67.3969,  ..., 28.3898, 24.6309, 43.6442],\n",
      "       device='cuda:0')\n",
      "tensor([23.3994, 34.4678, 67.3741,  ..., 28.4160, 24.6325, 43.4137],\n",
      "       device='cuda:0')\n",
      "tensor([23.4721, 34.5778, 67.2928,  ..., 28.3650, 24.5511, 43.4716],\n",
      "       device='cuda:0')\n",
      "tensor([23.3232, 34.4694, 67.4219,  ..., 28.3179, 24.6319, 43.6442],\n",
      "       device='cuda:0')\n",
      "tensor([23.4147, 34.5973, 67.5916,  ..., 28.3553, 24.6242, 43.5588],\n",
      "       device='cuda:0')\n",
      "tensor([23.4610, 34.5375, 67.5323,  ..., 28.3319, 24.6362, 43.2983],\n",
      "       device='cuda:0')\n",
      "tensor([23.3312, 34.5737, 67.8591,  ..., 28.2693, 24.7145, 43.6255],\n",
      "       device='cuda:0')\n",
      "tensor([23.3533, 34.5534, 67.5404,  ..., 28.3460, 24.6530, 43.3469],\n",
      "       device='cuda:0')\n",
      "tensor([23.5118, 34.4970, 67.3973,  ..., 28.3519, 24.6129, 43.5294],\n",
      "       device='cuda:0')\n",
      "tensor([23.2937, 34.5636, 67.6312,  ..., 28.3502, 24.6360, 43.5708],\n",
      "       device='cuda:0')\n",
      "tensor([23.5455, 34.5101, 67.3274,  ..., 28.3172, 24.7138, 43.5847],\n",
      "       device='cuda:0')\n",
      "ROLLOUT: total: -2.139, distance: 0.000, pinning: -0.148, origin: 0.000, bound: 0.000, velocity: -1.915, action: -0.077\n",
      "Timer unit: 1 s\n",
      "\n",
      "Total time: 0.197983 s\n",
      "File: /home/thema/repos/inept/celltrip/environment.py\n",
      "Function: step at line 216\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   216                                               def step(self, actions=None, *, delta=None, pinning_func_list=None, return_itemized_rewards=False):\n",
      "   217                                                   # Defaults\n",
      "   218        51          0.0      0.0      0.0          if actions is None: actions = torch.zeros_like(self.vel, device=self.device)\n",
      "   219        51          0.0      0.0      0.0          if delta is None: delta = self.delta\n",
      "   220                                           \n",
      "   221                                                   # Check dimensions\n",
      "   222                                                   # assert actions.shape == self.vel.shape\n",
      "   223                                           \n",
      "   224                                                   # Hypersphere or hypercube constraints\n",
      "   225                                                   # NOTE: Hypersphere is technically more correct, but also harder on the model\n",
      "   226                                           \n",
      "   227                                                   ### Pre-step calculations\n",
      "   228        51          0.0      0.0      0.0          if self.compute_rewards:\n",
      "   229                                                       # Distance reward (Emulate combined intra-modal distances)\n",
      "   230        51          0.0      0.0      0.0              get_reward_distance = lambda: self.get_distance_match(use_cache=True)\n",
      "   231                                                       # get_reward_distance = lambda: (self.get_distance_match()+self.epsilon).log().mean(dim=-1)\n",
      "   232                                                       # get_reward_distance = lambda: 1 / (1+self.get_distance_match())\n",
      "   233        51          0.0      0.0      0.0              if self.reward_scales['reward_distance'] != 0:\n",
      "   234                                                           reward_distance = get_reward_distance()\n",
      "   235                                                           # reward_distance = 0\n",
      "   236        51          0.0      0.0      0.7              else: reward_distance = torch.zeros(actions.shape[0], device=self.device)\n",
      "   237                                                       # Pinning reward\n",
      "   238        51          0.0      0.0      0.0              get_reward_pinning = lambda: self.get_pinning(use_cache=True, pinning_func_list=pinning_func_list)\n",
      "   239                                                       # get_reward_pinning = lambda: (self.get_pinning(use_cache=True)+self.epsilon).log().mean(dim=-1)\n",
      "   240        51          0.0      0.0      0.0              if self.reward_scales['reward_pinning'] != 0:\n",
      "   241        51          0.0      0.0     15.1                  reward_pinning = get_reward_pinning()\n",
      "   242                                                       else: reward_pinning = torch.zeros(actions.shape[0], device=self.device)\n",
      "   243                                                       # Origin penalty\n",
      "   244        51          0.0      0.0      0.0              get_reward_origin = lambda: self.get_distance_from_origin()\n",
      "   245                                                       # get_reward_origin = lambda: (self.get_distance_from_origin()+self.epsilon).log()\n",
      "   246        51          0.0      0.0      0.0              if self.reward_scales['reward_origin'] != 0:\n",
      "   247                                                           reward_origin = get_reward_origin()\n",
      "   248                                                           # reward_origin = 0\n",
      "   249        51          0.0      0.0      0.5              else: reward_origin = torch.zeros(actions.shape[0], device=self.device)\n",
      "   250                                                       # Velocity penalty\n",
      "   251        51          0.0      0.0      0.0              if self.spherical:\n",
      "   252                                                           get_penalty_velocity = lambda: self.vel.norm(dim=-1)\n",
      "   253                                                           # get_penalty_velocity = lambda: (self.vel.norm(dim=-1)+self.epsilon).log()\n",
      "   254                                                       else:\n",
      "   255        51          0.0      0.0      0.0                  get_penalty_velocity = lambda: self.vel.square().mean(dim=-1)\n",
      "   256                                                           # get_penalty_velocity = lambda: (self.vel.square().mean(dim=-1)+self.epsilon).log()\n",
      "   257                                                           # get_penalty_velocity = lambda: self.vel.mean(dim=-1)\n",
      "   258        51          0.0      0.0      0.0              if self.reward_scales['penalty_velocity'] != 0:\n",
      "   259                                                           # penalty_velocity = get_penalty_velocity()\n",
      "   260        51          0.0      0.0      0.0                  penalty_velocity = 0\n",
      "   261                                                       else: penalty_velocity = torch.zeros(actions.shape[0], device=self.device)\n",
      "   262                                           \n",
      "   263                                                   ### Step positions\n",
      "   264                                                   # Old storage\n",
      "   265                                                   # old_vel = self.vel.clone()\n",
      "   266                                                   # old_bound_hit_mask = self.pos.abs() == self.pos_bound\n",
      "   267                                                   # Clamp actions\n",
      "   268                                                   # actions = actions.clamp(-self.force_bound, self.force_bound)\n",
      "   269                                                   # Convert actions to velocity\n",
      "   270                                                   # NOTE: It would be nice to use polar here, but couldn't find a general method which didn't require unreasonable precision for later axes\n",
      "   271                                                   # magnitude = (.5*actions[..., [-1]]+.5).clamp(0, self.force_bound)\n",
      "   272                                                   # direction = actions[..., :-1] / actions[..., :-1].norm(keepdim=True, dim=-1)\n",
      "   273                                                   # force = magnitude * direction\n",
      "   274        51          0.0      0.0      0.0          if self.discrete:\n",
      "   275                                                       force = self.discrete_force * (actions - 1)\n",
      "   276                                                       if self.spherical:\n",
      "   277                                                           force_norm = force.norm(keepdim=True, dim=-1)\n",
      "   278                                                           force_norm[force_norm==0] = 1\n",
      "   279                                                           force = self.discrete_force * force / force_norm\n",
      "   280        51          0.0      0.0      0.0          else: force = actions\n",
      "   281        51          0.0      0.0      0.0          if self.spherical:\n",
      "   282                                                       force_norm = force.norm(keepdim=True, dim=-1)\n",
      "   283                                                       strong_mask = force_norm.squeeze(-1) > self.force_bound\n",
      "   284                                                       force[strong_mask] = self.force_bound * force[strong_mask] / force_norm[strong_mask]\n",
      "   285                                                   else:\n",
      "   286        51          0.0      0.0      4.2              force = force.clamp(-self.force_bound, self.force_bound)\n",
      "   287                                                   # Add velocity and apply friction\n",
      "   288        51          0.0      0.0      1.2          self.add_velocities(delta * force)\n",
      "   289        51          0.0      0.0      1.8          self.apply_friction(realized_force=delta*self.friction_force)\n",
      "   290                                                   # Iterate positions\n",
      "   291        51          0.0      0.0      0.6          self.pos = self.pos + delta * self.vel  # .square()  # TODO: Experimental square\n",
      "   292                                                   # Clip by bounds\n",
      "   293                                                   # self.pos = torch.clamp(self.pos, -self.pos_bound, self.pos_bound)\n",
      "   294                                                   # Adjust nodes on bound-hits\n",
      "   295                                                   # bound_hit_mask = self.pos.abs() == self.pos_bound\n",
      "   296                                                   # self.pos[bound_hit_mask.sum(dim=1) > 0] = 0  # Send to center\n",
      "   297                                                   # self.vel[bound_hit_mask] = 0  # Kill velocity\n",
      "   298                                                   # self.vel[bound_hit_mask] = -self.vel[bound_hit_mask]  # Bounce\n",
      "   299                                                   # Out of bounds\n",
      "   300        51          0.0      0.0      0.0          if self.spherical: oob = self.pos.norm(dim=-1)-self.pos_bound\n",
      "   301        51          0.0      0.0      1.4          else: oob = (self.pos.abs() >= self.pos_bound).sum(dim=-1)\n",
      "   302                                                   # oob[oob < 0] = 0\n",
      "   303        51          0.0      0.0      1.1          self.vel[oob > 0] = 0\n",
      "   304        51          0.0      0.0      0.0          if self.spherical:\n",
      "   305                                                       self.pos[oob > 0] = self.pos_bound * self.pos[oob > 0] / self.pos[oob > 0].norm(keepdim=True, dim=-1)\n",
      "   306        51          0.0      0.0      0.4          else: self.pos = self.pos.clamp(-self.pos_bound, self.pos_bound)\n",
      "   307                                                   # reward_distance[oob > 0] = 0\n",
      "   308                                                   # Reset cache\n",
      "   309        51          0.0      0.0      0.1          self.reset_cache()\n",
      "   310                                           \n",
      "   311                                                   ### Post-step calculations\n",
      "   312                                                   # Finished\n",
      "   313        51          0.0      0.0      0.0          self.time += delta\n",
      "   314        51          0.0      0.0      0.0          finished, _ = self.finished()\n",
      "   315        51          0.0      0.0      0.0          if self.compute_rewards:\n",
      "   316                                                       # Distance reward\n",
      "   317        51          0.0      0.0      0.0              if self.reward_scales['reward_distance'] != 0: reward_distance -= get_reward_distance()\n",
      "   318                                                       # Pinning reward\n",
      "   319        51          0.1      0.0     25.7              if self.reward_scales['reward_pinning'] != 0: reward_pinning -= get_reward_pinning()\n",
      "   320                                                       # Origin reward\n",
      "   321        51          0.0      0.0      0.0              if self.reward_scales['reward_origin'] != 0: reward_origin -= get_reward_origin()\n",
      "   322                                                       # Velocity penalty (Apply to ending velocity)\n",
      "   323        51          0.0      0.0      1.4              if self.reward_scales['penalty_velocity'] != 0: penalty_velocity -= get_penalty_velocity()\n",
      "   324                                                       # Boundary penalty\n",
      "   325        51          0.0      0.0      0.5              penalty_bound = torch.zeros(self.pos.shape[0], device=self.device)\n",
      "   326        51          0.0      0.0      0.8              penalty_bound[oob > 0] = -1\n",
      "   327                                                       # Action penalty (Smooth movements)\n",
      "   328                                                       # NOTE: Calculated on unclipped forces\n",
      "   329        51          0.0      0.0      0.0              if self.spherical:\n",
      "   330                                                           # penalty_action = -force_norm.squeeze(-1).square()  # WRONG\n",
      "   331                                                           penalty_action = -force.norm(dim=-1)\n",
      "   332        51          0.0      0.0      0.9              else: penalty_action = -actions.square().mean(dim=-1)\n",
      "   333                                           \n",
      "   334                                                       ### Management\n",
      "   335        51          0.1      0.0     35.1              if self.get_distance_match().mean() < self.best: self.lapses += delta\n",
      "   336        51          0.0      0.0      6.3              else: self.best = self.get_distance_match().mean(); self.lapses = 0\n",
      "   337                                           \n",
      "   338        51          0.0      0.0      0.3              reward_distance     *=  self.reward_scales['reward_distance']    * 1e-1/delta\n",
      "   339        51          0.0      0.0      0.2              reward_pinning      *=  self.reward_scales['reward_pinning']     * 1e0/delta\n",
      "   340        51          0.0      0.0      0.2              reward_origin       *=  self.reward_scales['reward_origin']      * 1e-1/delta\n",
      "   341        51          0.0      0.0      0.2              penalty_bound       *=  self.reward_scales['penalty_bound']      * 1e0\n",
      "   342        51          0.0      0.0      0.2              penalty_velocity    *=  self.reward_scales['penalty_velocity']   * 1e-2/delta\n",
      "   343        51          0.0      0.0      0.2              penalty_action      *=  self.reward_scales['penalty_action']     * 1e-3\n",
      "   344                                                       # self.steps += 1\n",
      "   345                                                   else:\n",
      "   346                                                       placeholder = torch.zeros(self.num_nodes, device=self.device)\n",
      "   347                                                       reward_distance = placeholder\n",
      "   348                                                       reward_pinning = placeholder\n",
      "   349                                                       reward_origin = placeholder\n",
      "   350                                                       penalty_bound = placeholder\n",
      "   351                                                       penalty_velocity = placeholder\n",
      "   352                                                       penalty_action = placeholder\n",
      "   353                                           \n",
      "   354                                                   # Compute total reward\n",
      "   355        51          0.0      0.0      0.0          rwd = (\n",
      "   356       306          0.0      0.0      0.9              reward_distance\n",
      "   357        51          0.0      0.0      0.0              + reward_pinning\n",
      "   358        51          0.0      0.0      0.0              + reward_origin\n",
      "   359        51          0.0      0.0      0.0              + penalty_bound\n",
      "   360        51          0.0      0.0      0.0              + penalty_velocity\n",
      "   361        51          0.0      0.0      0.0              + penalty_action)\n",
      "   362                                           \n",
      "   363        51          0.0      0.0      0.0          ret = (rwd, finished)\n",
      "   364       102          0.0      0.0      0.0          if return_itemized_rewards: ret += {\n",
      "   365        51          0.0      0.0      0.0              'distance': reward_distance,\n",
      "   366        51          0.0      0.0      0.0              'pinning': reward_pinning,\n",
      "   367        51          0.0      0.0      0.0              'origin': reward_origin,\n",
      "   368        51          0.0      0.0      0.0              'bound': penalty_bound,\n",
      "   369        51          0.0      0.0      0.0              'velocity': penalty_velocity,\n",
      "   370        51          0.0      0.0      0.0              'action': penalty_action},\n",
      "   371        51          0.0      0.0      0.0          return ret\n",
      "\n",
      "Total time: 0 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: forward at line 168\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   168                                               def forward(self, x, kv=None, mask=None):\n",
      "   169                                                   # Parameters\n",
      "   170                                                   x1 = x\n",
      "   171                                                   layer_norm_idx = 0\n",
      "   172                                           \n",
      "   173                                                   # Apply residual self attention\n",
      "   174                                                   x2 = self.layer_norms[layer_norm_idx](x1)\n",
      "   175                                                   # x2 = x1\n",
      "   176                                                   layer_norm_idx += 1\n",
      "   177                                                   if kv is None: kv = x2\n",
      "   178                                                   x3, _ = self.attention(x2, kv, kv, attn_mask=mask)\n",
      "   179                                                   x1 = x1 + x3\n",
      "   180                                           \n",
      "   181                                                   # Apply residual mlps\n",
      "   182                                                   for mlp in self.mlps:\n",
      "   183                                                       x2 = self.layer_norms[layer_norm_idx](x1)\n",
      "   184                                                       # x2 = x1\n",
      "   185                                                       layer_norm_idx += 1\n",
      "   186                                                       x3 = mlp(x2)\n",
      "   187                                                       x1 = x1 + x3\n",
      "   188                                           \n",
      "   189                                                   # Final layer norm\n",
      "   190                                                   xf = self.layer_norms[layer_norm_idx](x1)\n",
      "   191                                                   # xf = x1\n",
      "   192                                           \n",
      "   193                                                   return xf\n",
      "\n",
      "Total time: 0.316722 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: forward at line 510\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   510                                               def forward(\n",
      "   511                                                       self, self_entities, node_entities=None, mask=None,\n",
      "   512                                                       actor=True, action=None, entropy=False, critic=False,\n",
      "   513                                                       feature_embeds=None, return_feature_embeds=False,\n",
      "   514                                                       squeeze=True, fit_and_strip=True):\n",
      "   515                                                   # Formatting\n",
      "   516        52          0.0      0.0      0.0          if node_entities is None: node_entities = self_entities\n",
      "   517        52          0.0      0.0      0.0          if mask is None:\n",
      "   518        52          0.0      0.0      0.9              mask = torch.eye(self_entities.shape[-2], dtype=torch.bool, device=self_entities.device)\n",
      "   519        52          0.0      0.0      0.0              if self_entities.dim() > 2: mask = mask.repeat((self_entities.shape[0], 1, 1))\n",
      "   520                                           \n",
      "   521                                                   # Workaround for https://github.com/pytorch/pytorch/issues/41508\n",
      "   522                                                   # Essentially, totally masked entries in attn_mask will cause NAN on backprop\n",
      "   523                                                   # regardless of if they're even considered in loss, so, we allow masked entries\n",
      "   524                                                   # to attend to themselves\n",
      "   525        52          0.0      0.0      2.0          include_mask = mask.sum(dim=-1) < mask.shape[-1]\n",
      "   526        52          0.0      0.0      7.7          mask[~include_mask, torch.argwhere(~include_mask)[:, -1]] = False\n",
      "   527                                                   \n",
      "   528                                                   # More formatting\n",
      "   529        52          0.0      0.0      0.0          if self_entities.dim() > 2:\n",
      "   530                                                       # NOTE: Grouped batches (i.e. (>1, >1, ...) shape) are possible with squeeze=False\n",
      "   531                                                       if mask.dim() < 3: mask.unsqueeze(0)\n",
      "   532                                                       # mask = mask.repeat((self.heads, 1, 1))\n",
      "   533                                                       mask = mask[[i for i in range(mask.shape[0]) for _ in range(self.heads)]]\n",
      "   534        52          0.0      0.0      0.0          if feature_embeds is not None:\n",
      "   535                                                       feature_embeds_ret = feature_embeds\n",
      "   536                                                       feature_embeds = feature_embeds.copy()\n",
      "   537        52          0.0      0.0      0.0          else: feature_embeds_ret = []\n",
      "   538                                           \n",
      "   539                                                   # Actor block\n",
      "   540        52          0.0      0.0      0.0          if actor or not self.independent_critic:\n",
      "   541                                                       # Positional embedding\n",
      "   542        52          0.0      0.0      4.2              self_pos_embeds = self.self_pos_embed(self_entities[..., :self.positional_dim])\n",
      "   543        52          0.0      0.0      0.7              node_pos_embeds = self.node_pos_embed(node_entities[..., :self.positional_dim])\n",
      "   544                                                       # Feature embedding\n",
      "   545        52          0.0      0.0      0.0              if feature_embeds is not None: self_feat_embeds, node_feat_embeds = feature_embeds.pop(0)\n",
      "   546                                                       else:\n",
      "   547        52          0.0      0.0      1.1                  self_feat_embeds = self.self_feat_embed(self_entities[..., self.positional_dim:])\n",
      "   548        52          0.0      0.0      0.7                  node_feat_embeds = self.node_feat_embed(node_entities[..., self.positional_dim:])\n",
      "   549        52          0.0      0.0      0.0                  feature_embeds_ret.append((self_feat_embeds, node_feat_embeds))\n",
      "   550                                                       # Self embeddings\n",
      "   551        52          0.0      0.0      7.9              self_embeds = self.self_embed(self_pos_embeds+self_feat_embeds)\n",
      "   552                                                       # self_embeds = self.self_embed(self_pos_embeds)\n",
      "   553                                                       # Node embeddings\n",
      "   554        52          0.0      0.0      5.4              node_embeds = self.node_embed(node_pos_embeds+node_feat_embeds)\n",
      "   555                                                       # node_embeds = self.self_embed(node_pos_embeds)\n",
      "   556                                                       # Attention\n",
      "   557       104          0.0      0.0      0.1              for block in self.residual_attention_blocks:\n",
      "   558        52          0.1      0.0     17.1                  self_embeds = block(self_embeds, kv=node_embeds, mask=mask)\n",
      "   559        52          0.0      0.0      0.0              actor_self_embeds = self_embeds\n",
      "   560                                           \n",
      "   561                                                   # Critic block\n",
      "   562        52          0.0      0.0      0.0          if self.independent_critic and critic:\n",
      "   563                                                       # Positional embedding\n",
      "   564                                                       self_pos_embeds = self.critic_self_pos_embed(self_entities[..., :self.positional_dim])\n",
      "   565                                                       node_pos_embeds = self.critic_node_pos_embed(node_entities[..., :self.positional_dim])\n",
      "   566                                                       # Feature embedding\n",
      "   567                                                       if feature_embeds is not None: self_feat_embeds, node_feat_embeds = feature_embeds.pop(0)\n",
      "   568                                                       else:\n",
      "   569                                                           self_feat_embeds = self.critic_self_feat_embed(self_entities[..., self.positional_dim:])\n",
      "   570                                                           node_feat_embeds = self.critic_node_feat_embed(node_entities[..., self.positional_dim:])\n",
      "   571                                                           feature_embeds_ret.append((self_feat_embeds, node_feat_embeds))\n",
      "   572                                                       # Self embeddings\n",
      "   573                                                       self_embeds = self.critic_self_embed(self_pos_embeds+self_feat_embeds)\n",
      "   574                                                       # Node embeddings\n",
      "   575                                                       node_embeds = self.critic_node_embed(node_pos_embeds+node_feat_embeds)\n",
      "   576                                                       # Attention\n",
      "   577                                                       for block in self.critic_residual_attention_blocks:\n",
      "   578                                                           self_embeds = block(self_embeds, kv=node_embeds, mask=mask)\n",
      "   579                                                       critic_self_embeds = self_embeds\n",
      "   580        52          0.0      0.0      0.0          else: critic_self_embeds = actor_self_embeds\n",
      "   581                                           \n",
      "   582                                                   # NOTE: fit_and_strip breaks compatibility on batch-batch native programs (Grouped batches)\n",
      "   583        52          0.0      0.0      0.0          if fit_and_strip and self_entities.dim() > 2:\n",
      "   584                                                       # Strip padded entries with workaround\n",
      "   585                                                       if actor: actor_self_embeds = actor_self_embeds[include_mask]\n",
      "   586                                                       if critic: critic_self_embeds = critic_self_embeds[include_mask]\n",
      "   587                                                       # # Strip padded entries\n",
      "   588                                                       # actor_self_embeds = actor_self_embeds[~actor_self_embeds.sum(dim=-1).isnan()]\n",
      "   589                                                       # if critic: critic_self_embeds = critic_self_embeds[~critic_self_embeds.sum(dim=-1).isnan()]\n",
      "   590                                           \n",
      "   591                                                   # Decisions, samples, and returns\n",
      "   592        52          0.0      0.0      0.0          ret = ()\n",
      "   593        52          0.0      0.0      0.0          if actor:  # action_means\n",
      "   594                                                       # Dot Method\n",
      "   595                                                       # self_action_embeds = self.actor_decider(actor_self_embeds)\n",
      "   596                                                       # action_embeds = self.action_embed(self.actions)\n",
      "   597                                                       # # Norms\n",
      "   598                                                       # # NOTE: Norm causes NAN, could use eps but might as well remove to avoid vanish\n",
      "   599                                                       # self_action_embeds = self_action_embeds  / (self_action_embeds.norm(p=2, keepdim=True, dim=-1) + 1e-8)\n",
      "   600                                                       # action_embeds = action_embeds   / (action_embeds.norm(p=2, keepdim=True, dim=-1) + 1e-8)\n",
      "   601                                                       # # Dot/cosine\n",
      "   602                                                       # if self_action_embeds.dim() > 2:\n",
      "   603                                                       #     action_means = torch.einsum('bik,jk->bij', self_action_embeds, action_embeds)\n",
      "   604                                                       # else: action_means = torch.einsum('ik,jk->ij', self_action_embeds, action_embeds)\n",
      "   605                                           \n",
      "   606                                                       # Regular method\n",
      "   607        51          0.2      0.0     49.7              ret += self.actor_decider(actor_self_embeds, action=action, return_entropy=entropy)  # action, action_log, dist_entropy\n",
      "   608                                                       \n",
      "   609                                                       # Magnitude method\n",
      "   610                                                       # action_direction = self.actor_decider_direction(actor_self_embeds)\n",
      "   611                                                       # action_direction = action_direction / action_direction.norm(keepdim=True, dim=-1)  # Get direction unit\n",
      "   612                                                       # action_magnitude = self.actor_decider_magnitude(actor_self_embeds)\n",
      "   613                                                       # action_means = action_magnitude * action_direction\n",
      "   614                                                       # # action_direction = np.sqrt(action_direction.shape[-1]) * action_direction / action_direction.std(keepdim=True, dim=-1)  # Get into comparable range for sampling\n",
      "   615                                                       # # action_means = torch.concat((action_direction, action_magnitude), dim=-1)\n",
      "   616        52          0.0      0.0      2.2          if critic: ret += (self.critic_decider(critic_self_embeds).squeeze(-1),)  # state_vals\n",
      "   617        52          0.0      0.0      0.0          if squeeze and self_entities.dim() > 2 and not fit_and_strip:\n",
      "   618                                                       ret = tuple(t.flatten(0, 1) for t in ret)\n",
      "   619        52          0.0      0.0      0.0          if return_feature_embeds: ret += feature_embeds_ret,\n",
      "   620        52          0.0      0.0      0.0          return ret\n",
      "\n",
      "Total time: 0.433715 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: forward at line 1307\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1307                                               def forward(\n",
      "  1308                                                   self, compressed_state, *,\n",
      "  1309                                                   keys=None, memory=None, forward_batch_size=None, terminal=False,\n",
      "  1310                                                   feature_embeds=None, return_feature_embeds=False):\n",
      "  1311                                                   # NOTE: `feature_embeds` will not re-randomize vision if applicable to `split_state` (i.e. do not use non-lite model with vision culling and feature embed caching)\n",
      "  1312                                                   # Data Checks\n",
      "  1313        52          0.0      0.0      0.0          assert compressed_state.shape[0] > 0, 'Empty state matrix passed'\n",
      "  1314        52          0.0      0.0      0.0          if keys is not None: assert len(keys) == compressed_state.shape[0], (\n",
      "  1315                                                       f'Length of keys vector must equal state dimension 0 ({compressed_state.shape[0]}), '\n",
      "  1316                                                       f'got {len(keys)} instead.'\n",
      "  1317                                                   )\n",
      "  1318                                                       \n",
      "  1319                                                   # Defaults\n",
      "  1320        52          0.0      0.0      0.0          if forward_batch_size is None: forward_batch_size = self.forward_batch_size\n",
      "  1321        52          0.0      0.0      0.0          feature_embeds_arg = feature_embeds\n",
      "  1322        52          0.0      0.0      0.0          construct_feature_embeds = feature_embeds is None and return_feature_embeds\n",
      "  1323                                           \n",
      "  1324                                                   # Act\n",
      "  1325        52          0.0      0.0      0.2          action = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1326        52          0.0      0.0      0.1          action_log = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1327        52          0.0      0.0      0.1          state_val = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1328       104          0.0      0.0      0.0          for start_idx in range(0, compressed_state.shape[0], forward_batch_size):\n",
      "  1329        52          0.0      0.0      0.1              self_idx = np.arange(start_idx, min(start_idx+forward_batch_size, compressed_state.shape[0]))\n",
      "  1330       208          0.0      0.0      3.1              state = _utility.processing.split_state(\n",
      "  1331        52          0.0      0.0      1.1                  self.input_standardization.apply(compressed_state),\n",
      "  1332        52          0.0      0.0      0.0                  idx=self_idx,\n",
      "  1333        52          0.0      0.0      0.0                  **self.split_args)\n",
      "  1334        52          0.0      0.0      0.0              feature_embeds_arg_use = [(sfe[self_idx], nfe) for sfe, nfe in feature_embeds_arg] if feature_embeds_arg is not None else None\n",
      "  1335        52          0.0      0.0      0.0              if not terminal:\n",
      "  1336       102          0.3      0.0     73.0                  action_sub, action_log_sub, state_val_sub, feature_embeds_sub = self.actor_critic(\n",
      "  1337        51          0.0      0.0      0.0                      *state, critic=True, feature_embeds=feature_embeds_arg_use, return_feature_embeds=True)\n",
      "  1338        51          0.0      0.0      0.2                  action = torch.concat((action, action_sub), dim=0)\n",
      "  1339        51          0.0      0.0      0.1                  action_log = torch.concat((action_log, action_log_sub), dim=0)\n",
      "  1340         2          0.0      0.0      0.5              else: state_val_sub, feature_embeds_sub = self.actor_critic(\n",
      "  1341         1          0.0      0.0      0.0                  *state, actor=False, critic=True, feature_embeds=feature_embeds_arg_use, return_feature_embeds=True)\n",
      "  1342        52          0.0      0.0      0.1              state_val = torch.concat((state_val, state_val_sub), dim=0)\n",
      "  1343        52          0.0      0.0      0.0              if construct_feature_embeds:\n",
      "  1344                                                           if feature_embeds is None: feature_embeds = feature_embeds_sub\n",
      "  1345                                                           else:\n",
      "  1346                                                               # feature_embeds = [\n",
      "  1347                                                               #     tuple(torch.concat((feature_embeds[i][j], t)) for j, t in enumerate(feat_tensors))\n",
      "  1348                                                               #     for i, feat_tensors in enumerate(feature_embeds_sub)]\n",
      "  1349                                                               for i in range(len(feature_embeds)):\n",
      "  1350                                                                   # NOTE: 0 is the self embeddings, which are the only ones subset in the Lite model\n",
      "  1351                                                                   # feature_embeds[i][0] = torch.concat((feature_embeds[i][0], feature_embeds_sub[i][0]))\n",
      "  1352                                                                   assert (feature_embeds[i][1] == feature_embeds_sub[i][1]).all(), 'Unexpected node embedding changes, make sure no vision culling is occurring.'\n",
      "  1353                                                                   feature_embeds[i] = (torch.concat((feature_embeds[i][0], feature_embeds_sub[i][0])), feature_embeds[i][1])\n",
      "  1354                                           \n",
      "  1355                                                   # Unstandardize state_val\n",
      "  1356        52          0.0      0.0      0.5          state_val = self.return_standardization.remove(state_val)\n",
      "  1357                                                   \n",
      "  1358                                                   # Record\n",
      "  1359                                                   # NOTE: `reward` and `is_terminal` are added outside of the class, calculated\n",
      "  1360                                                   # after stepping the environment\n",
      "  1361        52          0.0      0.0      0.0          if memory is not None and keys is not None:  #  and self.training\n",
      "  1362        52          0.0      0.0      0.0              if not terminal:\n",
      "  1363       102          0.1      0.0     19.5                  memory.record_buffer(\n",
      "  1364        51          0.0      0.0      0.0                      keys=keys,\n",
      "  1365        51          0.0      0.0      0.0                      states=compressed_state,\n",
      "  1366        51          0.0      0.0      0.0                      actions=action,\n",
      "  1367        51          0.0      0.0      0.0                      action_logs=action_log,\n",
      "  1368        51          0.0      0.0      0.0                      state_vals=state_val)\n",
      "  1369                                                       else:\n",
      "  1370         2          0.0      0.0      1.2                  memory.record_buffer(\n",
      "  1371         1          0.0      0.0      0.0                      terminal_states=compressed_state,\n",
      "  1372         1          0.0      0.0      0.0                      terminal_state_vals=state_val)\n",
      "  1373        52          0.0      0.0      0.0          ret = ()\n",
      "  1374        52          0.0      0.0      0.0          if not terminal: ret += action,\n",
      "  1375        52          0.0      0.0      0.0          if return_feature_embeds: ret += feature_embeds,\n",
      "  1376                                                   # print(action)\n",
      "  1377        52          0.0      0.0      0.0          return _utility.general.clean_return(ret)\n",
      "\n",
      "Total time: 0.843815 s\n",
      "File: /home/thema/repos/inept/celltrip/train.py\n",
      "Function: simulate_until_completion at line 20\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    20                                           def simulate_until_completion(\n",
      "    21                                               env, policy, memory=None, keys=None,\n",
      "    22                                               max_timesteps=np.inf, max_memories=np.inf, reset_on_finish=False,\n",
      "    23                                               cache_feature_embeds=False, store_states=False, flush=True,  # CHANGED CACHE TO FALSE FOR TRAINING\n",
      "    24                                               dummy=False, verbose=False):\n",
      "    25                                               # NOTE: Does not flush buffer\n",
      "    26                                               # Params\n",
      "    27         1          0.0      0.0      0.0      assert not (keys is not None and reset_on_finish), 'Cannot manually set keys while `reset_on_finish` is `True`'\n",
      "    28         1          0.0      0.0      0.0      if keys is None: keys = env.get_keys()\n",
      "    29         1          0.0      0.0      0.0      target_modalities = torch.concat(env.get_target_modalities(), dim=-1)\n",
      "    30                                           \n",
      "    31                                               # Store states\n",
      "    32         1          0.0      0.0      0.0      if store_states: state_storage = [env.get_state()]\n",
      "    33                                           \n",
      "    34                                               # Simulation\n",
      "    35         1          0.0      0.0      0.0      ep_timestep = 0; ep_memories = 0; ep_reward = 0; ep_itemized_reward = defaultdict(lambda: 0); finished = False\n",
      "    36         1          0.0      0.0      0.0      feature_embeds = None\n",
      "    37         2          0.0      0.0      0.0      with torch.inference_mode():\n",
      "    38        51          0.0      0.0      0.0          while True:\n",
      "    39                                                       # Get current state\n",
      "    40        51          0.0      0.0      0.3              state = env.get_state(include_modalities=True)\n",
      "    41                                           \n",
      "    42                                                       # Get actions from policy\n",
      "    43       102          0.4      0.0     50.8              actions = policy(\n",
      "    44        51          0.0      0.0      0.0                  state, keys=keys, memory=memory,\n",
      "    45        51          0.0      0.0      0.0                  feature_embeds=feature_embeds, return_feature_embeds=cache_feature_embeds)\n",
      "    46        51          0.0      0.0      0.0              if cache_feature_embeds: actions, feature_embeds = actions\n",
      "    47                                           \n",
      "    48                                                       # Step environment and get reward\n",
      "    49        51          0.2      0.0     23.7              rewards, finished, itemized_rewards = env.step(actions, return_itemized_rewards=True, pinning_func_list=policy.pinning)\n",
      "    50                                           \n",
      "    51                                                       # Store states\n",
      "    52        51          0.0      0.0      0.0              if store_states: state_storage.append(env.get_state())\n",
      "    53                                           \n",
      "    54                                                       # Tracking\n",
      "    55        51          0.1      0.0      6.1              ts_reward = rewards.cpu().mean()\n",
      "    56        51          0.0      0.0      0.0              ep_reward = ep_reward + ts_reward\n",
      "    57       357          0.0      0.0      0.0              for k, v in itemized_rewards.items():\n",
      "    58       306          0.0      0.0      1.0                  ep_itemized_reward[k] += v.cpu().mean()\n",
      "    59        51          0.0      0.0      0.0              ep_timestep += 1\n",
      "    60        51          0.0      0.0      0.0              ep_memories += env.num_nodes\n",
      "    61                                           \n",
      "    62                                                       # Record rewards\n",
      "    63        51          0.0      0.0      0.0              continue_condition = ep_timestep < max_timesteps\n",
      "    64        51          0.0      0.0      0.0              if memory is not None: continue_condition *= ep_memories < max_memories\n",
      "    65       102          0.1      0.0     17.0              if memory is not None: memory.record_buffer(\n",
      "    66        51          0.0      0.0      0.0                  rewards=rewards, target_modalities=target_modalities,\n",
      "    67        51          0.0      0.0      0.0                  is_truncateds=finished or not continue_condition,\n",
      "    68        51          0.0      0.0      0.0                  is_naturals=finished)\n",
      "    69                                           \n",
      "    70                                                       # Dummy return for testing\n",
      "    71                                                       # if dummy:\n",
      "    72                                                       #     if not finished:\n",
      "    73                                                       #         # Fill all but first and last\n",
      "    74                                                       #         ep_timestep = env.max_timesteps\n",
      "    75                                                       #         memory.flush_buffer()\n",
      "    76                                                       #         for _ in range(ep_timestep-2):\n",
      "    77                                                       #             if memory is not None: memory.append_memory({k: v[-1:] for k, v in memory.storage.items()})\n",
      "    78                                                       #             if store_states: state_storage.append(env.get_state)\n",
      "    79                                                       #         memory.storage['is_terminals'][-1] = True\n",
      "    80                                                   \n",
      "    81                                                       # CLI\n",
      "    82        51          0.0      0.0      0.0              if verbose and ((ep_timestep % 200 == 0) or ep_timestep in (100,) or finished):\n",
      "    83                                                           print(f'Timestep {ep_timestep:>4} - Reward {ts_reward:.3f}')\n",
      "    84                                                   \n",
      "    85                                                       # Record terminals and reset if needed\n",
      "    86        51          0.0      0.0      0.0              if finished or not continue_condition:\n",
      "    87         1          0.0      0.0      0.0                  state = env.get_state(include_modalities=True)\n",
      "    88         1          0.0      0.0      0.9                  policy(state, keys=keys, memory=memory, terminal=True, feature_embeds=feature_embeds)\n",
      "    89                                                       # Reset if needed\n",
      "    90        51          0.0      0.0      0.0              if finished:\n",
      "    91                                                           if reset_on_finish:\n",
      "    92                                                               env.reset()\n",
      "    93                                                               keys = env.get_keys()\n",
      "    94                                                               target_modalities = torch.concat(env.get_target_modalities(), dim=-1)\n",
      "    95                                                               feature_embeds = None\n",
      "    96                                                           else: break\n",
      "    97                                                       # Escape\n",
      "    98        51          0.0      0.0      0.0              if not continue_condition: break\n",
      "    99                                           \n",
      "   100                                               # Flush\n",
      "   101         1          0.0      0.0      0.0      if flush and memory: memory.flush_buffer()\n",
      "   102                                           \n",
      "   103                                               # Summarize and return\n",
      "   104         1          0.0      0.0      0.0      denominator = 1  # env.max_timesteps if env.max_timesteps is not None else ep_timestep\n",
      "   105         1          0.0      0.0      0.0      ep_reward = (ep_reward / denominator).item()  # Standard mean\n",
      "   106         1          0.0      0.0      0.0      ep_itemized_reward = {k: (v / denominator).item() for k, v in ep_itemized_reward.items()}\n",
      "   107         1          0.0      0.0      0.0      ret = (ep_timestep, ep_memories, ep_reward, ep_itemized_reward)\n",
      "   108         1          0.0      0.0      0.0      if store_states:\n",
      "   109                                                   state_storage = torch.stack(state_storage)\n",
      "   110                                                   ret += (state_storage,)\n",
      "   111         1          0.0      0.0      0.0      return ret\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Forward\n",
    "# import line_profiler\n",
    "# memory.mark_sampled()\n",
    "# memory.cleanup()\n",
    "# prof = line_profiler.LineProfiler(\n",
    "#     celltrip.train.simulate_until_completion,\n",
    "#     celltrip.policy.PPO.forward,\n",
    "#     celltrip.policy.EntitySelfAttentionLite.forward,\n",
    "#     celltrip.policy.ResidualAttention.forward,\n",
    "#     celltrip.environment.EnvironmentBase.step)\n",
    "# ret = prof.runcall(celltrip.train.simulate_until_completion, env, policy, memory, max_memories=config.update_timesteps, reset_on_finish=True)\n",
    "# print('ROLLOUT: ' + f'total: {ret[2]:.3f}, ' + ', '.join([f'{k}: {v:.3f}' for k, v in ret[3].items()]))\n",
    "# # memory.feed_new(policy.reward_standardization)\n",
    "# memory.compute_advantages()  # moving_standardization=policy.reward_standardization\n",
    "# prof.print_stats(output_unit=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Memory pull\n",
    "# import line_profiler\n",
    "# prof = line_profiler.LineProfiler(\n",
    "#     celltrip.memory.AdvancedMemoryBuffer.__getitem__)\n",
    "# ret = prof.runcall(memory.__getitem__, np.random.choice(len(memory), 10_000, replace=False))\n",
    "# memory.compute_advantages()\n",
    "# prof.print_stats(output_unit=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 01 - Total (1.90447) + PPO (0.44890) + critic (1.46693) + entropy (-11.36146) + KL (3.53687) :: Moving Return Mean (-0.00725), Moving Return STD (1.01281), Return Mean (-0.53739), Return STD (1.62391), Moving Input Mean (0.00435), Moving Input STD (1.04395), Input Mean (0.32519), Input STD (6.75260), Explained Variance (-0.44245)\n",
      "Iteration 05 - Total (1.42196) + PPO (0.48111) + critic (0.95228) + entropy (-11.43396) + KL (3.54111) :: Moving Return Mean (-0.06725), Moving Return STD (1.11182), Return Mean (-0.53801), Return STD (1.62348), Moving Input Mean (0.04051), Moving Input STD (1.20664), Input Mean (0.32304), Input STD (6.75808), Explained Variance (0.07293)\n",
      "UPDATE: Total: 1.562, PPO: 0.447, critic: 1.126, entropy: -11.399, KL: 3.444, Moving Return Mean: -0.038, Moving Return STD: 1.064, Return Mean: -0.538, Return STD: 1.623, Moving Input Mean: 0.023, Moving Input STD: 1.134, Input Mean: 0.324, Input STD: 6.756, Explained Variance: -0.092\n",
      "Timer unit: 1 s\n",
      "\n",
      "Total time: 1.028 s\n",
      "File: /home/thema/repos/inept/celltrip/memory.py\n",
      "Function: __getitem__ at line 197\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   197                                               def __getitem__(self, idx):\n",
      "   198                                                   # Params\n",
      "   199        50          0.0      0.0      0.0          pre_append = True  # Append node features once during concatenation stage then never again\n",
      "   200        50          0.0      0.0      0.0          pre_cast = True  # Cast to tensor once during concatenation stage and never again\n",
      "   201        50          0.0      0.0      0.0          pad_nodes = True  # Pad node array to avoid indexing\n",
      "   202        50          0.0      0.0      0.0          general_storage_keys = ('actions', 'action_logs', 'state_vals', 'advantages', 'propagated_rewards')\n",
      "   203                                               \n",
      "   204                                                   # Pre concatenate vars\n",
      "   205        50          0.0      0.0      0.0          if 'concatenated_buffer' not in self.variable_storage:\n",
      "   206         1          0.0      0.0      0.0              self.variable_storage['concatenated_buffer'] = {}\n",
      "   207                                                       # General case\n",
      "   208         6          0.0      0.0      0.0              for k in general_storage_keys:\n",
      "   209         5          0.0      0.0      0.1                  self.variable_storage['concatenated_buffer'][k] = np.concat(self.storage[k], axis=0)\n",
      "   210                                                       # Get key indices\n",
      "   211         1          0.0      0.0      1.6              self.variable_storage['concatenated_buffer']['keys'] = np.concat(self.storage['keys'])\n",
      "   212         1          0.1      0.1      9.1              unique_keys, new_suffix_idx = np.unique(self.variable_storage['concatenated_buffer']['keys'], return_inverse=True, axis=-1)\n",
      "   213         1          0.0      0.0      0.0              try:\n",
      "   214         3          0.0      0.0      0.4                  self.variable_storage['concatenated_buffer']['suffixes'] = np.stack([\n",
      "   215         2          0.0      0.0      0.0                      self.persistent_storage['suffixes'][k] for k in unique_keys], axis=0)\n",
      "   216                                                       except:\n",
      "   217                                                           print(unique_keys)\n",
      "   218                                                           print(self.persistent_storage.keys())\n",
      "   219                                                           raise RuntimeError('Something went wrong with suffix concatenation.')\n",
      "   220         1          0.0      0.0      0.0              self.variable_storage['concatenated_buffer']['idx_to_suffix'] = new_suffix_idx\n",
      "   221         1          0.0      0.0      0.0              state_lens = np.array(list(map(len, self.storage['keys'])))\n",
      "   222         1          0.0      0.0      0.0              suffix_keys_padded = -np.ones((state_lens.shape[0], state_lens.max()), dtype=int)\n",
      "   223         1          0.0      0.0      0.0              suffix_keys_padded_mask = np.expand_dims(np.arange(state_lens.max()), axis=0) < np.expand_dims(state_lens, axis=-1)\n",
      "   224         1          0.0      0.0      0.0              suffix_keys_padded[suffix_keys_padded_mask] = new_suffix_idx\n",
      "   225         1          0.0      0.0      0.0              self.variable_storage['concatenated_buffer']['suffix_indices'] = suffix_keys_padded\n",
      "   226                                                       # Get state indices\n",
      "   227         1          0.0      0.0      1.1              mask = _utility.general.padded_stack(list(map(lambda x: np.ones_like(x, dtype=bool), self.storage['keys'])), method='false')\n",
      "   228         1          0.0      0.0      0.0              grid = np.meshgrid(*[np.arange(s) for s in mask.shape], indexing='ij')\n",
      "   229         1          0.0      0.0      0.0              self.variable_storage['concatenated_buffer']['idx_to_buffer'] = np.stack([arr[mask] for arr in grid], axis=-1)  # TODO: Try on variable-sized envs, should work\n",
      "   230                                                       # Concatenate states\n",
      "   231         1          0.0      0.0      3.6              if pre_append: states = [self._append_suffix(s, keys=k) for k, s in zip(self.storage['keys'], self.storage['states'])]\n",
      "   232                                                       else: states = self.storage['states']\n",
      "   233         1          0.1      0.1     11.9              s01 = _utility.general.padded_stack(states, method='zero')\n",
      "   234         1          0.1      0.1      9.3              s2 =  _utility.general.padded_stack(list(map(lambda x: np.eye(x.shape[0], dtype=bool), states)), method='true')\n",
      "   235         1          0.0      0.0      0.0              if pre_cast:\n",
      "   236         1          0.0      0.0      4.7                  s01 = torch.from_numpy(s01).to(torch.get_default_dtype()).to(self.device)  # Cast to tensor early to avoid repeated casting cost\n",
      "   237         1          0.0      0.0      0.0                  s2 = torch.from_numpy(s2).to(torch.bool).to(self.device)\n",
      "   238         1          0.0      0.0      0.0              states = [s01, s01, s2]\n",
      "   239         1          0.0      0.0      0.0              self.variable_storage['concatenated_buffer']['states'] = states\n",
      "   240         1          0.0      0.0      0.0              self.out = None\n",
      "   241                                           \n",
      "   242                                                   # Automatically determine idx if int\n",
      "   243        50          0.0      0.0      0.0          if isinstance(idx, int):\n",
      "   244                                                       idx = [idx]\n",
      "   245                                                       # TODO: Make clustered version of this\n",
      "   246        50          0.0      0.0      1.8          idx = np.sort(np.array(idx))\n",
      "   247                                                   # return self.fast_sample(chosen=idx)\n",
      "   248                                           \n",
      "   249                                                   # Get indices to padded buffer from idx\n",
      "   250        50          0.0      0.0      1.3          buffer_idx = self.variable_storage['concatenated_buffer']['idx_to_buffer'][idx]\n",
      "   251        50          0.0      0.0      0.6          unique_list_nums, unique_list_counts = np.unique(buffer_idx[:, 0], return_counts=True)\n",
      "   252        50          0.0      0.0      0.0          if pad_nodes:\n",
      "   253        50          0.0      0.0      0.0              size = self.variable_storage['concatenated_buffer']['states'][1].shape[0]\n",
      "   254        50          0.0      0.0      0.0              new_unique_list_nums = np.arange(size, dtype=int)\n",
      "   255        50          0.0      0.0      0.4              mask = np.isin(new_unique_list_nums, unique_list_nums)\n",
      "   256        50          0.0      0.0      0.0              new_unique_list_counts = np.zeros(size, dtype=int)\n",
      "   257        50          0.0      0.0      0.0              new_unique_list_counts[mask] = unique_list_counts\n",
      "   258        50          0.0      0.0      0.0              unique_list_nums = new_unique_list_nums\n",
      "   259        50          0.0      0.0      0.0              unique_list_counts = new_unique_list_counts\n",
      "   260        50          0.0      0.0      0.1          grouped_indices = -np.ones((unique_list_nums.shape[0], unique_list_counts.max()), dtype=int)\n",
      "   261        50          0.0      0.0      0.2          grouped_sample_mask = np.expand_dims(np.arange(unique_list_counts.max()), axis=0) < np.expand_dims(unique_list_counts, axis=-1)\n",
      "   262        50          0.0      0.0      0.1          grouped_indices[grouped_sample_mask] = buffer_idx[:, 1]  # np.argsort(unique_list_inverse) doesn't respect initial ordering\n",
      "   263        50          0.0      0.0      0.0          overall_indices = grouped_indices.copy()\n",
      "   264        50          0.0      0.0      0.0          overall_indices[grouped_sample_mask] = idx\n",
      "   265                                           \n",
      "   266                                                   # Format output\n",
      "   267                                                   # feature_dim = self.storage['states'][0].shape[-1] + self.suffix_len\n",
      "   268                                                   # if self.out is None:\n",
      "   269                                                   #     self.out = [\n",
      "   270                                                   #         np.zeros((*grouped_indices.shape, feature_dim)),\n",
      "   271                                                   #         np.zeros((grouped_indices.shape[0], self.variable_storage['concatenated_buffer']['states'][1].shape[1], feature_dim)),\n",
      "   272                                                   #         np.zeros((*grouped_indices.shape, self.variable_storage['concatenated_buffer']['states'][1].shape[1])),\n",
      "   273                                                   #     ]\n",
      "   274                                                   # states = self.out\n",
      "   275                                                   # Format states\n",
      "   276                                                   # states[0][..., :-self.suffix_len] = self.variable_storage['concatenated_buffer']['states'][0][np.expand_dims(unique_list_nums, axis=-1), grouped_indices]\n",
      "   277                                                   # states[1][..., :-self.suffix_len] = self.variable_storage['concatenated_buffer']['states'][1][unique_list_nums]\n",
      "   278                                                   # states[2][:] = self.variable_storage['concatenated_buffer']['states'][2][np.expand_dims(unique_list_nums, axis=-1), grouped_indices]\n",
      "   279                                           \n",
      "   280                                                   # Format states\n",
      "   281        50          0.0      0.0      0.0          states = [\n",
      "   282        50          0.2      0.0     18.1              self.variable_storage['concatenated_buffer']['states'][0][np.expand_dims(unique_list_nums, axis=-1), grouped_indices],\n",
      "   283        50          0.0      0.0      0.2              self.variable_storage['concatenated_buffer']['states'][1][unique_list_nums if not pad_nodes else slice(unique_list_nums.shape[0])],\n",
      "   284        50          0.2      0.0     15.5              self.variable_storage['concatenated_buffer']['states'][2][np.expand_dims(unique_list_nums, axis=-1), grouped_indices]]\n",
      "   285        50          0.1      0.0     13.7          if pre_cast: states[2] = states[2].clone()\n",
      "   286                                                   else: states[2] = states[2].copy()\n",
      "   287                                                   # Post-append\n",
      "   288        50          0.0      0.0      0.0          if not pre_append:\n",
      "   289                                                       suffix_idx = self.variable_storage['concatenated_buffer']['idx_to_suffix'][idx]\n",
      "   290                                                       suffix_grouped_indices = grouped_indices.copy()\n",
      "   291                                                       suffix_grouped_indices[grouped_sample_mask] = suffix_idx\n",
      "   292                                                       # states[0][..., -self.suffix_len:] = self.variable_storage['concatenated_buffer']['suffixes'][suffix_grouped_indices.flatten()].reshape((*suffix_grouped_indices.shape, -1))\n",
      "   293                                                       # states[1][..., -self.suffix_len:] = self.variable_storage['concatenated_buffer']['suffixes'][self.variable_storage['concatenated_buffer']['suffix_indices'][unique_list_nums]]\n",
      "   294                                                       s0_suffix = self.variable_storage['concatenated_buffer']['suffixes'][suffix_grouped_indices.flatten()].reshape((*suffix_grouped_indices.shape, -1))\n",
      "   295                                                       s1_suffix = self.variable_storage['concatenated_buffer']['suffixes'][self.variable_storage['concatenated_buffer']['suffix_indices'][unique_list_nums]]\n",
      "   296                                                       # states[0] = np.concatenate((states[0], s0_suffix), axis=-1)\n",
      "   297                                                       # states[1] = np.concatenate((states[1], s1_suffix), axis=-1)\n",
      "   298                                                   # Mask ragged fillers, uses -1 as indicator\n",
      "   299        50          0.0      0.0      3.1          states[2][tuple(np.argwhere(grouped_indices==-1).T)] = True\n",
      "   300                                           \n",
      "   301                                                   # Pull from padded buffer and cast to tensors\n",
      "   302        50          0.0      0.0      0.0          ret = {}\n",
      "   303                                                   # General case\n",
      "   304       300          0.0      0.0      0.0          for k in general_storage_keys:\n",
      "   305       250          0.0      0.0      2.8              ret[k] = torch.from_numpy(self.variable_storage['concatenated_buffer'][k][idx]).to(torch.get_default_dtype()).to(self.device)\n",
      "   306                                                   # State case\n",
      "   307        50          0.0      0.0      0.0          if pre_cast: ret['states'] = states\n",
      "   308                                                   else:\n",
      "   309                                                       ret['states'] = [\n",
      "   310                                                           torch.from_numpy(states[0]).to(torch.get_default_dtype()).to(self.device),\n",
      "   311                                                           torch.from_numpy(states[1]).to(torch.get_default_dtype()).to(self.device),\n",
      "   312                                                           torch.from_numpy(states[2]).to(torch.bool).to(self.device)]\n",
      "   313        50          0.0      0.0      0.0          return overall_indices, ret  # indices, data\n",
      "\n",
      "Total time: 0.0508055 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: forward at line 391\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   391                                               def forward(self, x, kv=None, mask=None):\n",
      "   392                                                   # Parameters\n",
      "   393        50          0.0      0.0      0.1          if kv is None: x = kv\n",
      "   394                                           \n",
      "   395                                                   # Residual Attention\n",
      "   396        50          0.0      0.0      7.0          x1 = self.norms[0](x)\n",
      "   397        50          0.0      0.0      5.4          kv1 = self.norms[1](kv)\n",
      "   398                                                   # kv1 = kv\n",
      "   399        50          0.0      0.0     62.1          x2, _ = self.attention(x1, kv1, kv1, attn_mask=mask)\n",
      "   400        50          0.0      0.0      1.6          x = x + x2\n",
      "   401        50          0.0      0.0      6.2          x1 = self.norms[2](x)\n",
      "   402        50          0.0      0.0     15.8          x2 = self.mlp(x1)\n",
      "   403        50          0.0      0.0      1.7          x = x + x2\n",
      "   404        50          0.0      0.0      0.0          return x\n",
      "\n",
      "Total time: 6.81378 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: update at line 1400\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1400                                               def update(\n",
      "  1401                                                   self,\n",
      "  1402                                                   memory,\n",
      "  1403                                                   update_iterations=None,\n",
      "  1404                                                   standardize_inputs=True,\n",
      "  1405                                                   standardize_returns=True,\n",
      "  1406                                                   verbose=False,\n",
      "  1407                                                   # Collective args\n",
      "  1408                                                   sync_iterations=None,\n",
      "  1409                                                   **kwargs,\n",
      "  1410                                               ):\n",
      "  1411                                                   # NOTE: The number of epochs is spread across `world_size` workers\n",
      "  1412                                                   # NOTE: Assumes col.init_collective_group has already been called if world_size > 1\n",
      "  1413                                                   # Parameters\n",
      "  1414         1          0.0      0.0      0.0          if update_iterations is None: update_iterations = self.update_iterations\n",
      "  1415         1          0.0      0.0      0.0          if sync_iterations is None: sync_iterations = self.sync_iterations\n",
      "  1416                                           \n",
      "  1417                                                   # Collective operations\n",
      "  1418         1          0.0      0.0      0.0          use_collective = col.is_group_initialized('default')\n",
      "  1419                                           \n",
      "  1420                                                   # Batch parameters\n",
      "  1421                                                   # level_dict = {'pool': 0, 'epoch': 1, 'batch': 2, 'minibatch': 3}\n",
      "  1422                                                   # load_level = level_dict[self.load_level]\n",
      "  1423                                                   # cast_level = level_dict[self.cast_level]\n",
      "  1424                                                   # assert cast_level >= load_level, 'Cannot cast without first loading'\n",
      "  1425                                           \n",
      "  1426                                                   # Determine level sizes\n",
      "  1427         1          0.0      0.0      0.0          memory_size = len(memory)\n",
      "  1428                                                   \n",
      "  1429                                                   # Pool size\n",
      "  1430         1          0.0      0.0      0.0          pool_size = self.pool_size\n",
      "  1431                                                   # if pool_size is not None:\n",
      "  1432         1          0.0      0.0      0.0          pool_size = min(pool_size, memory_size)\n",
      "  1433                                                   \n",
      "  1434                                                   # Epoch size\n",
      "  1435         1          0.0      0.0      0.0          epoch_size = self.epoch_size if not (self.epoch_size is None and pool_size is not None) else pool_size\n",
      "  1436                                                   # if epoch_size is not None and pool_size is not None:\n",
      "  1437         1          0.0      0.0      0.0          epoch_size = int(min(epoch_size, pool_size))\n",
      "  1438                                                   \n",
      "  1439                                                   # Batch size\n",
      "  1440         1          0.0      0.0      0.0          batch_size = self.batch_size if not (self.batch_size is None and epoch_size is not None) else epoch_size\n",
      "  1441                                                   # if batch_size is not None and epoch_size is not None:\n",
      "  1442         1          0.0      0.0      0.0          batch_size = int(min(batch_size, epoch_size))\n",
      "  1443                                           \n",
      "  1444                                                   # Level adjustment\n",
      "  1445         1          0.0      0.0      0.0          denominator = get_world_size('learners') if sync_iterations == 1 else 1  # Adjust sizes if gradients synchronized across GPUs\n",
      "  1446                                                   # if epoch_size is not None:\n",
      "  1447         1          0.0      0.0      0.0          if not np.isinf(self.epoch_size): epoch_size = np.ceil(epoch_size / denominator).astype(int)\n",
      "  1448                                                   # if batch_size is not None:\n",
      "  1449         1          0.0      0.0      0.0          if not np.isinf(self.batch_size): batch_size = np.ceil(batch_size / denominator).astype(int)\n",
      "  1450                                           \n",
      "  1451                                                   # Minibatch size\n",
      "  1452         1          0.0      0.0      0.0          minibatch_size = self.minibatch_size if not (self.minibatch_size is None and batch_size is not None) else batch_size\n",
      "  1453         1          0.0      0.0      0.0          if minibatch_size is not None and batch_size is not None: minibatch_size = int(min(minibatch_size, batch_size))\n",
      "  1454                                           \n",
      "  1455                                                   # Load pool\n",
      "  1456         1          0.0      0.0      0.0          total_losses = defaultdict(lambda: [])\n",
      "  1457         1          0.0      0.0      0.0          total_statistics = defaultdict(lambda: [])\n",
      "  1458         1          0.0      0.0      0.0          pool_idx = np.random.choice(memory_size, pool_size, replace=False) if pool_size < memory_size else memory_size\n",
      "  1459                                           \n",
      "  1460                                                   # Train\n",
      "  1461         1          0.0      0.0      0.0          iterations = 0; synchronized = True; escape = False\n",
      "  1462         5          0.0      0.0      0.0          while True:\n",
      "  1463                                                       # Load epoch\n",
      "  1464         5          0.0      0.0      0.1              epoch_idx = np.random.choice(pool_idx, epoch_size, replace=False)  # Also shuffles\n",
      "  1465         5          0.0      0.0      0.0              batches = np.floor(epoch_size/batch_size).astype(int) if epoch_size is not None else 1  # Drop any smaller batches\n",
      "  1466        55          0.0      0.0      0.0              for batch_num in range(batches):\n",
      "  1467                                                           # Load batch\n",
      "  1468        50          0.0      0.0      0.0                  batch_losses = defaultdict(lambda: 0)\n",
      "  1469        50          0.0      0.0      0.0                  batch_statistics = defaultdict(lambda: 0)\n",
      "  1470        50          0.0      0.0      0.0                  batch_idx = epoch_idx[batch_num*batch_size:(batch_num+1)*batch_size]\n",
      "  1471        50          0.0      0.0      0.0                  batch_state_vals_new = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1472        50          0.0      0.0      0.0                  batch_inputs = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1473        50          0.0      0.0      0.0                  batch_returns = torch.zeros(0, device=self.policy_iteration.device)\n",
      "  1474        50          0.0      0.0      0.0                  minibatches = np.ceil(batch_size/minibatch_size).astype(int) if batch_size is not None else 1\n",
      "  1475       100          0.0      0.0      0.0                  for minibatch_num in range(minibatches):\n",
      "  1476                                                               # Load minibatch\n",
      "  1477        50          0.0      0.0      0.0                      minibatch_idx = batch_idx[minibatch_num*minibatch_size:(minibatch_num+1)*minibatch_size]\n",
      "  1478        50          1.0      0.0     15.1                      minibatch_indices, minibatch_data = memory[minibatch_idx]\n",
      "  1479                                           \n",
      "  1480                                                               # Normalize advantages\n",
      "  1481        50          0.0      0.0      0.1                      minibatch_data['normalized_advantages'] = (minibatch_data['advantages'] - minibatch_data['advantages'].mean()) / (minibatch_data['advantages'].std() + 1e-8)\n",
      "  1482                                           \n",
      "  1483                                                               # Cast\n",
      "  1484        50          2.1      0.0     31.3                      minibatch_data = _utility.processing.dict_map_recursive_tensor_idx_to(minibatch_data, None, self.policy_iteration.device)\n",
      "  1485                                           \n",
      "  1486                                                               # Ministeps\n",
      "  1487        50          0.0      0.0      0.0                      minibatch_memories = self.minibatch_memories if self.minibatch_memories is not None else np.prod(minibatch_data['states'][1].shape[:-1])\n",
      "  1488        50          0.0      0.0      0.0                      ministep_size = np.maximum(np.floor(minibatch_memories / minibatch_data['states'][1].shape[1]), 1).astype(int)\n",
      "  1489        50          0.0      0.0      0.0                      ministeps = np.ceil(minibatch_data['states'][1].shape[0] / ministep_size).astype(int)\n",
      "  1490        50          0.0      0.0      0.1                      cumsum_indices = (minibatch_indices > -1).flatten().cumsum(0).reshape(minibatch_indices.shape)\n",
      "  1491        50          0.0      0.0      0.0                      proc_mems = 0\n",
      "  1492       100          0.0      0.0      0.0                      for ministep_num in range(ministeps):\n",
      "  1493                                                                   # Subsample\n",
      "  1494        50          0.0      0.0      0.0                          double_idx = slice(ministep_num*ministep_size, (ministep_num+1)*ministep_size)\n",
      "  1495        50          0.0      0.0      0.0                          single_idx = cumsum_indices[double_idx]\n",
      "  1496        50          0.0      0.0      0.0                          first_true = int(minibatch_indices[double_idx][0, 0] > -1)\n",
      "  1497        50          0.0      0.0      0.0                          num_memories = single_idx.max() - single_idx.min() + first_true\n",
      "  1498        50          0.0      0.0      0.0                          single_idx = slice(single_idx.min() - first_true, single_idx.max())  # NOTE: No +1 here because cumsum is always one ahead\n",
      "  1499        50          0.0      0.0      0.0                          if num_memories == 0: continue\n",
      "  1500        50          0.0      0.0      0.0                          proc_mems += num_memories\n",
      "  1501                                           \n",
      "  1502                                                                   # Get subset data\n",
      "  1503        50          0.0      0.0      0.0                          states = [s[double_idx] for s in minibatch_data['states']]\n",
      "  1504        50          0.0      0.0      0.0                          actions = minibatch_data['actions'][single_idx]\n",
      "  1505        50          0.0      0.0      0.0                          action_logs = minibatch_data['action_logs'][single_idx]\n",
      "  1506        50          0.0      0.0      0.0                          state_vals = minibatch_data['state_vals'][single_idx]\n",
      "  1507        50          0.0      0.0      0.0                          advantages = minibatch_data['advantages'][single_idx]\n",
      "  1508        50          0.0      0.0      0.0                          normalized_advantages = minibatch_data['normalized_advantages'][single_idx]\n",
      "  1509                                                                   # rewards = minibatch_data['propagated_rewards'][single_idx]\n",
      "  1510                                           \n",
      "  1511                                                                   # Perform backward\n",
      "  1512       100          1.8      0.0     26.6                          loss, loss_ppo, loss_critic, loss_entropy, loss_kl, state_vals_new = self.calculate_losses(\n",
      "  1513        50          0.0      0.0      0.0                              states, actions, action_logs, state_vals, advantages=advantages, normalized_advantages=normalized_advantages, rewards=None)\n",
      "  1514                                           \n",
      "  1515                                                                   # Scale and calculate gradient\n",
      "  1516                                                                   # accumulation_frac = minibatch_actual_size / batch_size\n",
      "  1517                                                                   # accumulation_frac = minibatch_idx.shape[0] / batch_size\n",
      "  1518        50          0.0      0.0      0.0                          accumulation_frac = num_memories / batch_size\n",
      "  1519        50          0.0      0.0      0.0                          loss = loss * accumulation_frac\n",
      "  1520        50          0.3      0.0      4.3                          loss.backward()  # Longest computation\n",
      "  1521                                           \n",
      "  1522                                                                   # Record required logs\n",
      "  1523        50          0.0      0.0      0.0                          batch_inputs = torch.cat((batch_inputs, states[0].view(-1, states[0].shape[-1])), dim=0)  # Only use first to save memory\n",
      "  1524        50          0.0      0.0      0.0                          batch_returns = torch.cat((batch_returns, advantages+state_vals), dim=0)\n",
      "  1525        50          0.0      0.0      0.0                          batch_state_vals_new = torch.cat((batch_state_vals_new, state_vals_new), dim=0)\n",
      "  1526                                           \n",
      "  1527                                                                   # Scale and record\n",
      "  1528        50          0.0      0.0      0.0                          batch_losses['Total'] += loss.detach()\n",
      "  1529        50          0.0      0.0      0.0                          batch_losses['PPO'] += loss_ppo.detach().mean() * accumulation_frac\n",
      "  1530        50          0.0      0.0      0.0                          batch_losses['critic'] += loss_critic.detach().mean() * accumulation_frac\n",
      "  1531        50          0.0      0.0      0.0                          batch_losses['entropy'] += loss_entropy.detach().mean() * accumulation_frac\n",
      "  1532        50          0.0      0.0      0.0                          batch_losses['KL'] += loss_kl.detach().mean() * accumulation_frac\n",
      "  1533                                           \n",
      "  1534                                                           # Calculate explained variance\n",
      "  1535        50          0.0      0.0      0.0                  normalized_returns = self.return_standardization.apply(batch_returns)\n",
      "  1536        50          0.0      0.0      0.2                  exp_var = (1- (normalized_returns - batch_state_vals_new).var() / normalized_returns.var()).clamp(min=-1)\n",
      "  1537                                           \n",
      "  1538                                                           # Statistics\n",
      "  1539        50          0.0      0.0      0.0                  batch_statistics['Moving Return Mean'] += self.return_standardization.mean.detach().mean()\n",
      "  1540        50          0.0      0.0      0.0                  batch_statistics['Moving Return STD'] += self.return_standardization.std.detach().mean()\n",
      "  1541        50          0.0      0.0      0.0                  batch_statistics['Return Mean'] += batch_returns.detach().mean() * accumulation_frac\n",
      "  1542        50          0.0      0.0      0.0                  batch_statistics['Return STD'] += batch_returns.detach().std() * accumulation_frac\n",
      "  1543        50          0.0      0.0      0.0                  batch_statistics['Moving Input Mean'] += self.input_standardization.mean.detach().mean()\n",
      "  1544        50          0.0      0.0      0.0                  batch_statistics['Moving Input STD'] += self.input_standardization.std.detach().mean()\n",
      "  1545        50          0.0      0.0      0.0                  batch_statistics['Input Mean'] += batch_inputs.detach().mean() * accumulation_frac\n",
      "  1546        50          0.0      0.0      0.0                  batch_statistics['Input STD'] += batch_inputs.detach().std() * accumulation_frac\n",
      "  1547                                                           # batch_statistics['Moving Reward Mean'] += self.reward_standardization.mean.mean() * accumulation_frac\n",
      "  1548                                                           # batch_statistics['Moving Reward STD'] += self.reward_standardization.std.mean() * accumulation_frac\n",
      "  1549        50          0.0      0.0      0.0                  batch_statistics['Explained Variance'] += exp_var.detach()\n",
      "  1550                                                           # batch_statistics['Advantage Mean'] += advantages.detach().mean() * accumulation_frac\n",
      "  1551                                                           # batch_statistics['Advantage STD'] += advantages.detach().std() * accumulation_frac\n",
      "  1552                                                           # batch_statistics['Log STD'] += self.get_log_std() * accumulation_frac\n",
      "  1553                                                           \n",
      "  1554                                                           # Record\n",
      "  1555       300          0.0      0.0      0.0                  for k, v in batch_losses.items(): total_losses[k].append(v)\n",
      "  1556       500          0.0      0.0      0.0                  for k, v in batch_statistics.items(): total_statistics[k].append(v)\n",
      "  1557                                           \n",
      "  1558                                                           # Synchronize GPU policies and step\n",
      "  1559                                                           # NOTE: Synchronize gradients every batch if =1, else synchronize whole model\n",
      "  1560                                                           # NOTE: =1 keeps optimizers in sync without need for whole-model synchronization\n",
      "  1561        50          0.0      0.0      0.0                  if sync_iterations == 1: synchronize(self, 'learners', grad=False)  # Sync only grad\n",
      "  1562        50          0.0      0.0      0.0                  if self.kl_early_stop and synchronized: self.copy_policy()\n",
      "  1563        50          0.1      0.0      0.7                  nn.utils.clip_grad_norm_(self.actor_critic.parameters(), self.grad_clip)\n",
      "  1564        50          0.1      0.0      1.1                  self.optimizer.step()\n",
      "  1565        50          0.0      0.0      0.1                  self.optimizer.zero_grad()\n",
      "  1566        50          0.0      0.0      0.0                  if sync_iterations != 1:\n",
      "  1567                                                               # Synchronize for offsets\n",
      "  1568                                                               sync_loop = (iterations) % sync_iterations == 0\n",
      "  1569                                                               last_epoch = iterations == update_iterations\n",
      "  1570                                                               if use_collective and (sync_loop or last_epoch):\n",
      "  1571                                                                   synchronize(self, 'learners')\n",
      "  1572                                                                   synchronized = True\n",
      "  1573                                                               else: synchronized = False\n",
      "  1574                                           \n",
      "  1575                                                           # Update moving return mean\n",
      "  1576        50          0.0      0.0      0.0                  if standardize_inputs:\n",
      "  1577        50          1.3      0.0     18.9                      self.input_standardization.update(batch_inputs)\n",
      "  1578        50          0.0      0.0      0.0                  if standardize_returns:\n",
      "  1579        50          0.0      0.0      0.5                      self.return_standardization.update(batch_returns)\n",
      "  1580        50          0.0      0.0      0.0                      synchronize(self, 'learners', sync_list=self.return_standardization.parameters())\n",
      "  1581                                           \n",
      "  1582                                                           # Update KL beta\n",
      "  1583                                                           # NOTE: Same as Torch KLPENPPOLoss implementation\n",
      "  1584        50          0.0      0.0      0.0                  if self.kl_early_stop or self.kl_beta != 0:\n",
      "  1585                                                               loss_kl_mean = loss_kl.detach().mean()\n",
      "  1586                                                               synchronize(self, 'learners', sync_list=[loss_kl_mean])\n",
      "  1587                                                               if not self.kl_early_stop:\n",
      "  1588                                                                   exp_limit = 32\n",
      "  1589                                                                   if loss_kl_mean < self.kl_target / 1.5 and self.kl_beta > 2**-exp_limit: self.kl_beta.data *= self.kl_beta_increment[0]\n",
      "  1590                                                                   elif loss_kl_mean > self.kl_target * 1.5 and self.kl_beta < 2**exp_limit: self.kl_beta.data *= self.kl_beta_increment[1]\n",
      "  1591                                           \n",
      "  1592                                                           # Escape and roll back if KLD too high\n",
      "  1593        50          0.0      0.0      0.0                  if self.kl_early_stop:\n",
      "  1594                                                               if loss_kl_mean > 1.5 * self.kl_target:\n",
      "  1595                                                                   if iterations - sync_iterations > 0:\n",
      "  1596                                                                       # Revert to previous synchronized state within kl target\n",
      "  1597                                                                       self.revert_policy()\n",
      "  1598                                                                       # iterations -= sync_iterations\n",
      "  1599                                                                       escape = True; break\n",
      "  1600                                                                   else:\n",
      "  1601                                                                       warnings.warn(\n",
      "  1602                                                                           'Update exceeded KL target too fast! Proceeding with update, but may be unstable. '\n",
      "  1603                                                                           'Try lowering clip or learning rate parameters.')\n",
      "  1604                                                                       escape = True; break\n",
      "  1605                                                                   \n",
      "  1606                                                       # Iterate\n",
      "  1607         5          0.0      0.0      0.0              iterations += 1\n",
      "  1608         5          0.0      0.0      0.0              if iterations >= update_iterations: escape = True\n",
      "  1609                                           \n",
      "  1610                                                       # CLI\n",
      "  1611         5          0.0      0.0      0.0              if verbose and (iterations in (1, 5) or iterations % 10 == 0 or escape):\n",
      "  1612         4          0.0      0.0      0.0                  print(\n",
      "  1613         8          0.0      0.0      0.0                      f'Iteration {iterations:02} - '\n",
      "  1614         2          0.0      0.0      0.0                      + f' + '.join([f'{k} ({np.mean([v.item() for v in vl[-batches:]]):.5f})' for k, vl in total_losses.items()])\n",
      "  1615         2          0.0      0.0      0.0                      + f' :: '\n",
      "  1616         2          0.0      0.0      0.0                      + f', '.join([f'{k} ({np.mean([v.item() for v in vl[-batches:]]):.5f})' for k, vl in total_statistics.items()]))\n",
      "  1617                                           \n",
      "  1618                                                       # Break\n",
      "  1619         5          0.0      0.0      0.0              if escape: break\n",
      "  1620                                           \n",
      "  1621                                                   # Update scheduler\n",
      "  1622         1          0.0      0.0      0.0          self.scheduler.step()\n",
      "  1623                                           \n",
      "  1624                                                   # Train pinning\n",
      "  1625         1          0.0      0.0      0.0          X, Y = memory.get_terminal_pairs()\n",
      "  1626         1          0.0      0.0      0.0          has_memories = torch.tensor(0., device=self.policy_iteration.device)\n",
      "  1627         1          0.0      0.0      0.0          if X is not None: has_memories += 1\n",
      "  1628         1          0.0      0.0      0.0          synchronize(self, 'learners', sync_list=[has_memories], override_world_size=1)\n",
      "  1629         1          0.0      0.0      0.0          has_memories = int(has_memories.cpu().item())\n",
      "  1630         1          0.0      0.0      0.0          running_feat = 0; pinning_losses = {}\n",
      "  1631         2          0.0      0.0      0.0          for i, (pinning, pinning_modal_dim) in enumerate(zip(self.pinning, self.pinning_modal_dims)):\n",
      "  1632         1          0.0      0.0      0.0              if X is None: pinning.update(None, None, world_size=has_memories)\n",
      "  1633                                                       else:\n",
      "  1634                                                           X_sub = X[..., :self.pinning_dim].to(self.policy_iteration.device)\n",
      "  1635                                                           Y_sub = Y[..., running_feat:running_feat+pinning_modal_dim].to(self.policy_iteration.device)\n",
      "  1636                                                           pinning_losses[f'Pinning Mean {i}'] = X_sub.mean(dim=0).mean().cpu().item()\n",
      "  1637                                                           pinning_losses[f'Pinning Abs Mean {i}'] = X_sub.mean(dim=0).abs().mean().cpu().item()\n",
      "  1638                                                           pinning_losses[f'Pinning STD {i}'] = X_sub.std(dim=0).mean().cpu().item()\n",
      "  1639                                                           pinning_losses[f'Pinning Loss {i}'] = pinning.update(\n",
      "  1640                                                               X_sub, Y_sub, world_size=has_memories)\n",
      "  1641         1          0.0      0.0      0.0              running_feat += pinning_modal_dim\n",
      "  1642         1          0.0      0.0      0.0          if Y is not None:\n",
      "  1643                                                       assert running_feat == Y.shape[1], (\n",
      "  1644                                                           f'`pinning_modal_dims` sum ({running_feat}) does not match target modality combined length ({Y.shape[1]})')\n",
      "  1645                                           \n",
      "  1646                                                   # Update records\n",
      "  1647         1          0.0      0.0      0.0          self.policy_iteration += 1\n",
      "  1648         1          0.0      0.0      0.1          self.copy_policy()\n",
      "  1649                                                   # Return\n",
      "  1650         1          0.0      0.0      0.0          total_losses_ret = {k: np.mean([v.item() for v in vl]) for k, vl in total_losses.items()}\n",
      "  1651         1          0.0      0.0      0.0          total_losses_ret = {**total_losses_ret, **pinning_losses}  # TODO: Maybe revise\n",
      "  1652         1          0.0      0.0      0.0          total_statistics_ret = {k: np.mean([v.item() for v in vl]) for k, vl in total_statistics.items()}\n",
      "  1653         1          0.0      0.0      0.0          return (\n",
      "  1654         1          0.0      0.0      0.0              iterations,\n",
      "  1655         1          0.0      0.0      0.0              total_losses_ret,\n",
      "  1656         1          0.0      0.0      0.0              total_statistics_ret)\n",
      "\n",
      "Total time: 1.81055 s\n",
      "File: /home/thema/repos/inept/celltrip/policy.py\n",
      "Function: calculate_losses at line 1658\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1658                                               def calculate_losses(\n",
      "  1659                                                   self,\n",
      "  1660                                                   states,\n",
      "  1661                                                   actions,\n",
      "  1662                                                   action_logs,\n",
      "  1663                                                   state_vals,\n",
      "  1664                                                   advantages=None,\n",
      "  1665                                                   normalized_advantages=None,\n",
      "  1666                                                   rewards=None):\n",
      "  1667                                                   # TODO: Maybe implement PFO https://github.com/CLAIRE-Labo/no-representation-no-trust\n",
      "  1668        50          0.0      0.0      0.0          if advantages is not None:\n",
      "  1669                                                       # Get inferred rewards\n",
      "  1670        50          0.0      0.0      0.1              rewards = advantages + state_vals\n",
      "  1671                                                   elif rewards is not None:\n",
      "  1672                                                       # Get advantages\n",
      "  1673                                                       advantages = rewards - state_vals\n",
      "  1674                                                   # Get normalized advantages\n",
      "  1675        50          0.0      0.0      0.0          if normalized_advantages is None:\n",
      "  1676                                                       advantages_mean, advantages_std = advantages.mean(), advantages.std() + 1e-8\n",
      "  1677                                                       normalized_advantages = (advantages - advantages_mean) / advantages_std\n",
      "  1678                                                   # Clip advantages for stability\n",
      "  1679                                                   # normalized_advantages =  normalized_advantages.clamp(\n",
      "  1680                                                   #     normalized_advantages.quantile(.05), normalized_advantages.quantile(.95))\n",
      "  1681                                           \n",
      "  1682                                                   # Get normalized returns/rewards (sensitive to minibatch)\n",
      "  1683                                                   # NOTE: Action STD explosion/instability points to a normalization and/or critic fitting issue\n",
      "  1684                                                   #       or, possibly, the returns are too homogeneous - i.e. the problem is solved\n",
      "  1685        50          0.0      0.0      0.2          normalized_rewards = self.return_standardization.apply(rewards)  # , mean=False\n",
      "  1686                                           \n",
      "  1687                                                   # Evaluate actions and states\n",
      "  1688        50          0.0      0.0      0.3          normalized_states = [self.input_standardization.apply(states[0]), self.input_standardization.apply(states[1]), states[2]]\n",
      "  1689        50          1.8      0.0     97.9          action_logs_new, dist_entropy, state_vals_new = self.actor_critic(*normalized_states, action=actions, entropy=True, critic=True)\n",
      "  1690                                                   # action_logs_new = action_logs_new.clamp(-20, 0)\n",
      "  1691                                                   \n",
      "  1692                                                   # Calculate PPO loss\n",
      "  1693        50          0.0      0.0      0.0          log_ratios = action_logs_new - action_logs\n",
      "  1694                                                   # log_ratios = log_ratios.clamp(-20, 2)\n",
      "  1695        50          0.0      0.0      0.0          ratios = log_ratios.exp()\n",
      "  1696        50          0.0      0.0      0.0          unclipped_ppo = ratios * normalized_advantages\n",
      "  1697        50          0.0      0.0      0.1          clipped_ppo = ratios.clamp(1-self.epsilon_ppo, 1+self.epsilon_ppo) * normalized_advantages\n",
      "  1698        50          0.0      0.0      0.3          loss_ppo = -torch.min(unclipped_ppo, clipped_ppo)\n",
      "  1699                                           \n",
      "  1700                                                   # Calculate KL divergence\n",
      "  1701                                                   # NOTE: A bit odd when it comes to replay\n",
      "  1702                                                   # Discrete\n",
      "  1703                                                   # loss_kl = F.kl_div(action_logs, action_logs_new, reduction='batchmean', log_target=True)\n",
      "  1704                                                   # loss_kl = ((action_logs - action_logs_new)  # * action_logs.exp()).sum(-1)  # Approximation\n",
      "  1705                                                   # Continuous (http://joschu.net/blog/kl-approx.html)\n",
      "  1706        50          0.0      0.0      0.1          loss_kl = (log_ratios.exp() - 1) - log_ratios\n",
      "  1707                                                   # Mask and scale where needed (for replay)\n",
      "  1708                                                   # loss_kl[~new_memories] = 0\n",
      "  1709                                                   # loss_kl = loss_kl * loss_kl.shape[0] / new_memories.sum()\n",
      "  1710                                           \n",
      "  1711                                                   # Calculate critic loss\n",
      "  1712        50          0.0      0.0      0.0          criteria = F.smooth_l1_loss\n",
      "  1713                                                   # criteria = F.mse_loss\n",
      "  1714        50          0.0      0.0      0.3          unclipped_critic = criteria(state_vals_new, normalized_rewards)\n",
      "  1715        50          0.0      0.0      0.1          clipped_state_vals_new = torch.clamp(state_vals_new, state_vals-self.epsilon_critic, state_vals+self.epsilon_critic)\n",
      "  1716        50          0.0      0.0      0.1          clipped_critic = criteria(clipped_state_vals_new, normalized_rewards, reduction='none')\n",
      "  1717        50          0.0      0.0      0.1          loss_critic = torch.max(unclipped_critic, clipped_critic)\n",
      "  1718                                           \n",
      "  1719                                                   # Calculate entropy bonus\n",
      "  1720                                                   # NOTE: Not included in training grad if action_std is constant\n",
      "  1721                                                   # dist_entropy = -action_logs_new  # Approximation\n",
      "  1722        50          0.0      0.0      0.0          loss_entropy = -dist_entropy\n",
      "  1723                                           \n",
      "  1724                                                   # Construct final loss\n",
      "  1725        50          0.0      0.0      0.0          loss = (\n",
      "  1726       200          0.0      0.0      0.1              loss_ppo\n",
      "  1727        50          0.0      0.0      0.0              + self.critic_weight * loss_critic\n",
      "  1728        50          0.0      0.0      0.0              + self.entropy_weight * loss_entropy\n",
      "  1729        50          0.0      0.0      0.0              + self.kl_beta * loss_kl)\n",
      "  1730        50          0.0      0.0      0.0          loss = loss.mean()\n",
      "  1731                                           \n",
      "  1732        50          0.0      0.0      0.0          return loss, loss_ppo, loss_critic, loss_entropy, loss_kl, state_vals_new\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Updates\n",
    "# import line_profiler\n",
    "# prof = line_profiler.LineProfiler(\n",
    "#     # memory.fast_sample, policy.actor_critic.forward,\n",
    "#     celltrip.policy.ResidualAttentionBlock.forward,\n",
    "#     policy.calculate_losses, policy.update,\n",
    "#     celltrip.memory.AdvancedMemoryBuffer.__getitem__)\n",
    "# ret = prof.runcall(policy.update, memory, verbose=True)\n",
    "# print('UPDATE: ' + ', '.join([f'{k}: {v:.3f}' for ret_dict in ret[1:] for k, v in ret_dict.items()]))\n",
    "# prof.print_stats(output_unit=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6789,  0.6088,  0.5714,  ..., -1.1509, -1.6819,  2.0672],\n",
      "        [ 2.3578, -1.3243, -2.1103,  ...,  0.4661, -0.2684, -0.1553],\n",
      "        [ 0.8144, -1.5807,  0.1408,  ...,  0.9140, -1.8973, -0.8437],\n",
      "        ...,\n",
      "        [-0.8506,  0.5550, -1.2938,  ..., -0.5367,  0.6879,  1.3929],\n",
      "        [-1.1079,  0.1883,  0.9195,  ...,  0.2999, -2.9068, -1.6411],\n",
      "        [ 0.7353, -1.9406, -0.6259,  ...,  0.6976,  1.1831,  1.1897]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7893, -1.9561, -1.1821,  ..., -1.1454, -1.7943, -1.1448],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.9200, -0.3403, -1.2042,  ...,  0.5757,  3.0719, -1.0956],\n",
      "        [ 0.5124, -1.1635,  0.1780,  ..., -1.9831, -0.6756, -2.2262],\n",
      "        [ 1.2168, -0.7434, -0.7732,  ..., -0.6749,  0.1009,  0.3238],\n",
      "        ...,\n",
      "        [ 0.2259,  0.1847,  0.4070,  ...,  2.5144, -4.0476,  0.5622],\n",
      "        [-1.3349,  1.0668,  0.1303,  ..., -0.9193, -1.2485,  0.6354],\n",
      "        [-1.0493,  1.3721,  1.2776,  ...,  0.3216, -0.9740,  0.9439]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.3432, -2.0471, -0.4173,  ..., -3.0787, -1.0476, -1.1519],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8225, -1.8609, -0.7724,  ..., -1.8833, -0.8584, -0.6349],\n",
      "        [ 0.4077, -0.8513,  0.8628,  ..., -0.6460,  0.2723, -1.0799],\n",
      "        [ 0.6517, -2.8201, -0.7574,  ..., -0.2789, -1.9926,  2.3490],\n",
      "        ...,\n",
      "        [ 0.8377, -1.3842, -0.7359,  ...,  1.7548, -0.2611, -0.4130],\n",
      "        [ 0.4232,  0.4848,  2.1439,  ...,  0.6257,  0.1675,  0.5949],\n",
      "        [-0.9984,  0.6043,  1.3360,  ...,  1.0088, -1.2127,  2.8073]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2157, -0.7470, -2.5189,  ..., -1.0796, -2.2366, -1.8350],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5056, -1.1826, -1.8826,  ..., -0.2300,  2.1381,  1.6527],\n",
      "        [-1.0606, -1.6803, -1.2169,  ..., -0.3795, -2.0579,  2.0318],\n",
      "        [-1.6097,  1.3593,  0.0625,  ..., -0.7972,  0.4078,  0.2732],\n",
      "        ...,\n",
      "        [ 0.5687,  1.5506,  0.3509,  ..., -0.9565, -0.1019,  2.1100],\n",
      "        [ 1.0585, -0.4044, -0.1059,  ...,  2.0862, -0.2587, -2.0388],\n",
      "        [-2.2180, -2.0002, -0.0891,  ..., -0.4641, -0.0561, -0.5376]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8448, -1.9444, -1.4938,  ..., -1.5680, -1.3282, -2.7404],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.7754, -0.2929, -0.0887,  ..., -0.1774, -0.7699,  0.7420],\n",
      "        [ 0.5343, -0.6452,  2.0874,  ...,  0.2081, -0.0056, -1.1048],\n",
      "        [-0.1005, -0.1383,  0.8236,  ..., -1.1892, -0.1143, -0.9737],\n",
      "        ...,\n",
      "        [ 0.1410,  0.0881,  1.9677,  ..., -1.8359,  0.7989,  0.0674],\n",
      "        [ 0.7324, -0.5854, -0.4456,  ...,  2.0494, -1.0840,  1.4197],\n",
      "        [ 2.2262,  0.0656,  2.1450,  ...,  1.3144,  0.0261,  1.5134]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6871, -0.9229, -0.5101,  ..., -1.0198, -1.3253, -1.8837],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.3601, -0.0556,  0.6255,  ..., -0.0584, -0.6904,  0.3303],\n",
      "        [-0.8954, -0.8356,  0.2754,  ..., -1.9426, -0.5359, -0.3349],\n",
      "        [-2.2089, -0.0389, -2.0385,  ..., -1.2195, -0.6006, -0.1201],\n",
      "        ...,\n",
      "        [-0.6249,  1.6233, -0.6399,  ..., -1.0147,  0.6064,  1.1233],\n",
      "        [ 0.1254,  1.0021, -0.3039,  ..., -1.3380, -0.2020, -1.9004],\n",
      "        [-0.6503, -0.6158,  0.7617,  ...,  1.9206, -0.9034,  0.8655]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3756, -0.8972, -1.5670,  ..., -1.7944, -1.1436, -1.1287],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.9494, -0.7534,  0.4934,  ...,  1.1459, -1.0575,  1.5522],\n",
      "        [ 1.1754,  0.9499,  1.0961,  ..., -3.7236, -0.4357,  1.0602],\n",
      "        [ 0.7015,  0.7973, -0.2497,  ...,  1.1670, -1.4395,  0.0113],\n",
      "        ...,\n",
      "        [-1.0241,  1.4778, -1.2118,  ...,  1.4554,  0.2632,  0.4215],\n",
      "        [ 1.1848,  1.0412,  1.7401,  ..., -0.2403,  1.0067,  1.5151],\n",
      "        [ 0.0969,  0.2801,  1.2056,  ..., -0.7371,  1.2435, -1.7142]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8997, -2.3791, -1.1644,  ..., -1.4028, -1.3333, -1.2087],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2798,  0.6766, -0.7134,  ..., -0.8868, -0.4031,  0.4872],\n",
      "        [ 0.2183, -1.6582, -0.5422,  ..., -0.6834, -1.5573,  1.5427],\n",
      "        [ 0.1980,  1.8816,  1.4610,  ..., -1.3371, -1.6041, -0.4076],\n",
      "        ...,\n",
      "        [-0.7118, -1.0226, -0.0498,  ...,  0.9211,  2.8352,  0.3510],\n",
      "        [ 1.9131,  0.1291,  1.2091,  ..., -1.7413,  2.1455, -0.1234],\n",
      "        [-1.8288,  0.7966,  0.9837,  ..., -0.5298,  0.1971, -0.2780]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6714, -2.2878, -1.5847,  ..., -1.7070, -2.2330, -1.1467],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1149,  0.3043,  1.6058,  ..., -2.9001,  0.6870, -0.2143],\n",
      "        [-1.9832, -1.7708,  0.2107,  ..., -0.3883,  0.1193,  2.1150],\n",
      "        [-2.1364,  0.7799,  1.7047,  ..., -0.9032, -1.1242,  2.4162],\n",
      "        ...,\n",
      "        [-0.4988,  0.8959, -1.4494,  ..., -0.8310, -1.5515,  1.6564],\n",
      "        [-0.5216,  0.3496, -1.9270,  ...,  1.1132,  1.0409,  0.3874],\n",
      "        [ 0.6417, -1.6278, -0.3944,  ..., -0.5914, -0.7989,  0.7592]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6041, -1.8742, -2.1029,  ..., -1.3678, -1.0091, -0.8691],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.8785, -0.8580,  0.7222,  ..., -0.0822, -2.1056,  0.1275],\n",
      "        [-1.0898,  0.5472, -0.7307,  ..., -2.9404, -1.8526, -1.4225],\n",
      "        [-0.5094, -2.2819, -0.3633,  ..., -0.7121, -1.2929,  0.3812],\n",
      "        ...,\n",
      "        [ 0.2671,  0.7195, -0.4410,  ...,  0.8650, -1.0862, -1.6810],\n",
      "        [ 0.6245,  2.3446,  0.9039,  ...,  1.5433, -1.6237,  0.5436],\n",
      "        [ 0.5905,  1.7095,  3.4492,  ...,  0.9205, -2.7256,  0.3755]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.2652, -2.0381, -1.5657,  ..., -1.6804, -2.0470, -3.3592],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.4562,  1.5264,  0.6555,  ...,  1.2228, -0.5615,  2.5060],\n",
      "        [-0.6150,  0.6776,  1.6068,  ...,  0.1938, -1.8159, -0.9722],\n",
      "        [ 1.7266, -0.4735,  3.1610,  ..., -1.1532,  0.2238, -0.9121],\n",
      "        ...,\n",
      "        [ 1.3848,  0.1006,  0.9271,  ...,  0.0335,  1.9887, -0.3962],\n",
      "        [-0.8576,  0.6409,  0.5766,  ..., -1.1803,  1.1882, -2.3357],\n",
      "        [ 0.9996, -0.2073, -1.2925,  ...,  1.8838,  0.1105,  0.2035]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8933, -1.0121, -2.3532,  ..., -1.0440, -2.3606, -0.9278],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.0617,  2.2821,  1.1117,  ..., -1.0377, -0.1601,  1.7000],\n",
      "        [ 1.2821, -1.2823, -0.3477,  ...,  0.8032, -0.8838, -1.1090],\n",
      "        [ 0.2287,  1.8678,  1.4507,  ...,  0.8296,  0.9433, -1.2670],\n",
      "        ...,\n",
      "        [-0.2519, -0.3590, -0.8724,  ..., -1.4565, -0.8347,  0.3493],\n",
      "        [-1.2778,  0.0162,  0.7572,  ...,  1.0003, -1.5851,  0.8094],\n",
      "        [-1.7264,  0.3062,  1.5284,  ...,  1.0687,  1.7975,  0.9920]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0910, -1.4450, -1.2988,  ..., -0.5745, -0.9789, -1.4967],\n",
      "       device='cuda:0')\n",
      "tensor([[-2.0009, -1.1316, -0.2664,  ..., -0.8083, -1.2365,  2.8495],\n",
      "        [-0.5197, -0.4697, -1.1203,  ...,  0.7951, -1.1314, -2.6306],\n",
      "        [-0.1431,  0.8613, -0.5635,  ...,  0.1825,  0.6357, -2.3614],\n",
      "        ...,\n",
      "        [ 0.5351, -0.0653,  1.7267,  ...,  0.5866, -0.4074,  0.5237],\n",
      "        [-1.0357,  3.2258,  0.7596,  ...,  2.7099,  0.7390,  0.5619],\n",
      "        [ 1.4052,  1.2439,  1.4031,  ...,  0.1977, -0.4220,  0.6541]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0779, -1.4546, -1.0419,  ..., -0.5320, -2.5899, -1.0696],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.0164, -1.9847, -0.7524,  ..., -0.3964,  1.3760, -0.9474],\n",
      "        [ 1.9136, -1.3240, -0.7201,  ..., -0.9178, -2.6406, -1.1657],\n",
      "        [-1.5317,  2.1333, -1.9432,  ...,  0.3625,  2.0953, -1.1431],\n",
      "        ...,\n",
      "        [-0.1314,  0.6088, -0.3984,  ...,  0.0270,  1.5072,  1.0853],\n",
      "        [ 1.4381,  0.0439,  0.5666,  ..., -0.8882, -0.3761, -0.5757],\n",
      "        [-0.2681, -2.5771, -0.3251,  ...,  0.9546, -2.2360,  1.1723]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6350, -2.6011, -2.5877,  ..., -0.5941, -1.0802, -2.5312],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.5435, -0.2925, -1.6823,  ..., -0.4579,  1.9511,  1.1033],\n",
      "        [ 1.4802,  0.4877,  1.6772,  ..., -0.0306,  0.7453,  0.2982],\n",
      "        [ 1.0954,  0.4164, -0.7686,  ..., -0.1549, -0.5664,  0.8738],\n",
      "        ...,\n",
      "        [-0.6692,  0.6766, -0.3547,  ...,  2.0032, -1.5198,  2.1669],\n",
      "        [-1.5534, -0.7056, -0.7749,  ...,  0.6518, -1.5376,  0.9189],\n",
      "        [-0.2208,  0.4248,  1.5488,  ...,  1.2625,  0.4749, -0.5272]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5490, -1.4713, -1.2059,  ..., -1.7343, -0.9959, -0.9640],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.4326, -0.7331,  0.9385,  ..., -0.6167,  1.7537,  1.1947],\n",
      "        [-1.7959, -0.7158,  1.8521,  ...,  1.1614, -1.4757, -0.8518],\n",
      "        [ 1.1004,  0.7173, -1.0425,  ...,  1.1253,  0.0566,  2.1190],\n",
      "        ...,\n",
      "        [ 0.9888, -0.1733, -0.4420,  ...,  1.9244,  1.1503, -1.4032],\n",
      "        [ 0.8019,  3.0270, -2.4403,  ...,  1.5873, -0.1143,  1.8430],\n",
      "        [-0.2956, -0.5329,  0.8457,  ...,  0.3923, -1.0367, -0.7721]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5914, -1.6015, -1.4345,  ..., -2.1251, -2.7499, -0.6604],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.9750,  0.3412, -0.0323,  ...,  1.1998,  0.3532, -0.1898],\n",
      "        [-1.4546, -1.1301,  0.2475,  ..., -0.9006,  0.1664, -1.0959],\n",
      "        [ 0.5762, -0.1889, -1.1698,  ..., -0.8741, -0.3378, -0.2744],\n",
      "        ...,\n",
      "        [-0.1918,  1.0333, -0.3221,  ...,  0.0535,  0.4037,  1.1702],\n",
      "        [ 0.3676,  0.2681, -0.0475,  ..., -1.0462, -1.4399,  1.6126],\n",
      "        [ 0.4742,  0.7946, -0.2474,  ...,  0.0941,  0.8278,  0.6766]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4778, -0.8496, -1.4864,  ..., -0.3804, -1.0320, -0.7874],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8778, -0.8546, -0.0631,  ...,  1.0990, -1.8059,  0.2732],\n",
      "        [-1.9993,  0.9088, -1.3027,  ..., -3.0706, -2.1709, -0.9914],\n",
      "        [-0.5389, -0.0516,  0.1964,  ...,  2.3392, -1.1780, -0.1901],\n",
      "        ...,\n",
      "        [-0.0658, -0.5208, -0.5526,  ...,  0.0602, -1.1213, -1.3662],\n",
      "        [ 0.6341,  0.4096,  0.6623,  ...,  1.9572, -0.6856, -1.3405],\n",
      "        [ 0.2584,  1.1323, -0.4794,  ..., -0.0169, -0.5849,  1.0625]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9167, -2.8192, -1.2112,  ..., -0.6204, -1.7368, -0.4148],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1693,  2.0648, -0.5754,  ..., -0.9219,  0.6772, -0.6694],\n",
      "        [-1.2027,  0.7962, -1.2089,  ..., -1.1580, -2.7946, -0.1043],\n",
      "        [ 0.1134, -0.9386,  0.6065,  ...,  0.4073,  0.1928,  0.6744],\n",
      "        ...,\n",
      "        [ 1.9875, -2.1572,  1.3996,  ..., -1.4684,  0.5614,  0.5732],\n",
      "        [-1.2453,  0.6677,  1.1331,  ..., -0.3600,  1.6424,  0.7486],\n",
      "        [-0.0351,  0.7568,  1.6132,  ...,  0.1173, -1.0536,  1.6575]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4799, -1.7849, -0.9344,  ..., -1.9759, -1.5995, -1.0003],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.5208, -0.1932, -0.1330,  ..., -0.5130,  0.5092,  1.7278],\n",
      "        [ 1.3888, -1.0292, -0.4533,  ...,  3.1183, -1.3469,  0.2112],\n",
      "        [-0.3438, -0.7046, -0.0061,  ..., -1.8197, -0.5323, -1.3768],\n",
      "        ...,\n",
      "        [ 1.5592,  0.3062, -1.0356,  ..., -2.5712,  0.2151, -0.4627],\n",
      "        [-0.9814,  1.8824, -2.2709,  ...,  1.8527, -0.0382, -1.6008],\n",
      "        [-1.2040,  0.6916,  1.3922,  ...,  1.6770, -0.5258,  1.1570]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4424, -2.1801, -1.1969,  ..., -2.0383, -2.8658, -1.3857],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.8877,  0.6910, -1.3962,  ...,  1.7690,  0.6198, -1.2372],\n",
      "        [ 0.8410, -1.8566, -1.2730,  ..., -0.5194,  0.5213, -0.5739],\n",
      "        [-0.4223,  1.1589,  0.5571,  ..., -1.7956,  0.0418, -1.0262],\n",
      "        ...,\n",
      "        [ 0.0576,  0.9136, -0.0831,  ..., -1.0621,  0.4644,  3.3850],\n",
      "        [ 0.1381,  0.3461, -2.8159,  ..., -0.9642, -0.5800, -0.8851],\n",
      "        [ 0.2517,  1.1311,  2.7067,  ..., -0.5289, -0.1097, -1.0861]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5827, -1.1424, -0.8982,  ..., -2.0960, -2.4193, -1.6114],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.3635,  0.2220,  1.2640,  ..., -0.2219,  0.0861,  0.3138],\n",
      "        [-0.6640, -1.1342, -1.2839,  ..., -0.4632, -0.0480, -0.1331],\n",
      "        [ 0.7254, -0.6082,  0.8942,  ...,  0.6245,  1.8319,  1.0257],\n",
      "        ...,\n",
      "        [ 0.7173, -0.8910,  2.1600,  ..., -0.0703,  1.2053,  0.9822],\n",
      "        [ 0.1729,  1.6684,  0.0818,  ...,  1.3107, -1.7723, -0.4195],\n",
      "        [-0.2022,  1.3851,  3.1558,  ..., -0.1222,  1.1609,  1.3863]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6350, -1.3706, -2.0281,  ..., -1.2348, -1.1393, -1.9150],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.9788, -0.8195,  0.8125,  ..., -2.2425, -2.3897,  1.1062],\n",
      "        [-1.6068,  1.3974, -0.6679,  ...,  0.1129, -0.5368,  0.3103],\n",
      "        [-0.6438, -2.4331, -1.4519,  ...,  1.6273, -0.9430, -0.8532],\n",
      "        ...,\n",
      "        [ 0.1030, -0.6566,  0.8591,  ...,  0.2685, -1.7433, -0.2749],\n",
      "        [-1.5748,  1.2421,  0.1542,  ...,  0.9331, -1.4208,  1.1111],\n",
      "        [-0.0195, -1.3094,  1.0048,  ..., -2.4134, -1.2185,  0.8332]],\n",
      "       device='cuda:0')\n",
      "tensor([-3.1005, -0.9471, -1.6828,  ..., -0.8288, -1.2223, -1.5501],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.5158, -0.8777, -0.9470,  ...,  0.3305, -1.1989, -1.5074],\n",
      "        [-0.4190, -1.1174,  0.3382,  ..., -1.6525,  1.5332,  1.4670],\n",
      "        [-0.8723, -0.8067,  2.2257,  ...,  0.5886,  1.0131,  0.9710],\n",
      "        ...,\n",
      "        [-0.0747,  1.6230,  1.3689,  ...,  0.2131, -0.5818, -1.2364],\n",
      "        [-2.0852, -0.8973,  0.3862,  ...,  0.7656, -1.1489, -0.2685],\n",
      "        [ 1.7080,  1.0789, -1.4169,  ..., -0.3504, -0.9235,  1.1010]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3421, -1.2698, -1.8987,  ..., -1.4738, -0.9358, -1.3688],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.0336,  1.8525,  0.2393,  ..., -0.4234,  1.6337,  0.5100],\n",
      "        [ 1.4808, -2.6451, -1.5180,  ..., -0.4687, -0.8739,  0.4831],\n",
      "        [ 1.1000,  0.3208, -1.8690,  ..., -2.1219,  0.0594, -1.5776],\n",
      "        ...,\n",
      "        [ 1.1697,  1.5386,  0.1100,  ..., -0.5696,  0.7863, -0.3399],\n",
      "        [-1.0674,  0.2812,  0.3720,  ...,  0.9214, -0.8783,  2.5175],\n",
      "        [ 0.2334, -1.0054,  0.6603,  ...,  0.5662,  1.8482, -0.6640]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3961, -1.6097, -2.0033,  ..., -0.9341, -1.7695, -1.8295],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3.0698,  0.8304, -0.0628,  ..., -1.1201,  0.9256, -0.7370],\n",
      "        [ 2.4360, -0.4575, -0.4290,  ...,  0.5436, -1.5449, -2.1267],\n",
      "        [-3.1525, -0.9588, -0.7672,  ...,  0.5880,  0.5629,  0.6937],\n",
      "        ...,\n",
      "        [ 0.1286, -2.0649,  1.4226,  ...,  0.6250,  0.0455,  1.3886],\n",
      "        [-1.0568,  1.0226,  2.0340,  ...,  1.8516,  0.0094,  1.0528],\n",
      "        [ 0.2681, -1.9101,  0.9685,  ...,  1.8361, -0.6940,  0.3194]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.3279, -2.1925, -1.9041,  ..., -1.8253, -1.4545, -1.0782],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.3717, -0.0066, -0.7634,  ...,  0.4800,  0.8726,  0.0212],\n",
      "        [ 0.4605, -0.8708, -0.3294,  ..., -0.5021,  0.3485,  1.4171],\n",
      "        [-0.8129, -1.0357,  1.4701,  ..., -1.3231,  0.8940, -1.0774],\n",
      "        ...,\n",
      "        [ 1.4307,  1.2778,  1.2855,  ...,  0.4424,  0.0859,  0.5863],\n",
      "        [-1.0524,  2.1157, -0.3195,  ...,  2.6989,  0.4866, -1.1173],\n",
      "        [-0.5454, -0.0117,  1.6028,  ..., -0.0915, -0.0470,  0.6834]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0275, -2.0348, -1.0147,  ..., -0.7437, -2.2063, -0.7875],\n",
      "       device='cuda:0')\n",
      "tensor([[-2.0059,  0.7888, -0.1716,  ..., -3.2722, -0.9707, -0.0128],\n",
      "        [ 0.1407, -1.6219,  1.8321,  ..., -1.6424, -0.1850,  0.4713],\n",
      "        [ 0.9193, -0.3950, -1.3313,  ...,  2.1450, -1.4462,  1.8652],\n",
      "        ...,\n",
      "        [ 0.4203,  1.6432, -0.1747,  ...,  0.8482, -1.3188,  1.2211],\n",
      "        [ 0.7025,  1.4688, -0.3967,  ..., -0.2107,  2.3443,  0.5212],\n",
      "        [-2.2693,  0.3155,  0.0812,  ..., -1.4997, -0.4557,  1.7630]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.3155, -1.3108, -1.8736,  ..., -1.0374, -1.2215, -1.4815],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8444, -0.7324,  1.5681,  ..., -0.2865, -0.2544,  2.1763],\n",
      "        [-1.1696,  1.0972, -1.9134,  ..., -1.5707,  1.2591,  0.5008],\n",
      "        [ 0.6904, -1.1778,  0.3262,  ...,  0.0456, -0.2602, -1.5567],\n",
      "        ...,\n",
      "        [-1.2771,  0.2108, -0.3960,  ...,  0.5309, -1.6940,  1.7190],\n",
      "        [ 1.2956,  1.5404,  0.6945,  ..., -0.8581,  0.1826, -0.9684],\n",
      "        [ 0.9188, -0.7849,  1.0175,  ..., -0.1866, -0.6002, -2.3402]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4083, -1.7526, -1.1481,  ..., -1.6314, -1.0479, -1.4567],\n",
      "       device='cuda:0')\n",
      "tensor([[-2.3660, -0.3842,  0.2166,  ...,  2.7504,  0.1276,  1.4105],\n",
      "        [-1.1322, -0.1721, -0.5288,  ..., -0.8820,  0.2340,  0.9683],\n",
      "        [-1.7330, -0.9501, -0.5591,  ..., -1.5482, -2.1598,  0.5841],\n",
      "        ...,\n",
      "        [-0.3998, -1.2728, -2.8900,  ..., -0.0900, -0.7890,  2.3570],\n",
      "        [-1.1526,  2.4834,  0.1124,  ..., -0.3254, -1.6334, -1.2698],\n",
      "        [ 0.1994, -0.6213, -0.7591,  ...,  1.0708,  1.4143,  1.0302]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.6692, -0.7006, -1.7332,  ..., -2.1637, -1.6016, -1.1807],\n",
      "       device='cuda:0')\n",
      "tensor([[-3.0135e-01,  8.7706e-03, -1.8808e+00,  ...,  9.8560e-01,\n",
      "          7.1520e-01,  2.2628e+00],\n",
      "        [ 1.5104e+00,  1.5409e+00, -1.1037e+00,  ...,  1.0857e+00,\n",
      "         -3.2502e-02,  5.8238e-01],\n",
      "        [-9.6935e-01,  1.6172e+00,  5.6885e-01,  ..., -7.3792e-01,\n",
      "         -9.8886e-02, -2.2227e+00],\n",
      "        ...,\n",
      "        [ 2.2810e+00,  1.3164e+00, -5.0896e-01,  ...,  1.1539e+00,\n",
      "         -1.0543e+00, -7.5981e-01],\n",
      "        [-1.5479e+00,  8.4908e-02, -2.5378e+00,  ...,  3.4306e-01,\n",
      "         -2.3965e-01,  2.1663e-03],\n",
      "        [ 3.0134e+00, -5.6491e-01,  5.6939e-01,  ...,  2.9519e-01,\n",
      "         -1.7379e+00, -2.3073e+00]], device='cuda:0')\n",
      "tensor([-1.3705, -1.1065, -1.5814,  ..., -1.4851, -1.2355, -3.3150],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8395,  1.5190,  0.6829,  ..., -0.7014,  0.6175,  0.0346],\n",
      "        [-2.5517, -1.0811,  0.5428,  ...,  1.2383, -0.2840, -0.6602],\n",
      "        [ 1.8069,  0.8111, -1.6921,  ..., -0.2031, -1.1310,  1.1095],\n",
      "        ...,\n",
      "        [ 0.3147,  2.2330, -0.0065,  ...,  0.7370, -0.3569, -0.4715],\n",
      "        [-1.0767,  1.5759, -0.6762,  ..., -0.2072,  0.1395, -1.9529],\n",
      "        [-0.6189,  0.3386,  0.1934,  ...,  0.3923, -1.3615, -0.5043]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6282, -1.9741, -1.2211,  ..., -0.7763, -2.3236, -0.4973],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8552, -0.4626, -1.9948,  ...,  0.5170, -0.6589,  0.8663],\n",
      "        [-1.1660, -0.5773, -0.6414,  ..., -0.6690, -1.9417,  0.0725],\n",
      "        [ 0.5020,  0.4866,  2.0299,  ...,  0.1478,  0.7005,  0.4398],\n",
      "        ...,\n",
      "        [-0.1475, -1.1858, -1.2776,  ..., -1.5705, -2.2455,  2.0112],\n",
      "        [-0.3261,  0.2881,  0.9063,  ..., -0.1425, -1.2730, -0.5836],\n",
      "        [-0.7081, -0.9926,  1.0987,  ...,  0.5808, -2.8888, -0.6112]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9064, -1.8565, -1.2638,  ..., -1.9577, -0.6452, -1.6590],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.8161,  0.0276,  1.5428,  ...,  0.2179,  0.6563,  0.4457],\n",
      "        [ 0.5521, -0.6437,  1.0253,  ..., -2.4784,  0.1283, -0.3939],\n",
      "        [ 0.8001,  0.2769, -0.2198,  ..., -0.0905,  1.4559, -1.1790],\n",
      "        ...,\n",
      "        [-1.4458,  0.1584, -0.0936,  ...,  1.6465, -0.7000,  0.0890],\n",
      "        [ 1.7419, -0.8902, -0.7022,  ..., -1.2585, -2.3741, -1.3471],\n",
      "        [ 0.0253,  1.3256,  1.9709,  ...,  3.2640,  0.0701,  0.0481]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1539, -1.0166, -0.9862,  ..., -0.8403, -1.7939, -2.1198],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1244, -2.4233,  1.7042,  ..., -0.5586, -2.0028,  1.2645],\n",
      "        [-0.7230, -0.5953,  1.0226,  ..., -0.8011,  1.0647,  0.2735],\n",
      "        [ 1.2740,  2.4470,  1.1557,  ..., -1.4960, -0.6169,  1.4634],\n",
      "        ...,\n",
      "        [ 1.5418,  0.2466,  0.6604,  ..., -2.0871, -2.9255,  1.4231],\n",
      "        [ 0.9110, -0.6006,  0.6727,  ...,  0.2630,  1.1332,  0.9795],\n",
      "        [-1.1183,  1.2232,  0.1260,  ..., -0.9882, -0.9203,  0.6425]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1887, -0.9850, -1.9613,  ..., -2.4404, -1.0262, -0.7394],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7671,  0.6135,  1.0722,  ...,  0.3066,  1.6931,  0.9676],\n",
      "        [-2.3835, -0.8200, -1.8987,  ..., -1.5125,  0.8334, -1.0763],\n",
      "        [ 1.1926,  0.1621,  1.0961,  ...,  2.6171,  0.1138,  0.1881],\n",
      "        ...,\n",
      "        [-1.6144,  0.5012,  1.6205,  ..., -0.8043, -2.3669,  2.2588],\n",
      "        [ 1.7302,  0.5896,  2.0481,  ...,  0.5962,  0.4788,  1.0450],\n",
      "        [ 0.7317,  1.1407, -0.2422,  ..., -1.4976,  0.6644,  0.1709]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8636, -2.6280, -1.8361,  ..., -2.5362, -1.5619, -0.8750],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.1991, -1.3731,  0.8093,  ...,  0.7765,  1.1591, -1.2716],\n",
      "        [-1.0357,  1.7051,  0.6158,  ...,  0.9028, -2.0188,  0.5919],\n",
      "        [-1.5104, -2.9858, -0.4557,  ...,  1.1335, -2.6969, -1.1228],\n",
      "        ...,\n",
      "        [ 0.8752,  1.0484, -0.1538,  ..., -0.1250, -1.8974, -0.1139],\n",
      "        [ 0.0390,  1.9689, -0.4105,  ..., -2.4728, -0.3593, -0.2110],\n",
      "        [ 1.0253,  1.5484,  2.2057,  ..., -0.9626,  0.5603, -0.7520]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7260, -1.6677, -2.7472,  ..., -0.8306, -1.3892, -1.4944],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8098,  0.2289, -2.1862,  ...,  1.6534,  2.8371,  1.3771],\n",
      "        [-2.6571,  3.1009,  1.9776,  ..., -1.5936, -1.9320, -0.7018],\n",
      "        [ 1.3128, -0.4542, -0.6877,  ..., -0.9591, -2.2204,  1.3345],\n",
      "        ...,\n",
      "        [ 0.7758,  0.0853,  1.1618,  ..., -0.2921, -1.4289,  1.0276],\n",
      "        [ 1.1441, -1.1671,  2.8856,  ...,  0.1389, -0.7944,  1.8906],\n",
      "        [ 0.5463, -1.7685, -1.0252,  ...,  0.9200, -3.3879,  0.4986]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.2836, -4.3102, -1.6852,  ..., -1.3978, -1.9204, -2.8063],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.3866e+00, -1.3406e+00,  8.0697e-01,  ...,  2.3184e+00,\n",
      "          1.5641e+00,  2.9740e-01],\n",
      "        [ 1.4961e+00, -4.9996e-01,  1.5284e+00,  ...,  5.4238e-02,\n",
      "         -1.5515e+00, -2.2781e+00],\n",
      "        [-1.6414e-01,  1.5948e+00, -1.2440e+00,  ..., -3.3682e-01,\n",
      "         -2.8271e-02, -5.2434e-01],\n",
      "        ...,\n",
      "        [-1.7948e-01, -1.3281e+00, -8.7164e-01,  ...,  3.2404e+00,\n",
      "         -5.3816e-01,  1.6625e+00],\n",
      "        [-8.2161e-01, -3.1717e-01,  1.7976e+00,  ..., -1.0499e+00,\n",
      "         -1.5278e+00,  5.2706e-01],\n",
      "        [-4.1738e-04,  5.9989e-03,  6.6660e-01,  ...,  1.2670e+00,\n",
      "         -1.2672e+00,  1.6368e+00]], device='cuda:0')\n",
      "tensor([-1.7665, -3.5994, -0.8939,  ..., -2.5413, -1.6716, -1.8911],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0394, -0.0133, -0.6703,  ..., -0.8556,  0.6331, -1.1354],\n",
      "        [-0.9479, -0.5391,  1.2882,  ...,  0.5424, -0.9768,  1.9491],\n",
      "        [ 1.9762, -0.4075,  0.9204,  ...,  1.4087,  0.1352, -1.1081],\n",
      "        ...,\n",
      "        [ 0.0742, -0.0841,  1.1420,  ..., -1.6942, -0.1449, -0.7275],\n",
      "        [-2.7873, -0.9177,  0.4043,  ...,  0.9557,  0.2502,  0.0538],\n",
      "        [ 1.4268, -1.0639,  0.0772,  ...,  0.4604, -1.3596,  0.7885]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5042, -3.0719, -1.0212,  ..., -0.6556, -1.9735, -0.8112],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.6454, -0.8503,  0.1305,  ...,  1.7036, -1.9524, -0.4014],\n",
      "        [-0.9586,  2.2494, -1.3321,  ..., -0.9441, -0.2699,  1.2052],\n",
      "        [ 0.9412, -2.0436, -1.0287,  ...,  0.3673,  1.4701,  0.0417],\n",
      "        ...,\n",
      "        [ 2.7151, -0.0849,  0.3978,  ..., -0.4914, -2.2745, -1.2058],\n",
      "        [ 1.3732, -1.4679, -1.4147,  ...,  0.2582, -0.4423,  0.5483],\n",
      "        [-0.6482,  1.5444,  0.9668,  ...,  0.7178,  1.0294,  0.3020]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4527, -1.4392, -1.1232,  ..., -1.8296, -1.0334, -1.4122],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.8360,  1.8727, -1.3159,  ..., -0.7020,  2.7070, -1.1177],\n",
      "        [-0.4325,  0.3421,  1.3448,  ..., -2.0265, -0.6947,  1.2418],\n",
      "        [ 0.2250,  2.0529,  0.5592,  ..., -1.4197,  0.3438, -0.5873],\n",
      "        ...,\n",
      "        [ 1.0596, -0.5073,  1.5846,  ...,  0.2414,  0.8709, -0.1526],\n",
      "        [-0.1867,  0.6654, -0.1885,  ...,  0.6639, -1.2628, -0.5081],\n",
      "        [-0.1028,  2.3393,  4.3296,  ...,  0.6319, -1.7268, -0.1168]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.7343, -1.2575, -0.8843,  ..., -1.0206, -0.3572, -3.4948],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.5036,  0.2511,  1.4576,  ...,  0.5777,  0.3487,  0.3695],\n",
      "        [-1.5407, -0.6550,  0.6470,  ...,  1.0525, -0.6278,  0.0471],\n",
      "        [ 0.9521,  0.5930, -0.0802,  ...,  0.1989, -0.1398, -0.3816],\n",
      "        ...,\n",
      "        [ 0.4070,  1.7234,  1.9027,  ...,  1.4470,  0.0528,  0.0056],\n",
      "        [-0.5043, -2.7234, -1.2639,  ..., -2.2576, -0.8887,  1.7249],\n",
      "        [ 1.0146, -0.6624, -0.2210,  ..., -1.2365,  0.8502,  0.3004]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5758, -0.5946, -1.1237,  ..., -2.3902, -2.3091, -0.5582],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.9291,  1.1036,  0.3007,  ..., -0.2897,  1.2577, -1.6517],\n",
      "        [-0.9837, -0.8038,  2.9373,  ..., -0.8853, -1.1221, -1.9387],\n",
      "        [ 0.6848, -2.1007, -0.1199,  ..., -0.9333, -2.2372,  0.8321],\n",
      "        ...,\n",
      "        [ 0.6129,  0.8872,  0.2785,  ..., -2.9667, -1.2141, -0.2441],\n",
      "        [ 1.9179,  0.2508, -0.4264,  ..., -1.2937, -0.1807,  2.1733],\n",
      "        [ 0.4617,  1.8899,  1.1155,  ...,  0.6660, -0.7214,  1.4838]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1652, -2.5311, -1.9628,  ..., -1.9821, -1.3456, -1.3061],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6180, -3.4015, -0.9614,  ...,  0.6092,  1.1637, -0.3718],\n",
      "        [-1.1857, -0.2277, -0.8443,  ..., -0.8627,  0.5758, -1.6756],\n",
      "        [ 1.7805, -1.3549, -2.4143,  ...,  0.3671, -0.8441,  1.1855],\n",
      "        ...,\n",
      "        [ 1.5729,  0.7846,  1.9760,  ..., -0.6057, -0.4110, -1.3684],\n",
      "        [ 1.9532, -1.0896,  0.4167,  ...,  0.0638,  0.7842,  0.4669],\n",
      "        [ 1.0505, -0.8093,  0.8799,  ..., -0.5008,  2.2793,  2.5712]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1638, -1.0537, -2.5580,  ..., -1.3210, -1.3401, -2.2495],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3653, -0.2654,  1.2852,  ...,  0.5236, -0.8339,  0.5292],\n",
      "        [-1.7354, -1.3462,  0.7999,  ..., -1.0182, -1.6277, -0.0913],\n",
      "        [-4.4121,  0.8496,  0.8942,  ...,  3.3106,  0.6017, -2.3039],\n",
      "        ...,\n",
      "        [-1.7179, -0.0876, -0.2899,  ..., -0.6149, -1.1567, -0.1001],\n",
      "        [ 0.3733,  0.8626,  0.1591,  ..., -0.8642,  0.4085, -1.3482],\n",
      "        [ 1.0133,  0.0142, -0.9447,  ...,  0.8780,  1.2065,  0.7173]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4553, -1.4924, -4.7858,  ..., -0.6985, -0.8263, -1.0143],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.2513, -0.0206,  0.5825,  ...,  0.5211, -0.9975, -0.0243],\n",
      "        [-0.1761,  0.6646, -0.8535,  ...,  0.4960,  1.5866,  1.0119],\n",
      "        [-1.1647,  0.9930,  0.7411,  ..., -0.8066,  0.2739, -0.0620],\n",
      "        ...,\n",
      "        [-0.7295,  0.3474, -1.8737,  ..., -0.0919, -0.9606, -1.7636],\n",
      "        [-1.6787,  1.4454, -1.0889,  ...,  1.0322,  1.5429, -0.0848],\n",
      "        [ 1.7862,  0.5435,  1.0014,  ...,  1.5362,  0.3988, -1.7577]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3566, -0.7423, -0.5268,  ..., -1.0424, -1.9006, -1.9893],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7110,  0.1952, -1.5192,  ..., -0.9493,  0.7615, -0.1448],\n",
      "        [-0.2627,  0.7435, -1.2286,  ..., -1.6968, -0.2058, -1.3084],\n",
      "        [ 1.2229,  0.6094,  0.6268,  ...,  0.0179,  0.1858,  2.2572],\n",
      "        ...,\n",
      "        [-0.7496, -1.7585, -1.5535,  ...,  0.0120,  0.9846, -1.9406],\n",
      "        [-0.0283,  0.6322,  0.8388,  ...,  0.9031, -0.4784, -0.9889],\n",
      "        [ 0.0945,  1.0936,  1.9645,  ...,  0.6521,  0.5228,  0.4192]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7934, -2.9594, -1.4549,  ..., -1.6132, -0.3975, -1.9634],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0317,  2.0001,  1.4712,  ...,  0.0373,  0.8819, -0.7479],\n",
      "        [ 1.0044, -0.4387,  1.4912,  ..., -1.1856,  0.8121, -1.3999],\n",
      "        [ 1.1975,  1.0348,  1.6347,  ...,  0.6972,  0.7368, -2.2331],\n",
      "        ...,\n",
      "        [ 1.9711, -0.5948, -0.9603,  ...,  1.2376, -1.1836, -0.0218],\n",
      "        [-1.7148,  1.3957,  0.9533,  ...,  0.6722, -0.2183,  0.4255],\n",
      "        [-0.6324, -0.0335, -0.3461,  ...,  1.9372, -2.2838,  0.5242]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2282, -1.6126, -1.4413,  ..., -2.0562, -0.9341, -1.3882],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.1271,  0.1043,  0.0271,  ...,  0.5360,  1.8402, -1.3104],\n",
      "        [ 1.5253, -0.9874,  2.2454,  ..., -1.0588, -0.9732,  0.4666],\n",
      "        [ 2.3483, -1.7775, -0.2701,  ..., -3.8352, -2.6723, -1.6612],\n",
      "        ...,\n",
      "        [ 0.4087,  0.6265,  1.5476,  ..., -0.8728, -1.6605, -1.0042],\n",
      "        [-1.0010, -0.2508,  0.0401,  ...,  0.6695, -1.8051, -0.3926],\n",
      "        [ 1.4351,  2.9473,  1.3060,  ..., -0.2887,  0.9254,  0.8633]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8629, -1.4366, -4.3028,  ..., -1.1612, -1.4385, -2.1110],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.1974e+00, -8.5833e-01,  7.5275e-01,  ...,  2.3655e+00,\n",
      "          1.0339e-02, -1.0186e+00],\n",
      "        [-1.1129e+00, -4.2502e-01,  1.3222e+00,  ...,  1.9775e+00,\n",
      "          8.0701e-03, -8.9559e-01],\n",
      "        [-1.9829e+00, -2.2785e+00,  1.0176e+00,  ..., -6.3744e-02,\n",
      "          9.5617e-01, -2.3793e+00],\n",
      "        ...,\n",
      "        [-3.5546e-01, -2.8576e+00, -5.2975e-01,  ..., -1.1113e+00,\n",
      "          1.3169e+00, -3.0398e-05],\n",
      "        [ 2.7548e-01,  1.6302e+00,  7.8945e-01,  ..., -7.3694e-02,\n",
      "         -9.1116e-01, -2.2363e-01],\n",
      "        [-4.8717e-01, -4.2140e-01,  7.4523e-01,  ..., -5.0351e-01,\n",
      "          5.5435e-01,  2.3112e-01]], device='cuda:0')\n",
      "tensor([-2.5276, -1.3615, -2.9224,  ..., -2.0478, -0.6864, -0.5164],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.6086,  1.4022,  1.2600,  ..., -1.1601,  0.5542, -1.8374],\n",
      "        [-0.4801, -0.4466,  0.2882,  ..., -2.9527,  0.1006, -0.0675],\n",
      "        [ 1.0534, -2.1469, -0.5959,  ...,  1.3299, -0.6087,  1.2031],\n",
      "        ...,\n",
      "        [ 0.3568,  1.7320,  1.3449,  ...,  0.0210,  1.1835,  0.5096],\n",
      "        [ 0.1553, -0.9971, -0.7615,  ..., -0.0067,  0.1408, -0.9727],\n",
      "        [ 1.4252, -2.9286,  1.7969,  ..., -1.0069,  1.0840, -0.2866]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4160, -1.3274, -1.2331,  ..., -0.8526, -1.5183, -2.1472],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.3197, -1.2818, -0.9263,  ..., -0.0941,  1.0336,  1.6199],\n",
      "        [-1.4496,  1.1320,  0.8034,  ..., -1.6740,  1.4588,  0.7097],\n",
      "        [ 0.8050, -2.7609,  3.0050,  ...,  0.0594, -2.0476,  0.4832],\n",
      "        ...,\n",
      "        [ 0.4650,  1.2883,  0.3281,  ..., -1.4068, -1.8413,  1.1590],\n",
      "        [ 3.0774, -1.1630, -1.2438,  ..., -0.5432, -0.9516,  1.6270],\n",
      "        [ 0.2034,  0.8448,  0.2479,  ...,  0.5084, -1.7197,  0.8747]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7394, -1.3838, -2.8288,  ..., -1.1379, -2.1527, -0.8875],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.9358, -0.9185, -1.7824,  ...,  0.4690, -0.9384, -0.0680],\n",
      "        [ 0.0324,  1.5138,  1.0812,  ..., -1.3162,  0.1560, -1.5678],\n",
      "        [ 0.4095,  0.1513, -0.3164,  ..., -0.5080, -0.1871,  0.8944],\n",
      "        ...,\n",
      "        [ 1.1200,  0.2609, -0.5526,  ..., -0.8113,  0.9859, -0.9292],\n",
      "        [-1.3815,  0.6294, -3.1052,  ...,  0.5594, -0.7031,  0.3656],\n",
      "        [-0.5417,  1.4496,  1.3579,  ...,  1.4832, -1.6852, -0.0761]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9111, -1.6886, -0.5589,  ..., -1.0061, -2.3310, -1.1993],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.6617,  1.3847,  1.0282,  ..., -0.5360,  0.5670,  0.7964],\n",
      "        [-0.7077,  0.4868,  2.9894,  ..., -1.0302,  0.8449,  2.0985],\n",
      "        [-1.6467, -2.2469, -0.7424,  ..., -0.6240, -1.4315,  2.2536],\n",
      "        ...,\n",
      "        [-0.1867, -0.2834,  0.2233,  ...,  1.0016, -0.8377,  1.5643],\n",
      "        [ 2.1054, -1.9435, -0.0385,  ...,  1.3091,  1.9478,  1.0681],\n",
      "        [-0.9415, -2.4372,  0.8736,  ..., -0.3747, -1.6577,  0.5984]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2633, -2.5096, -2.4884,  ..., -1.5270, -1.9450, -2.8673],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2959,  0.3005, -0.6267,  ..., -1.9597,  2.0873,  0.6075],\n",
      "        [-0.3876, -1.4603,  0.2212,  ..., -1.1944, -0.4873, -0.2238],\n",
      "        [ 0.7032, -1.4149, -0.0975,  ...,  1.5218, -1.1179, -0.3114],\n",
      "        ...,\n",
      "        [-1.1419,  0.7186,  0.7723,  ...,  0.9537,  0.4503,  0.5533],\n",
      "        [-2.4339,  0.8560, -0.9038,  ..., -1.4335,  0.6429,  0.9078],\n",
      "        [-1.6312,  0.9907,  1.4004,  ..., -1.3677,  1.7345,  3.3586]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4146, -0.5206, -0.9607,  ..., -1.2974, -1.4387, -3.1695],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.3899,  1.8354,  0.0106,  ..., -0.1974, -1.5914, -1.1241],\n",
      "        [-0.5975,  1.1703,  0.5286,  ..., -0.6382, -1.3123,  1.7026],\n",
      "        [ 1.5003, -0.8701, -2.0045,  ...,  0.5611,  1.1152, -0.0487],\n",
      "        ...,\n",
      "        [-3.0721,  0.8702,  0.8468,  ...,  1.5947,  0.5401,  0.7191],\n",
      "        [-1.6924,  0.5615, -2.2300,  ...,  0.8753,  1.4187,  1.5459],\n",
      "        [ 0.9669, -1.1621, -0.5961,  ...,  1.5976,  0.2370,  0.1314]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8316, -1.3107, -1.3069,  ..., -1.8510, -2.0306, -1.3229],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2328,  0.5153, -1.6653,  ..., -0.3873, -0.6407, -0.4336],\n",
      "        [-2.4174, -1.8586, -0.7246,  ...,  1.6775, -1.0121, -1.1480],\n",
      "        [ 0.3602, -1.7372,  0.4215,  ...,  1.5998, -1.1692, -0.1046],\n",
      "        ...,\n",
      "        [-0.5179,  1.3629,  1.2268,  ...,  0.3761,  0.2452,  0.4032],\n",
      "        [-0.0042, -1.2941, -0.7650,  ..., -1.3542, -0.8927,  0.5379],\n",
      "        [ 1.5138, -1.6721,  3.2435,  ..., -0.3525,  0.6150,  0.0766]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4225, -2.0476, -1.0033,  ..., -1.4846, -0.7046, -2.4691],\n",
      "       device='cuda:0')\n",
      "ROLLOUT: iterations:    58, total: -0.241, distance:  0.000, pinning:  0.000, origin:  0.000, bound:  0.000, velocity: -0.152, action: -0.090\n",
      "UPDATE: Total:  1.371, PPO:  0.561, critic:  0.822, entropy: -11.360, KL:  3.888, Moving Return Mean: -0.004, Moving Return STD:  0.989, Return Mean: -0.052, Return STD:  0.823, Moving Input Mean:  0.017, Moving Input STD:  1.184, Input Mean:  0.248, Input STD:  7.180, Explained Variance: -0.706\n",
      "tensor([[-1.8508,  0.6980, -0.9820,  ...,  2.4398, -2.0479,  0.4208],\n",
      "        [-1.6519, -0.4088, -0.4052,  ...,  0.5054, -1.4036, -0.6430],\n",
      "        [ 1.7294,  0.6664,  0.7961,  ...,  0.5847, -0.7769, -3.0764],\n",
      "        ...,\n",
      "        [-1.3811,  0.8341,  0.4684,  ..., -0.3134,  1.4834, -1.0328],\n",
      "        [ 0.3356, -1.4771,  0.2348,  ..., -0.2959,  1.4035,  0.7434],\n",
      "        [ 0.4280,  1.0808,  2.4727,  ..., -0.6852, -1.4462,  1.1366]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.4378, -0.8391, -2.3435,  ..., -0.9141, -0.7210, -2.0524],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.4538e+00, -4.0806e-01,  2.0720e+00,  ..., -3.7259e-01,\n",
      "         -5.2581e-01, -2.9680e-01],\n",
      "        [-3.4364e-01, -2.6259e+00, -1.5006e-01,  ..., -6.5023e-04,\n",
      "         -2.3160e-01, -8.6453e-01],\n",
      "        [ 1.8685e-01, -1.9139e-04, -2.2940e-01,  ..., -2.1384e+00,\n",
      "          2.2651e-01, -1.6668e-01],\n",
      "        ...,\n",
      "        [ 1.0179e+00, -9.8260e-01,  2.0827e-01,  ..., -2.0830e+00,\n",
      "          8.8677e-01,  8.8136e-01],\n",
      "        [ 9.8593e-01,  1.0219e+00,  1.1481e+00,  ...,  4.7286e-01,\n",
      "          8.9410e-01, -1.4885e+00],\n",
      "        [ 1.3193e+00,  7.1435e-01, -9.6131e-02,  ..., -9.0078e-01,\n",
      "          5.3967e-01,  8.8210e-02]], device='cuda:0')\n",
      "tensor([-2.0164, -1.3414, -0.7851,  ..., -1.2134, -1.0114, -1.0709],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.1405, -0.4530, -0.7233,  ...,  0.4475, -0.0307, -1.5921],\n",
      "        [-2.0490,  1.5782, -1.5887,  ...,  0.2425,  0.3454, -1.8917],\n",
      "        [ 0.0387, -0.6485,  1.3590,  ..., -1.3573,  0.6251, -0.0024],\n",
      "        ...,\n",
      "        [-0.6449,  1.4092, -2.1920,  ...,  1.5913, -1.2306,  1.0748],\n",
      "        [ 0.3087,  1.1675,  1.6278,  ..., -1.1972,  1.6094,  0.6662],\n",
      "        [-0.4751, -0.5064,  0.0230,  ..., -0.0716, -1.7061, -0.1166]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8285, -1.7717, -0.6608,  ..., -2.6655, -1.4861, -1.2644],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.7802e+00, -9.1697e-01,  6.6824e-01,  ..., -5.8637e-01,\n",
      "          4.6140e-01, -1.2324e+00],\n",
      "        [-7.8870e-01, -1.3109e-02,  1.7153e+00,  ...,  2.6999e-02,\n",
      "         -5.0080e-01,  1.4104e-01],\n",
      "        [-7.7350e-01, -6.2010e-03,  1.2619e+00,  ..., -2.3956e-01,\n",
      "         -1.0558e+00, -1.7264e+00],\n",
      "        ...,\n",
      "        [ 9.7040e-02,  7.3998e-01,  1.6185e-01,  ..., -2.8836e+00,\n",
      "         -1.2391e+00,  1.1996e+00],\n",
      "        [-1.7514e+00,  8.0482e-01, -1.4906e+00,  ..., -2.4035e+00,\n",
      "          3.8205e+00,  2.0338e-03],\n",
      "        [ 1.7443e+00, -3.2788e-01,  1.7415e+00,  ..., -1.2788e+00,\n",
      "         -1.6116e+00, -8.3007e-01]], device='cuda:0')\n",
      "tensor([-1.0951, -0.5605, -0.8890,  ..., -1.5444, -3.6451, -1.6044],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0729,  1.5594,  1.1909,  ..., -2.1798, -0.3853,  0.1406],\n",
      "        [ 0.8246, -0.6201, -0.7071,  ..., -0.0069,  0.2026,  1.5397],\n",
      "        [-1.5113,  1.4817,  0.9331,  ..., -1.0595, -0.3609, -2.4022],\n",
      "        ...,\n",
      "        [-1.2859,  0.8373, -1.3470,  ..., -1.6878,  0.8423, -0.6584],\n",
      "        [-1.0496,  0.1073, -0.1516,  ..., -0.0906, -0.4103,  0.2699],\n",
      "        [-0.5180, -0.7609,  0.8625,  ..., -1.9399,  2.3503,  0.4551]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2400, -1.5111, -2.3278,  ..., -1.1629, -0.7895, -1.4402],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4399,  0.1276,  0.0724,  ...,  0.5747,  1.0115,  1.7787],\n",
      "        [ 0.9110,  1.4047,  1.1053,  ..., -0.8399, -1.4506, -0.6704],\n",
      "        [ 0.4275,  1.2148, -1.3483,  ..., -0.6561,  0.8108, -0.8619],\n",
      "        ...,\n",
      "        [ 0.8442,  2.2707, -0.0971,  ...,  1.7046, -1.1938, -0.2666],\n",
      "        [-1.1803,  1.1383, -0.8954,  ...,  0.9584,  2.2490,  1.8882],\n",
      "        [-0.0325,  2.4084, -0.1485,  ...,  1.0264, -1.3031,  0.8184]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9031, -1.0081, -0.9673,  ..., -1.5398, -1.6636, -1.6571],\n",
      "       device='cuda:0')\n",
      "tensor([[-3.2077e-01, -1.1885e+00, -1.5385e+00,  ...,  6.0035e-01,\n",
      "          4.4703e-04, -8.6444e-01],\n",
      "        [ 2.9828e+00,  2.9103e-01,  1.2500e+00,  ...,  1.9507e+00,\n",
      "         -1.8028e+00,  8.8992e-01],\n",
      "        [ 2.2731e+00,  1.6870e+00, -1.5649e-01,  ..., -1.8749e+00,\n",
      "         -2.1717e-01,  1.1791e+00],\n",
      "        ...,\n",
      "        [-5.6213e-01, -6.1038e-01, -1.0837e-01,  ...,  3.8362e-02,\n",
      "          7.5976e-01, -2.8751e-01],\n",
      "        [-2.2995e-01,  1.7382e+00,  7.6881e-01,  ..., -5.6707e-01,\n",
      "          2.9579e-01,  2.3069e+00],\n",
      "        [ 1.2718e+00,  1.6696e+00,  1.1724e+00,  ...,  1.4116e+00,\n",
      "         -2.3503e+00,  1.6825e+00]], device='cuda:0')\n",
      "tensor([-1.0125, -2.7118, -1.7596,  ..., -0.8564, -1.7590, -2.0999],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2419,  0.0539,  1.0845,  ..., -2.0587,  1.0075, -1.8085],\n",
      "        [-1.7105, -0.9422,  0.1993,  ..., -1.3738,  0.7470, -0.5863],\n",
      "        [ 1.8404,  1.3587, -0.2238,  ...,  0.0975, -1.0498,  1.4006],\n",
      "        ...,\n",
      "        [ 0.3855,  0.5973, -1.3181,  ...,  0.5947, -0.3950, -2.2299],\n",
      "        [-1.9300, -1.0313,  1.0145,  ..., -1.8992, -0.0692,  0.8633],\n",
      "        [-1.2936, -1.9352,  0.6154,  ..., -0.7213, -2.8785,  0.7527]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3296, -0.9593, -1.4255,  ..., -1.0315, -1.4920, -1.9085],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.3160, -0.2274,  0.7544,  ...,  2.2539,  0.5257,  1.0230],\n",
      "        [ 1.9757, -1.3299,  0.8297,  ..., -1.6870,  0.7580,  0.8013],\n",
      "        [-0.1414, -0.7617,  2.3389,  ...,  0.2124, -1.9036,  0.6753],\n",
      "        ...,\n",
      "        [ 0.3385,  0.1022, -1.1465,  ...,  0.8118, -0.5056, -2.2633],\n",
      "        [ 0.0327, -0.7710,  0.2351,  ..., -0.8685,  0.2962, -0.6820],\n",
      "        [-0.5527,  0.5461, -0.2325,  ...,  1.8763,  0.8972, -0.2015]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4271, -1.7138, -1.3837,  ..., -2.4055, -0.3582, -1.2257],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.6540,  1.8589,  1.2308,  ...,  0.4782, -1.8891, -2.1945],\n",
      "        [-0.7440,  1.5630,  0.4207,  ...,  0.2998, -0.2673,  3.2143],\n",
      "        [-0.4532, -0.1615, -1.3557,  ...,  0.0906, -2.2514,  0.0809],\n",
      "        ...,\n",
      "        [-0.0813,  1.4312, -0.5549,  ...,  0.5450, -2.4203,  0.9027],\n",
      "        [ 0.7123, -1.0929,  0.9704,  ...,  1.4590,  0.3352, -0.2687],\n",
      "        [ 0.6911,  0.6239, -0.0602,  ..., -1.0096,  1.3353,  1.7316]],\n",
      "       device='cuda:0')\n",
      "tensor([-2.3535, -1.7377, -1.2136,  ..., -1.5607, -1.3319, -1.4237],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0378, -0.0845, -0.2898,  ..., -1.4018,  0.1770,  0.1916],\n",
      "        [ 0.6872,  0.8672, -1.3252,  ...,  0.9268, -2.5703,  1.6273],\n",
      "        [-1.1072, -2.3818,  1.5925,  ..., -1.1314, -1.3144, -0.1234],\n",
      "        ...,\n",
      "        [-0.2242, -2.4936,  0.3252,  ..., -0.8701, -0.3973,  1.6124],\n",
      "        [-1.3402, -2.3838,  0.5259,  ..., -0.7421,  1.4265, -1.3927],\n",
      "        [ 0.4569, -1.7317, -0.7488,  ..., -0.4871, -0.7739,  0.6064]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3919, -1.7719, -1.9318,  ..., -2.3343, -1.6729, -0.9027],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1833, -0.5916, -0.9170,  ..., -0.6401, -0.7334, -1.8159],\n",
      "        [-1.9562, -0.3653, -3.5952,  ...,  1.4035,  0.5292,  0.8846],\n",
      "        [ 0.4398, -0.1890, -0.4339,  ...,  0.2229,  0.5373,  2.3570],\n",
      "        ...,\n",
      "        [ 1.3509, -0.9986, -1.3427,  ..., -1.1377, -0.5084,  0.1126],\n",
      "        [-0.5182, -0.8671,  0.4191,  ..., -2.0847, -1.0037,  2.8939],\n",
      "        [-0.8523,  0.8153,  0.9610,  ..., -1.2620, -1.8010, -1.2260]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9322, -3.3720, -0.9464,  ..., -0.8210, -2.3419, -1.4606],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.4590, -0.1968, -1.5742,  ..., -1.1334, -0.6142,  1.1924],\n",
      "        [-0.9184, -2.4323,  0.7752,  ..., -2.7760, -0.6581, -3.1833],\n",
      "        [-0.9027,  0.2327,  1.4998,  ...,  1.2426,  1.1785,  0.4425],\n",
      "        ...,\n",
      "        [ 1.3058, -0.0335, -0.9727,  ..., -0.6924,  1.0688,  0.0350],\n",
      "        [-2.0650,  1.0532,  0.3279,  ..., -0.5501, -2.8227, -1.6788],\n",
      "        [-2.0588, -0.5988,  0.2533,  ...,  0.3935,  0.2663, -0.0888]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0033, -4.7207, -1.0915,  ..., -0.5478, -2.7834, -1.0043],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.5845,  0.1553,  0.0105,  ...,  0.5817, -0.5424,  0.5050],\n",
      "        [ 0.8281, -0.2691, -0.6037,  ..., -0.9611, -2.3129, -1.3015],\n",
      "        [-0.0530,  0.7133,  1.2341,  ..., -1.7577, -0.4340,  0.4110],\n",
      "        ...,\n",
      "        [ 0.7379,  0.9801, -0.4381,  ...,  2.0019, -1.6020,  0.8604],\n",
      "        [ 0.5812,  1.0034,  1.3305,  ...,  1.8779, -1.1408, -0.2044],\n",
      "        [-2.4679,  2.9762,  1.3426,  ..., -1.3849, -0.8264,  0.7996]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0275, -1.4631, -0.7602,  ..., -1.1408, -1.8067, -2.7702],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.3137, -0.5312, -1.4151,  ..., -0.3885,  0.0712, -0.2920],\n",
      "        [ 1.5610, -0.2399,  0.6935,  ..., -1.2368, -0.2870,  0.2693],\n",
      "        [ 2.9894, -0.4819, -1.4901,  ...,  0.0297,  0.4983, -0.7624],\n",
      "        ...,\n",
      "        [-1.0257,  1.3243, -1.6639,  ..., -0.8457,  0.4939,  0.3146],\n",
      "        [ 1.0084, -1.6007,  1.2921,  ...,  1.0447, -1.8390,  1.2992],\n",
      "        [-0.2904,  0.6050,  0.8686,  ...,  1.5401,  0.8853,  0.4794]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1199, -0.6961, -2.1135,  ..., -2.1693, -1.5133, -1.7402],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.4792, -0.9076, -3.0198,  ..., -0.9868, -0.3995,  0.2573],\n",
      "        [-0.7550, -0.6281, -2.1840,  ..., -1.6949, -0.2337, -0.2308],\n",
      "        [-1.0384,  0.4996,  1.6204,  ...,  0.9930, -0.5510, -1.6980],\n",
      "        ...,\n",
      "        [ 0.2889, -0.1502, -0.1758,  ..., -0.5820,  1.5820,  0.0197],\n",
      "        [-1.0088, -0.8784, -0.3470,  ..., -0.2996, -0.8943, -2.1975],\n",
      "        [-1.8810,  1.2153,  0.3301,  ...,  0.9185, -0.5850,  0.9896]],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7054, -1.4294, -1.0664,  ..., -0.9065, -1.0468, -0.9218],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m memory\u001b[38;5;241m.\u001b[39mmark_sampled()\n\u001b[1;32m      4\u001b[0m memory\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m----> 5\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mcelltrip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_memories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_timesteps=100,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_on_finish\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROLLOUT: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m 5.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m 5.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m 5.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ret[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()]))\n\u001b[1;32m     11\u001b[0m memory\u001b[38;5;241m.\u001b[39mcompute_advantages()\n",
      "File \u001b[0;32m~/repos/inept/celltrip/train.py:92\u001b[0m, in \u001b[0;36msimulate_until_completion\u001b[0;34m(env, policy, memory, keys, max_timesteps, max_memories, reset_on_finish, cache_feature_embeds, store_states, flush, dummy, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finished:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reset_on_finish:\n\u001b[0;32m---> 92\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m         keys \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_keys()\n\u001b[1;32m     94\u001b[0m         target_modalities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat(env\u001b[38;5;241m.\u001b[39mget_target_modalities(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/repos/inept/celltrip/environment.py:378\u001b[0m, in \u001b[0;36mEnvironmentBase.reset\u001b[0;34m(self, resample, renoise, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, renoise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# Reset modalities if needed\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resample \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m         modalities, adata_obs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_modalities([\n\u001b[1;32m    380\u001b[0m             torch\u001b[38;5;241m.\u001b[39mtensor(m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m modalities],\n\u001b[1;32m    382\u001b[0m             keys\u001b[38;5;241m=\u001b[39madata_obs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_numpy())\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;66;03m# Add randomness to key to avoid culling in memory\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/inept/celltrip/utility/processing.py:686\u001b[0m, in \u001b[0;36mPreprocessFromAnnData._transform_disk\u001b[0;34m(self, return_partition, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m sampled_adata_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msubsample(\n\u001b[1;32m    680\u001b[0m     adata_obs\u001b[38;5;241m=\u001b[39madata_obs,\n\u001b[1;32m    681\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartition_cols,\n\u001b[1;32m    682\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask,\n\u001b[1;32m    683\u001b[0m     return_partition\u001b[38;5;241m=\u001b[39mreturn_partition,\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_partition: sampled_adata_obs, partition \u001b[38;5;241m=\u001b[39m sampled_adata_obs\n\u001b[0;32m--> 686\u001b[0m sampled_modalities \u001b[38;5;241m=\u001b[39m [adata[adata_ob\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_numpy()]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;28;01mfor\u001b[39;00m adata, adata_ob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madatas, sampled_adata_obs)]\n\u001b[1;32m    687\u001b[0m processed_adata_obs \u001b[38;5;241m=\u001b[39m sampled_adata_obs\n\u001b[1;32m    688\u001b[0m processed_modalities, processed_adata_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    689\u001b[0m     sampled_modalities, adata_vars, force_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/repos/inept/celltrip/utility/processing.py:686\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    679\u001b[0m sampled_adata_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msubsample(\n\u001b[1;32m    680\u001b[0m     adata_obs\u001b[38;5;241m=\u001b[39madata_obs,\n\u001b[1;32m    681\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartition_cols,\n\u001b[1;32m    682\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask,\n\u001b[1;32m    683\u001b[0m     return_partition\u001b[38;5;241m=\u001b[39mreturn_partition,\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_partition: sampled_adata_obs, partition \u001b[38;5;241m=\u001b[39m sampled_adata_obs\n\u001b[0;32m--> 686\u001b[0m sampled_modalities \u001b[38;5;241m=\u001b[39m [\u001b[43madata\u001b[49m\u001b[43m[\u001b[49m\u001b[43madata_ob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m adata, adata_ob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madatas, sampled_adata_obs)]\n\u001b[1;32m    687\u001b[0m processed_adata_obs \u001b[38;5;241m=\u001b[39m sampled_adata_obs\n\u001b[1;32m    688\u001b[0m processed_modalities, processed_adata_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    689\u001b[0m     sampled_modalities, adata_vars, force_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/anndata.py:561\u001b[0m, in \u001b[0;36mAnnData.X\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_view:\n\u001b[1;32m    560\u001b[0m     X \u001b[38;5;241m=\u001b[39m as_view(\n\u001b[0;32m--> 561\u001b[0m         \u001b[43m_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adata_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vidx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    562\u001b[0m         ElementRef(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:699\u001b[0m, in \u001b[0;36msubset_sparsedataset\u001b[0;34m(d, subset_idx)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;129m@_subset\u001b[39m\u001b[38;5;241m.\u001b[39mregister(BaseCompressedSparseDataset)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msubset_sparsedataset\u001b[39m(d, subset_idx):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubset_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:460\u001b[0m, in \u001b[0;36mBaseCompressedSparseDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    458\u001b[0m     sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_memory()[row_sp_matrix_validated, col_sp_matrix_validated]\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     sub \u001b[38;5;241m=\u001b[39m \u001b[43mmtx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# If indexing is array x array it returns a backed_sparse_matrix\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Not sure what the performance is on that operation\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# Also need to check if memory format is not matrix\u001b[39;00m\n\u001b[1;32m    465\u001b[0m mtx_fmt \u001b[38;5;241m=\u001b[39m get_memory_class(\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat, use_sparray_in_io\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39muse_sparse_array_on_read\n\u001b[1;32m    467\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/scipy/sparse/_index.py:87\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     85\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_arrayXint(row, col)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arrayXslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# arrayXarray preprocess\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (row\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m row\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (col\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m col\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# outer indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:196\u001b[0m, in \u001b[0;36mbacked_csr_matrix._get_arrayXslice\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idxs\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    194\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(idxs)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ss\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m--> 196\u001b[0m     \u001b[43mget_compressed_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(idxs), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    197\u001b[0m )[:, col]\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:267\u001b[0m, in \u001b[0;36mget_compressed_vectors\u001b[0;34m(x, row_idxs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     indices \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mindices[as_np_indptr]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x\u001b[38;5;241m.\u001b[39mdata[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices])\n\u001b[1;32m    268\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x\u001b[38;5;241m.\u001b[39mindices[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices])\n\u001b[1;32m    269\u001b[0m indptr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(accumulate(chain((\u001b[38;5;241m0\u001b[39m,), (s\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m-\u001b[39m s\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices))))\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/anndata/_core/sparse_dataset.py:267\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m     indices \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mindices[as_np_indptr]\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices])\n\u001b[1;32m    268\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([x\u001b[38;5;241m.\u001b[39mindices[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices])\n\u001b[1;32m    269\u001b[0m indptr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(accumulate(chain((\u001b[38;5;241m0\u001b[39m,), (s\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m-\u001b[39m s\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m indptr_slices))))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/h5py/_hl/dataset.py:802\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 802\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_selector.pyx:376\u001b[0m, in \u001b[0;36mh5py._selector.Reader.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5fd.pyx:162\u001b[0m, in \u001b[0;36mh5py.h5fd.H5FD_fileobj_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/fsspec/spec.py:2101\u001b[0m, in \u001b[0;36mAbstractBufferedFile.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"mirrors builtin file's readinto method\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m \n\u001b[1;32m   2098\u001b[0m \u001b[38;5;124;03mhttps://docs.python.org/3/library/io.html#io.RawIOBase.readinto\u001b[39;00m\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2101\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m out[: \u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/fsspec/spec.py:2083\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   2082\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2083\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2085\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   2086\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m read: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2087\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39m_log_stats(),\n\u001b[1;32m   2091\u001b[0m )\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/site-packages/fsspec/caching.py:880\u001b[0m, in \u001b[0;36mBackgroundBlockCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    877\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockCache waiting for background fetch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# Wait until result and put it in cache\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_block_cached\u001b[38;5;241m.\u001b[39madd_key(\n\u001b[0;32m--> 880\u001b[0m         \u001b[43mfetch_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, fetch_future_block_number\n\u001b[1;32m    881\u001b[0m     )\n\u001b[1;32m    883\u001b[0m \u001b[38;5;66;03m# these are cached, so safe to do multiple calls for the same start and end.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_block_number, end_block_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/ct/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for _ in range(int(config.max_timesteps / config.update_timesteps)):\n",
    "#     # Forward\n",
    "#     memory.mark_sampled()\n",
    "#     memory.cleanup()\n",
    "#     ret = celltrip.train.simulate_until_completion(\n",
    "#         env, policy, memory,\n",
    "#         max_memories=config.update_timesteps,\n",
    "#         # max_timesteps=100,\n",
    "#         reset_on_finish=True)\n",
    "#     print('ROLLOUT: ' + f'iterations: {ret[0]: 5.0f}, ' + f'total: {ret[2]: 5.3f}, ' + ', '.join([f'{k}: {v: 5.3f}' for k, v in ret[3].items()]))\n",
    "#     memory.compute_advantages()\n",
    "\n",
    "#     # Update\n",
    "#     # NOTE: Training often only improves when PopArt and actual distribution match\n",
    "#     ret = policy.update(memory, verbose=False)\n",
    "#     print('UPDATE: ' + ', '.join([f'{k}: {v: 5.3f}' for ret_dict in ret[1:] for k, v in ret_dict.items()]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
