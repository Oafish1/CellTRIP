{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High priority\n",
    "  - Auto set max GPUs for update (?)\n",
    "  - Add node to event log\n",
    "  - Implement stages\n",
    "  - Add checkpoints\n",
    "  - Add model loading\n",
    "  - Add train/val to dataloader\n",
    "  - Partition detection in `train_policy`\n",
    "  - Script arguments, including address for ray\n",
    "- Medium priority\n",
    "  - Eliminate passing of persistent storage for memory objects\n",
    "  - Add hook for wandb, etc.\n",
    "  - Add state manager to env and then parallelize in analysis, maybe make `analyze` function\n",
    "- Low priority\n",
    "  - Seed policy initialization and unseed update, add reproducibility tag to wait for all rollouts before updating\n",
    "  - Verify worker timeout\n",
    "  - Subtract working memory on host node\n",
    "  - Local data loading per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# # TODO: Figure out how to format arguments for appending h5ad files\n",
    "# parser.add_argument('datasets', type=str, required=False, help='.h5ad files to use for data')\n",
    "# parser.add_argument('--concatenate', type=str, required=False, help=\n",
    "#     '.h5ad files to concatenate as a single modality, may be used multiple times')\n",
    "\n",
    "# group = parser.add_argument_group('General')\n",
    "# group.add_argument('--seed', default=42, type=int, help='**Seed for random calls during training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = None\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Construct dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.shutdown(); ray.init(\n",
    "    address='ray://127.0.0.1:10001',\n",
    "    runtime_env={\n",
    "        'env_vars': {\n",
    "            # NOTE: Important, NCCL will timeout if network device is non-standard\n",
    "            'NCCL_SOCKET_IFNAME': 'tailscale',\n",
    "            # 'NCCL_DEBUG': 'WARN',\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "        }})\n",
    "\n",
    "# Initialize distributed manager\n",
    "policy_init, memory_init = celltrip.train.get_train_initializers(\n",
    "    3, [m.shape[1] for m in modalities])\n",
    "distributed_manager = celltrip.train.DistributedManager(\n",
    "    policy_init=policy_init, memory_init=memory_init,\n",
    "    max_jobs_per_gpu=2, update_gpus=1)\n",
    "\n",
    "# Perform training\n",
    "celltrip.train.train_policy(distributed_manager, dataloader, rollout_kwargs={'dummy': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End timer\n",
    "print(f'Ran for {time.perf_counter() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_init = lambda policy, modalities: celltrip.environment.EnvironmentBase(\n",
    "#     *modalities,\n",
    "#     dim=policy.output_dim,\n",
    "#     # max_timesteps=1e2,\n",
    "#     penalty_bound=1,\n",
    "#     device=policy.device)\n",
    "# ray.get(distributed_manager.rollout(\n",
    "#     modalities=modalities,\n",
    "#     keys=adata_obs[0].index.to_numpy(),\n",
    "#     env_init=env_init,\n",
    "#     dummy=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cancel\n",
    "# # dm.cancel()\n",
    "# # dm.clean()\n",
    "# # dm.rollout(dummy=True)\n",
    "# # dm.wait()\n",
    "\n",
    "# # Clear locks\n",
    "# distributed_manager.policy_manager.release_locks.remote()\n",
    "\n",
    "# # Get policy\n",
    "# device = 'cuda'\n",
    "# policy = policy_init().to(device)\n",
    "# celltrip.train.set_policy_state(policy, ray.get(distributed_manager.policy_manager.get_policy_state.remote()))\n",
    "\n",
    "# # Get memory\n",
    "# memory = memory_init(policy)\n",
    "# memory.append_memory(\n",
    "#     *ray.get(distributed_manager.policy_manager.get_memory_storage.remote()))\n",
    "\n",
    "# # Update remote policy\n",
    "# distributed_manager.policy_manager.release_locks.remote()\n",
    "# ray.get(distributed_manager.update())\n",
    "\n",
    "# # Get state of job from ObjectRef\n",
    "# import ray.util.state\n",
    "# object_id = dm.futures['simulation'][0].hex()\n",
    "# object_state = ray.util.state.get_objects(object_id)[0]\n",
    "# object_state.task_status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
