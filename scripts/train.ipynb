{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes model will be chaotic if it finds how to early-finish early on, if so, it waits until action_std is lower to implement\n",
    "- Train/test\n",
    "- Save preprocessing\n",
    "- Early stopping for `train_celltrip` based on action_std and/or KL\n",
    "- Maybe [this](https://arxiv.org/abs/2102.09430) but probably not\n",
    "- [EFS on clusters maybe](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/aws.html#start-ray-with-the-ray-cluster-launcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython is not active\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py s3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad --backed --target_modalities 1 --num_gpus 3 --num_learners 2 --num_runners 9 --steps 9000 --max_updates 50 --dont_sync_across_nodes --logfile s3://nkalafut-celltrip/logs/3gpu-9k-ExtraKL-DontSync.log --checkpoint_dir s3://nkalafut-celltrip/checkpoints --checkpoint_name 3gpu-9k-ExtraKL-DontSync\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "# NOTE: It is not recommended to use s3 with credentials unless the creds are permanent, the bucket is public, or this is run on AWS\n",
    "parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Reading\n",
    "group = parser.add_argument_group('Input')\n",
    "group.add_argument('input_files', type=str, nargs='*', help='h5ad files to be used for input')\n",
    "group.add_argument('--merge_files', type=str, action='append', nargs='+', help='h5ad files to merge as input')\n",
    "group.add_argument('--partition_cols', type=str, action='append', nargs='+', help='Columns for data partitioning, found in `adata.obs` DataFrame')\n",
    "group.add_argument('--backed', action='store_true', help='Read data directly from disk or s3, saving memory at the cost of time')\n",
    "group.add_argument('--input_modalities', type=int, nargs='+', help='Input modalities to give to CellTRIP')\n",
    "group.add_argument('--target_modalities', type=int, nargs='+', help='Target modalities to emulate, dictates environment reward')\n",
    "# Computation\n",
    "group = parser.add_argument_group('Computation')\n",
    "group.add_argument('--num_gpus', type=int, default=1, help='Number of GPUs to use during computation')\n",
    "group.add_argument('--num_learners', type=int, default=1, help='Number of learners used in backward computation, cannot exceed GPUs')\n",
    "group.add_argument('--num_runners', type=int, default=1, help='Number of workers for environment simulation')\n",
    "# Training\n",
    "group = parser.add_argument_group('Training')\n",
    "group.add_argument('--steps', type=int, default=int(5e3), help='Number of steps recorded before each update')\n",
    "group.add_argument('--max_updates', type=int, default=200, help='Maximum number of policy updates to compute before exiting')\n",
    "group.add_argument('--dont_sync_across_nodes', action='store_true', help='Avoid memory sync across nodes, saving overhead time at the cost of stability')\n",
    "# File saves\n",
    "group = parser.add_argument_group('Logging')\n",
    "group.add_argument('--logfile', type=str, default='cli', help='Location for log file, can be `cli`, `<local_file>`, or `<s3 location>`')\n",
    "group.add_argument('--flush_iterations', type=int, help='Number of iterations to wait before flushing logs')\n",
    "group.add_argument('--checkpoint', type=str, help='Checkpoint to use for initializing model')\n",
    "group.add_argument('--checkpoint_iterations', type=int, default=20, help='Number of iterations to wait before recording checkpoints')\n",
    "group.add_argument('--checkpoint_dir', type=str, default='./checkpoints', help='Directory for checkpoints')\n",
    "group.add_argument('--checkpoint_name', type=str, help='Run name, for checkpointing')\n",
    "\n",
    "# Notebook defaults and script handling\n",
    "if not celltrip.utility.notebook.is_notebook():\n",
    "    # ray job submit -- python train.py...\n",
    "    config = parser.parse_args()\n",
    "else:\n",
    "    experiment_name = '3gpu-9k-ExtraKL-DontSync'\n",
    "    command = (\n",
    "        f's3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad '\n",
    "        # f'/home/nck/repos/INEPT/data/MERFISH/expression.h5ad /home/nck/repos/INEPT/data/MERFISH/spatial.h5ad '\n",
    "        f'--backed '\n",
    "        f'--target_modalities 1 '\n",
    "        f'--num_gpus 3 --num_learners 2 --num_runners 9 '\n",
    "        f'--steps 9000 '\n",
    "        f'--max_updates 50 '\n",
    "        f'--dont_sync_across_nodes '\n",
    "        f'--logfile s3://nkalafut-celltrip/logs/{experiment_name}.log '\n",
    "        f'--checkpoint_dir s3://nkalafut-celltrip/checkpoints '\n",
    "        f'--checkpoint_name {experiment_name}')\n",
    "    config = parser.parse_args(command.split(' '))\n",
    "    print(f'python train.py {command}')\n",
    "    \n",
    "# Defaults\n",
    "if config.checkpoint_name is None:\n",
    "    config.checkpoint_name = f'RUN_{random.randint(0, 2**32):0>10}'\n",
    "    print(f'Run Name: {config.checkpoint_name}')\n",
    "# print(config)  # CLI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ray\n",
    "ray.shutdown()\n",
    "a = ray.init(\n",
    "    # address='ray://100.85.187.118:10001',\n",
    "    address='ray://localhost:10001',\n",
    "    runtime_env={\n",
    "        'py_modules': [celltrip],\n",
    "        'pip': '../requirements.txt',\n",
    "        'env_vars': {\n",
    "            # **access_keys,\n",
    "            'RAY_DEDUP_LOGS': '0'}},\n",
    "        # 'NCCL_SOCKET_IFNAME': 'tailscale',  # lo,en,wls,docker,tailscale\n",
    "    _system_config={'enable_worker_prestart': True})  # Doesn't really work for scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1e-4)\n",
    "def train(config):\n",
    "    import celltrip\n",
    "\n",
    "    # Initialization\n",
    "    dataloader_kwargs = {'num_nodes': 200, 'pca_dim': 128}\n",
    "    environment_kwargs = {\n",
    "        'input_modalities': config.input_modalities,\n",
    "        'target_modalities': config.target_modalities, 'dim': 3}\n",
    "    initializers = celltrip.train.get_initializers(\n",
    "        input_files=config.input_files, merge_files=config.merge_files,\n",
    "        backed=config.backed, dataloader_kwargs=dataloader_kwargs,\n",
    "        environment_kwargs=environment_kwargs)\n",
    "\n",
    "    stage_functions = [\n",
    "        # lambda w: w.env.set_rewards(penalty_velocity=1, penalty_action=1),\n",
    "        # lambda w: w.env.set_rewards(reward_origin=1),\n",
    "        # lambda w: w.env.set_rewards(reward_origin=0, reward_distance=1),\n",
    "    ]\n",
    "\n",
    "    # Run function\n",
    "    celltrip.train.train_celltrip(\n",
    "        initializers=initializers,\n",
    "        num_gpus=config.num_gpus, num_learners=config.num_learners,\n",
    "        num_runners=config.num_runners, max_updates=config.max_updates,\n",
    "        sync_across_nodes=not config.dont_sync_across_nodes,\n",
    "        checkpoint_iterations=config.checkpoint_iterations, checkpoint_dir=config.checkpoint_dir,\n",
    "        checkpoint=config.checkpoint, checkpoint_name=config.checkpoint_name,\n",
    "        stage_functions=stage_functions, logfile=config.logfile)\n",
    "\n",
    "ray.get(train.remote(config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get AWS keys\n",
    "# import boto3\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# session = boto3.Session()\n",
    "# creds = session.get_credentials()\n",
    "# access_keys = {\n",
    "#     'AWS_ACCESS_KEY_ID': creds.access_key,\n",
    "#     'AWS_SECRET_ACCESS_KEY': creds.secret_key,\n",
    "#     'AWS_DEFAULT_REGION': 'us-east-2'}\n",
    "\n",
    "# # Check s3\n",
    "# import os\n",
    "# import s3fs\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n",
    "# s3.ls('s3://nkalafut-celltrip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/utility/processing.py:106: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/envs/ct/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # Initialize locally\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# dataloader_kwargs = {'num_nodes': 20, 'pca_dim': 128}\n",
    "# environment_kwargs = {\n",
    "#     'input_modalities': config.input_modalities,\n",
    "#     'target_modalities': config.target_modalities, 'dim': 3}\n",
    "# env_init, policy_init, memory_init = celltrip.train.get_initializers(\n",
    "#     input_files=config.input_files, merge_files=config.merge_files,\n",
    "#     backed=config.backed, policy_kwargs={'minibatch_size': 2_000},\n",
    "#     dataloader_kwargs=dataloader_kwargs,\n",
    "#     environment_kwargs=environment_kwargs)\n",
    "# env = env_init().to('cuda')\n",
    "# policy = policy_init(env).to('cuda')\n",
    "# memory = memory_init(policy)\n",
    "# # celltrip.train.simulate_until_completion(env, policy, memory)\n",
    "# # memory.compute_advantages()\n",
    "# # policy.update(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZING\n",
    "# Removing layer norms helps but doesn't actually reduce time???\n",
    "\n",
    "# # Single iteration\n",
    "# import torch\n",
    "# env.max_timesteps = 1\n",
    "\n",
    "# # Time profile\n",
    "# import time\n",
    "# start = time.perf_counter()\n",
    "# for _ in range(10):\n",
    "#     celltrip.train.simulate_until_completion(env, policy, memory)\n",
    "#     torch.cuda.synchronize()\n",
    "# duration = time.perf_counter()-start\n",
    "# print(f'{int(1000*duration/10)}')\n",
    "\n",
    "# # Torch profile\n",
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "# with profile(activities=[ProfilerActivity.CUDA], record_shapes=True, with_stack=True) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         for _ in range(10):\n",
    "#             celltrip.train.simulate_until_completion(env, policy, memory)\n",
    "#             torch.cuda.synchronize()\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20, max_name_column_width=1000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
