{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Format command with ray submit\n",
    "\n",
    "Checkpoints\n",
    "\n",
    "On-disk reads from s3 (?)\n",
    "\n",
    "[EFS on clusters maybe](https://docs.ray.io/en/latest/cluster/vms/user-guides/launching-clusters/aws.html#start-ray-with-the-ray-cluster-launcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ray\n",
    "\n",
    "import celltrip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "# NOTE: It is not recommended to use s3 with credentials unless the creds are permanent, the bucket is public, or this is run on AWS\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# Important parameters\n",
    "# group = parser.add_argument_group('Input Data')\n",
    "parser.add_argument('input_files', type=str, nargs='*', help='h5ad files to be used for input')\n",
    "parser.add_argument('--merge_files', type=str, action='append', nargs='+', help='h5ad files to merge as input')\n",
    "parser.add_argument('--partition_cols', type=str, action='append', nargs='+', help='Columns for data partitioning, found in `adata.obs` DataFrame')\n",
    "parser.add_argument('--data_in_memory', action='store_true', help='Load data into memory for sampling')\n",
    "parser.add_argument('--download_dir', type=str, default='./downloads', help='Location for data download if needed')\n",
    "parser.add_argument('--logfile', type=str, default='cli', help='Location for log file, can be `cli`, `<local_file>`, or `<s3 location>`')\n",
    "\n",
    "# Notebook defaults and script handling\n",
    "if not celltrip.utility.notebook.is_notebook():\n",
    "    config = parser.parse_args()\n",
    "else:\n",
    "    # python train.py s3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad --logfile s3://nkalafut-celltrip/log.txt\n",
    "    config = parser.parse_args((\n",
    "        's3://nkalafut-celltrip/MERFISH/expression.h5ad s3://nkalafut-celltrip/MERFISH/spatial.h5ad '\n",
    "        '--logfile s3://nkalafut-celltrip/log.txt'\n",
    "        ).split(' '))\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AWS keys\n",
    "# import boto3\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# session = boto3.Session()\n",
    "# creds = session.get_credentials()\n",
    "\n",
    "# Reset Ray\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ray\n",
    "ray.init(\n",
    "    # address='ray://100.85.187.118:10001',\n",
    "    address='ray://localhost:10001',\n",
    "    runtime_env={\n",
    "        'py_modules': [celltrip],\n",
    "        'pip': '../requirements.txt',\n",
    "        'env_vars': {\n",
    "            # Logging\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "            # Networking\n",
    "            # 'NCCL_SOCKET_IFNAME': 'tailscale',  # lo,en,wls,docker,tailscale\n",
    "            # Keys\n",
    "            # 'AWS_ACCESS_KEY_ID': creds.access_key,\n",
    "            # 'AWS_SECRET_ACCESS_KEY': creds.secret_key,\n",
    "            # 'AWS_DEFAULT_REGION': 'us-east-2'\n",
    "        }})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1e-4)\n",
    "def train(config):\n",
    "    import celltrip\n",
    "\n",
    "    # Initialization\n",
    "    def env_init():\n",
    "        # Create dataloader\n",
    "        adatas = celltrip.utility.processing.read_adatas(*config.input_files, on_disk=(not config.data_in_memory), download_dir=config.download_dir)\n",
    "        if config.merge_files is not None:\n",
    "            for merge_files in config.merge_files:\n",
    "                merge_adatas = celltrip.utility.processing.read_adatas(*merge_files, on_disk=(not config.data_in_memory))\n",
    "                adatas += celltrip.utility.processing.merge_adatas(*merge_adatas, on_disk=(not config.data_in_memory))\n",
    "        celltrip.utility.processing.test_adatas(*adatas, partition_cols=config.partition_cols)\n",
    "        dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "            *adatas, partition_cols=config.partition_cols,  num_nodes=200,\n",
    "            pca_dim=128, seed=42)\n",
    "        # modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "        # Return env\n",
    "        return celltrip.environment.EnvironmentBase(\n",
    "            dataloader, dim=3)\n",
    "\n",
    "    # Default ~25Gb Forward, ~16Gb Update, at max capacity\n",
    "    policy_init = lambda env: celltrip.policy.PPO(\n",
    "        2*env.dim, env.dataloader.modal_dims, env.dim)  # update_iterations=2, minibatch_size=3e3,\n",
    "\n",
    "    memory_init = lambda policy: celltrip.memory.AdvancedMemoryBuffer(\n",
    "        sum(policy.modal_dims), split_args=policy.split_args)\n",
    "\n",
    "    initializers = (env_init, policy_init, memory_init)\n",
    "\n",
    "    stage_functions = [\n",
    "        # lambda w: w.env.set_rewards(penalty_velocity=1, penalty_action=1),\n",
    "        # lambda w: w.env.set_rewards(reward_origin=1),\n",
    "        # lambda w: w.env.set_rewards(reward_origin=0, reward_distance=1),\n",
    "    ]\n",
    "\n",
    "    # Run function\n",
    "    # rollout_kwargs={'dummy': True}, update_kwargs={'update_iterations': 5}, sync_across_nodes=False\n",
    "    celltrip.train.train_celltrip(\n",
    "        initializers=initializers,\n",
    "        num_gpus=5,\n",
    "        num_learners=5,\n",
    "        num_runners=5,\n",
    "        updates=10,\n",
    "        stage_functions=stage_functions,\n",
    "        logfile=config.logfile)\n",
    "\n",
    "ray.get(train.remote(config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import s3fs\n",
    "# os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "# s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n",
    "# s3.ls('s3://nkalafut-celltrip')\n",
    "# s3.open('s3://nkalafut-celltrip/test', 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = env_init(parent_dir=True).to('cuda')\n",
    "# policy = policy_init(env).to('cuda')\n",
    "# memory = memory_init(policy)\n",
    "# celltrip.train.simulate_until_completion(env, policy, memory)\n",
    "# memory.propagate_rewards()\n",
    "# memory.normalize_rewards()\n",
    "# # memory.fast_sample(10_000, shuffle=False)\n",
    "# len(memory)\n",
    "\n",
    "# memory.mark_sampled()\n",
    "# env.reset()\n",
    "# celltrip.train.simulate_until_completion(env, policy, memory)\n",
    "# memory.propagate_rewards()\n",
    "# memory.adjust_rewards()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
