{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython is active\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['RAY_DEDUP_LOGS'] = '0'\n",
    "# os.environ['NCCL_DEBUG'] = 'WARN'\n",
    "# os.environ['RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING'] = '1'\n",
    "# export RAY_BACKEND_LOG_LEVEL=debug\n",
    "import functools as ft\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import torch\n",
    "import tqdm.auto\n",
    "import tqdm.notebook\n",
    "tqdm.notebook.tqdm = tqdm.auto.tqdm  # Enable text output in notebooks\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High priority\n",
    "  - Auto set max GPUs for update (?)\n",
    "  - Implement stages\n",
    "  - Add checkpoints\n",
    "  - Add model loading\n",
    "  - Add train/val to dataloader\n",
    "  - Partition detection in `train_policy`\n",
    "  - Script arguments, including address for ray\n",
    "- Medium priority\n",
    "  - Eliminate passing of persistent storage for memory objects\n",
    "  - Add hook for wandb, etc.\n",
    "  - Add state manager to env and then parallelize in analysis, maybe make `analyze` function\n",
    "- Low priority\n",
    "  - Seed policy initialization and unseed update, add reproducibility tag to wait for all rollouts before updating\n",
    "  - Verify worker timeout\n",
    "  - Subtract working memory on host node\n",
    "  - Local data loading per worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# # TODO: Figure out how to format arguments for appending h5ad files\n",
    "# parser.add_argument('datasets', type=str, required=False, help='.h5ad files to use for data')\n",
    "# parser.add_argument('--concatenate', type=str, required=False, help=\n",
    "#     '.h5ad files to concatenate as a single modality, may be used multiple times')\n",
    "\n",
    "# group = parser.add_argument_group('General')\n",
    "# group.add_argument('--seed', default=42, type=int, help='**Seed for random calls during training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12045/1487911653.py:8: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
      "2025-03-20 02:53:18,947\tINFO client_builder.py:244 -- Passing the following kwargs to ray.init() on the server: log_to_driver\n",
      "SIGTERM handler is not set because current thread is not the main thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"node:100.64.246.20\": 1.0,\n",
      "  \"accelerator_type:G\": 1.0,\n",
      "  \"node:__internal_head__\": 1.0,\n",
      "  \"node:100.85.187.118\": 1.0,\n",
      "  \"CPU\": 48.0,\n",
      "  \"object_store_memory\": 62368414924.0,\n",
      "  \"accelerator_type:RTX\": 1.0,\n",
      "  \"VRAM\": 57291112448.0,\n",
      "  \"GPU\": 2.0,\n",
      "  \"memory\": 144151812507.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(NCCLUniqueIDStore pid=14383)\u001b[0m The NCCL ID has not been set yet for store 8dc42047ef47a89d46bb4a68f46182df4cae1779.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = None\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Construct dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "# ray.init(\n",
    "#     resources={'VRAM': torch.cuda.get_device_properties(0).total_memory},\n",
    "#     dashboard_host='0.0.0.0')\n",
    "ray.init(\n",
    "    address='ray://127.0.0.1:10001',\n",
    "    runtime_env={\n",
    "        'env_vars': {\n",
    "            # NOTE: Important, NCCL will timeout if network device is non-standard\n",
    "            'NCCL_SOCKET_IFNAME': 'tailscale',\n",
    "            # 'NCCL_DEBUG': 'WARN',\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "        }})\n",
    "\n",
    "# Initialize distributed manager\n",
    "policy_init, memory_init = celltrip.train.get_train_initializers(\n",
    "    3, [m.shape[1] for m in modalities])\n",
    "distributed_manager = celltrip.train.DistributedManager(\n",
    "    # modalities=modalities, env_init=env_init,\n",
    "    policy_init=policy_init,\n",
    "    memory_init=memory_init)\n",
    "\n",
    "# Available resources\n",
    "import json\n",
    "print(json.dumps(ray.available_resources(), indent=2, sort_keys=False))\n",
    "\n",
    "# Perform training\n",
    "celltrip.train.train_policy(distributed_manager, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End timer\n",
    "time.perf_counter() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cancel\n",
    "# # dm.cancel()\n",
    "# # dm.clean()\n",
    "# # dm.rollout(dummy=True)\n",
    "# # dm.wait()\n",
    "\n",
    "# # Clear locks\n",
    "# distributed_manager.policy_manager.release_locks.remote()\n",
    "\n",
    "# # Get policy\n",
    "# device = 'cuda'\n",
    "# policy = policy_init().to(device)\n",
    "# celltrip.train.set_policy_state(policy, ray.get(distributed_manager.policy_manager.get_policy_state.remote()))\n",
    "\n",
    "# # Get memory\n",
    "# memory = memory_init(policy)\n",
    "# memory.append_memory(\n",
    "#     *ray.get(distributed_manager.policy_manager.get_memory_storage.remote()))\n",
    "\n",
    "# # Update remote policy\n",
    "# distributed_manager.policy_manager.release_locks.remote()\n",
    "# ray.get(distributed_manager.update())\n",
    "\n",
    "# # Get state of job from ObjectRef\n",
    "# import ray.util.state\n",
    "# object_id = dm.futures['simulation'][0].hex()\n",
    "# object_state = ray.util.state.get_objects(object_id)[0]\n",
    "# object_state.task_status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
