{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6db96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:19.092221Z",
     "iopub.status.busy": "2025-10-25T15:04:19.091722Z",
     "iopub.status.idle": "2025-10-25T15:04:19.105662Z",
     "shell.execute_reply": "2025-10-25T15:04:19.105108Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2754518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:19.107721Z",
     "iopub.status.busy": "2025-10-25T15:04:19.107278Z",
     "iopub.status.idle": "2025-10-25T15:04:22.342813Z",
     "shell.execute_reply": "2025-10-25T15:04:22.342211Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import celltrip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1aac9c",
   "metadata": {},
   "source": [
    "# Load Data and Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367c9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:22.345004Z",
     "iopub.status.busy": "2025-10-25T15:04:22.344698Z",
     "iopub.status.idle": "2025-10-25T15:04:46.636460Z",
     "shell.execute_reply": "2025-10-25T15:04:46.635865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data files\n",
    "adata_prefix = 's3://nkalafut-celltrip/Flysta3D'\n",
    "# adata_prefix = '../data/Flysta3D'\n",
    "adatas = [\n",
    "    celltrip.utility.processing.merge_adatas(\n",
    "        *celltrip.utility.processing.read_adatas(*[\n",
    "            f'{adata_prefix}/{p}_{m}.h5ad'\n",
    "            for p in ('E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b')\n",
    "            # for p in ('L2_a',)\n",
    "        ], backed=True), backed=True)\n",
    "    for m in ('expression', 'spatial')]\n",
    "# Model location and name (should be prefix for .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/flysta-250909-5', 800  # Double-standard\n",
    "prefix, training_step = 's3://nkalafut-celltrip/checkpoints/flysta-250909-4', 800  # Regular\n",
    "prefix, training_step = 's3://nkalafut-celltrip/checkpoints/Flysta-251026', 800  # Additional hidden layer\n",
    "# Generate or load preprocessing\n",
    "preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "    mask = np.loadtxt(f).astype(bool)\n",
    "adatas[0].obs['Training'] = mask  # For meta export, note that obs is stored in memory\n",
    "# Create sample env (kind of a dumb workaround, TODO)\n",
    "m1, m2 = [preprocessing.transform(ad[:2].X, subset_modality=i)[0] for i, ad in enumerate(adatas)]\n",
    "env = celltrip.environment.EnvironmentBase(\n",
    "    torch.tensor(m1), torch.tensor(m2), target_modalities=[1], compute_rewards=False, dim=8).eval().to('cuda')\n",
    "# Load policy\n",
    "policy = celltrip.policy.create_agent_from_env(\n",
    "    env, forward_batch_size=1_000, vision_size=1_000, pinning_spatial=[1]).eval().to('cuda')\n",
    "policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f1aed",
   "metadata": {},
   "source": [
    "# Generate Steady States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7105cac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.639064Z",
     "iopub.status.busy": "2025-10-25T15:04:46.638390Z",
     "iopub.status.idle": "2025-10-25T15:04:46.676086Z",
     "shell.execute_reply": "2025-10-25T15:04:46.675501Z"
    }
   },
   "outputs": [],
   "source": [
    "# for dev in (pbar := tqdm.tqdm(adatas[0].obs['development'].unique(), desc='')):\n",
    "#     # Subset and preprocess the data\n",
    "#     pbar.set_description(f'{dev} (Preprocessing)')\n",
    "#     samples = adatas[0].obs.index[adatas[0].obs['development']==dev]\n",
    "#     # if len(samples) > 10_000: samples = np.random.choice(samples, 10_000, replace=False)  # For runtime, TESTING\n",
    "#     m1, m2 = [\n",
    "#         celltrip.utility.processing.chunk_X(\n",
    "#             ad[samples], chunk_size=2_000,\n",
    "#             func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "#             for i, ad in enumerate(adatas)]\n",
    "#     # Initialize environment\n",
    "#     pbar.set_description(f'{dev} (Initializing)')\n",
    "#     env = celltrip.environment.EnvironmentBase(\n",
    "#         torch.tensor(m1), torch.tensor(m2), target_modalities=[1], compute_rewards=False, dim=8).eval(time_scale=1).to('cuda')  # 32/env.max_time\n",
    "#     # Simulate to steady state\n",
    "#     pbar.set_description(f'{dev} (Running)')\n",
    "#     # env.train().eval(time_scale=1)\n",
    "#     env.reset()\n",
    "#     ret = celltrip.train.simulate_until_completion(env, policy, skip_states=100, store_states='cpu')  # progress_bar=True\n",
    "#     steady_state = ret[-1][-1, :, :env.dim]\n",
    "#     target_state = env.modalities[env.target_modalities[0]].cpu()\n",
    "#     with torch.no_grad():\n",
    "#         imputed_steady_state = policy.pinning[0](steady_state.to('cuda'), Y=target_state.to('cuda')).detach().cpu().numpy()\n",
    "#     imputed_steady_state, = preprocessing.inverse_transform(imputed_steady_state, subset_modality=1)\n",
    "#     # Save\n",
    "#     pbar.set_description(f'{dev} (Saving)')\n",
    "#     np.save(f'../plots/flysta/CellTRIP_{dev}.npy', imputed_steady_state)\n",
    "#     np.save(f'../plots/flysta/spatial_{dev}.npy', adatas[1][samples].X)\n",
    "#     adatas[0].obs.loc[samples].to_csv(f'../plots/flysta/meta_{dev}.csv', index=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd516593",
   "metadata": {},
   "source": [
    "## Run Comparison Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ca499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.678195Z",
     "iopub.status.busy": "2025-10-25T15:04:46.677997Z",
     "iopub.status.idle": "2025-10-25T15:04:46.714714Z",
     "shell.execute_reply": "2025-10-25T15:04:46.714133Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load full data\n",
    "# X, Y = [\n",
    "#     celltrip.utility.processing.chunk_X(\n",
    "#         ad, chunk_size=2_000,\n",
    "#         func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "#         for i, ad in enumerate(adatas)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a2d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.716978Z",
     "iopub.status.busy": "2025-10-25T15:04:46.716448Z",
     "iopub.status.idle": "2025-10-25T15:04:46.753655Z",
     "shell.execute_reply": "2025-10-25T15:04:46.753065Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Train MLP and export predictions\n",
    "# model = sklearn.neural_network.MLPRegressor(max_iter=100, verbose=True).fit(X[mask], Y[mask])\n",
    "# for dev in (pbar := tqdm.tqdm(adatas[0].obs['development'].unique())):\n",
    "#     # Subset and preprocess the data\n",
    "#     pbar.set_description(f'{dev} (Preprocessing)')\n",
    "#     samples = adatas[0].obs.index[adatas[0].obs['development']==dev]\n",
    "#     X_dev, Y_dev = [\n",
    "#         celltrip.utility.processing.chunk_X(\n",
    "#             ad[samples], chunk_size=2_000,\n",
    "#             func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "#             for i, ad in enumerate(adatas)]\n",
    "#     # Run model\n",
    "#     pbar.set_description(f'{dev} (Running)')\n",
    "#     Y_pred = model.predict(X_dev)\n",
    "#     imputed_steady_state, = preprocessing.inverse_transform(Y_pred, subset_modality=1)\n",
    "#     # Save\n",
    "#     pbar.set_description(f'{dev} (Saving)')\n",
    "#     np.save(f'../plots/flysta/MLP_{dev}.npy', imputed_steady_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e789165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.755957Z",
     "iopub.status.busy": "2025-10-25T15:04:46.755418Z",
     "iopub.status.idle": "2025-10-25T15:04:46.792435Z",
     "shell.execute_reply": "2025-10-25T15:04:46.791874Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Export KNN predictions\n",
    "# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=10).fit(X[mask], Y[mask])\n",
    "# for dev in (pbar := tqdm.tqdm(adatas[0].obs['development'].unique())):\n",
    "#     # Subset and preprocess the data\n",
    "#     pbar.set_description(f'{dev} (Preprocessing)')\n",
    "#     samples = adatas[0].obs.index[adatas[0].obs['development']==dev]\n",
    "#     X_dev, Y_dev = [\n",
    "#         celltrip.utility.processing.chunk_X(\n",
    "#             ad[samples], chunk_size=2_000,\n",
    "#             func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "#             for i, ad in enumerate(adatas)]\n",
    "#     # Run model\n",
    "#     pbar.set_description(f'{dev} (Running)')\n",
    "#     Y_pred = model.predict(X_dev)\n",
    "#     imputed_steady_state, = preprocessing.inverse_transform(Y_pred, subset_modality=1)\n",
    "#     # Save\n",
    "#     pbar.set_description(f'{dev} (Saving)')\n",
    "#     np.save(f'../plots/flysta/KNN_{dev}.npy', imputed_steady_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7b72d",
   "metadata": {},
   "source": [
    "# Recover Validation State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06104732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.794538Z",
     "iopub.status.busy": "2025-10-25T15:04:46.794364Z",
     "iopub.status.idle": "2025-10-25T15:04:46.831070Z",
     "shell.execute_reply": "2025-10-25T15:04:46.830528Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Separate training and validation stages\n",
    "# development = np.array(['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b'])  # Ordered\n",
    "# development_training = adatas[0].obs.loc[mask, 'development'].unique()\n",
    "# development_validation = adatas[0].obs.loc[~mask, 'development'].unique()\n",
    "# assert len(np.intersect1d(development_training, development_validation)) == 0  # Properly partitioned\n",
    "# # Get possible interpolation stages\n",
    "# possible_interpolated_stages = []\n",
    "# for i in np.argwhere(np.isin(development, development_validation)).flatten():\n",
    "#     if i == 0 or i == len(development)-1: continue\n",
    "#     possible_interpolated_stages.append(development[i-1:i+2])\n",
    "# # Set interpolation\n",
    "# start_stage, interp_stage, end_stage = possible_interpolated_stages[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb0683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.833203Z",
     "iopub.status.busy": "2025-10-25T15:04:46.833006Z",
     "iopub.status.idle": "2025-10-25T15:04:46.870381Z",
     "shell.execute_reply": "2025-10-25T15:04:46.869778Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Grab data\n",
    "# start_idx = np.argwhere(adatas[0].obs['development'] == start_stage).flatten()\n",
    "# end_idx = np.argwhere(adatas[0].obs['development'] == end_stage).flatten()\n",
    "# start_exp = celltrip.utility.processing.chunk_X(\n",
    "#     adatas[0][start_idx], chunk_size=2_000,\n",
    "#     func=lambda x: preprocessing.transform(x, subset_modality=0)[0])\n",
    "# end_exp = celltrip.utility.processing.chunk_X(\n",
    "#     adatas[0][end_idx], chunk_size=2_000,\n",
    "#     func=lambda x: preprocessing.transform(x, subset_modality=0)[0])\n",
    "# start_obs = celltrip.utility.general.transform_and_center(celltrip.utility.processing.chunk_X(adatas[1][start_idx], chunk_size=2_000))\n",
    "# end_obs = celltrip.utility.general.transform_and_center(celltrip.utility.processing.chunk_X(adatas[1][end_idx], chunk_size=2_000))\n",
    "\n",
    "# # Use K-Means to create start and end pseudocells\n",
    "# start_n_pcells = end_n_pcells = 5_000\n",
    "# start_pcell_ids = sklearn.cluster.KMeans(n_clusters=start_n_pcells, random_state=42).fit_predict(start_obs)\n",
    "# end_pcell_ids = sklearn.cluster.KMeans(n_clusters=end_n_pcells, random_state=42).fit_predict(start_obs)\n",
    "\n",
    "# # Get expression and spatial for pseudocells\n",
    "# start_processed_exp = np.stack([start_exp[np.argwhere(start_pcell_ids==i).flatten()].mean(axis=0) for i in range(start_n_pcells)], axis=0)\n",
    "# start_processed_obs = np.stack([start_obs[np.argwhere(start_pcell_ids==i).flatten()].mean(axis=0) for i in range(start_n_pcells)], axis=0)\n",
    "# end_processed_exp = np.stack([end_exp[np.argwhere(end_pcell_ids==i).flatten()].mean(axis=0) for i in range(end_n_pcells)], axis=0)\n",
    "# end_processed_obs = np.stack([end_obs[np.argwhere(end_pcell_ids==i).flatten()].mean(axis=0) for i in range(end_n_pcells)], axis=0)\n",
    "\n",
    "# # Calculate OT matrix\n",
    "# a, b, _, OT_mat = celltrip.utility.general.compute_discrete_ot_matrix(start_processed_obs, end_processed_obs)\n",
    "\n",
    "# # Calculate pseudocells\n",
    "# pcells = [([i], np.argwhere(OT_mat[i] > 0).flatten()) for i in range(OT_mat.shape[0]) if OT_mat[i].sum() > 0]\n",
    "# start_pcells_exp, end_pcells_exp = [], []\n",
    "# start_pcells_obs, end_pcells_obs = [], []\n",
    "# for pcell_start, pcell_end in pcells:\n",
    "#     start_pcells_exp.append(start_processed_exp[pcell_start].mean(axis=0))\n",
    "#     end_pcells_exp.append(end_processed_exp[pcell_end].mean(axis=0))\n",
    "#     start_pcells_obs.append(start_processed_obs[pcell_start].mean(axis=0))\n",
    "#     end_pcells_obs.append(end_processed_obs[pcell_end].mean(axis=0))\n",
    "# start_pcells_exp = np.stack(start_pcells_exp, axis=0)\n",
    "# end_pcells_exp = np.stack(end_pcells_exp, axis=0)\n",
    "# start_pcells_obs = np.stack(start_pcells_obs, axis=0)\n",
    "# end_pcells_obs = np.stack(end_pcells_obs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad0fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.872408Z",
     "iopub.status.busy": "2025-10-25T15:04:46.872230Z",
     "iopub.status.idle": "2025-10-25T15:04:46.908794Z",
     "shell.execute_reply": "2025-10-25T15:04:46.908233Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create env\n",
    "# m1_start, m1_end = start_pcells_exp, end_pcells_exp  # preprocessing.transform\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1_start), target_modalities=None, compute_rewards=False, dim=8).eval(time_scale=1).to('cuda')\n",
    "\n",
    "# # Get transition states\n",
    "# env.reset()\n",
    "# celltrip.train.simulate_until_completion(env, policy, store_states=False)  # Set env at steady state\n",
    "# env.time = 0  # Reset timing\n",
    "# env.set_modalities([torch.tensor(m1_end)]).to('cuda')  # Set to ending expression\n",
    "# transition_states = celltrip.train.simulate_until_completion(env, policy, skip_states=50, store_states='cpu', progress_bar=True)[-1][..., :env.dim].cpu()\n",
    "\n",
    "# # Impute transition states\n",
    "# with torch.no_grad():\n",
    "#     imputed_transition_states = policy.pinning[0](transition_states.to('cuda')).detach().cpu().numpy()\n",
    "# imputed_transition_states, = preprocessing.inverse_transform(imputed_transition_states, subset_modality=1)\n",
    "# np.save(f'../plots/flysta/Interpolated_CellTRIP_{interp_stage}.npy', imputed_transition_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e05a1",
   "metadata": {},
   "source": [
    "## Run Comparison Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0422ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.910785Z",
     "iopub.status.busy": "2025-10-25T15:04:46.910570Z",
     "iopub.status.idle": "2025-10-25T15:04:46.946772Z",
     "shell.execute_reply": "2025-10-25T15:04:46.946226Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Export LERP\n",
    "# for progress in (.25, .5, .75):\n",
    "#     imputed_transition_states = ((1-progress)*start_pcells_obs + progress*end_pcells_obs) / 2\n",
    "#     np.save(f'../plots/flysta/Interpolated_LERP-{progress:.2f}_{interp_stage}.npy', imputed_transition_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37705ce",
   "metadata": {},
   "source": [
    "# Perform Knockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca63f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T15:04:46.948936Z",
     "iopub.status.busy": "2025-10-25T15:04:46.948735Z",
     "iopub.status.idle": "2025-10-26T00:44:59.386943Z",
     "shell.execute_reply": "2025-10-26T00:44:59.386350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "np.random.seed(42)\n",
    "# genes_to_survey = np.random.choice(adatas[0].var_names, 2000, replace=False)\n",
    "assert preprocessing.filter_mask[0] is None\n",
    "genes_to_survey = adatas[0].var_names[preprocessing.standardize_std[0].flatten().argsort()[::-1]][:2000]  # 2k hvg\n",
    "sim_time = .5\n",
    "\n",
    "# Add results\n",
    "results = []\n",
    "def add_record(states, gene, dev, ct):\n",
    "    results.append({\n",
    "        'Gene': gene, 'Development': dev, 'Cell Type': ct,\n",
    "        'Effect Size': np.sqrt(np.square(states[-1] - states[0]).sum(axis=-1)).mean(),\n",
    "        'Trajectory Length': np.sqrt(np.square(states[1:] - states[:-1])).mean(axis=-1).sum()})\n",
    "    \n",
    "# Reset function\n",
    "def reset_env(env, steady_pos, steady_vel, modal_dict={}):\n",
    "    env.set_max_time(sim_time).reset()  # TODO: Maybe longer?, early stopping?\n",
    "    env.set_positions(steady_pos)\n",
    "    env.set_velocities(steady_vel)  # Maybe 0 manually?\n",
    "    for k, v in modal_dict.items():\n",
    "        env.modalities[k] = v\n",
    "\n",
    "# Running function\n",
    "def run_and_record(samples, env, policy, preprocessing, gene, dev, gene_idx):\n",
    "    # Run and impute\n",
    "    states = celltrip.train.simulate_until_completion(\n",
    "        env, policy,\n",
    "        env_hooks=[\n",
    "            celltrip.utility.hooks.clamp_inverted_features_hook(\n",
    "                gene_idx, preprocessing, feature_targets=0., modality_idx=0),\n",
    "        ],\n",
    "        store_states='cpu')[-1]\n",
    "    with torch.no_grad():\n",
    "        imputed_states = policy.pinning[0](states[..., :env.dim].to('cuda')).detach().cpu().numpy()\n",
    "    imputed_states, = preprocessing.inverse_transform(imputed_states, subset_modality=1)\n",
    "    # Record\n",
    "    add_record(imputed_states, gene, dev, 'All')\n",
    "    for ct in adatas[0][samples].obs['annotation'].unique():\n",
    "        add_record(imputed_states[:, adatas[0][samples].obs['annotation']==ct], gene, dev, ct)\n",
    "\n",
    "# Evaluate genes\n",
    "for dev in adatas[0].obs['development'].unique():\n",
    "    # Subset and preprocess the data\n",
    "    samples = adatas[0].obs.index[adatas[0].obs['development']==dev]\n",
    "    raw_m1 = celltrip.utility.processing.chunk_X(adatas[0][samples], chunk_size=2_000)\n",
    "    m1, m2 = [\n",
    "        celltrip.utility.processing.chunk_X(\n",
    "            ad[samples], chunk_size=2_000,\n",
    "            func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "            for i, ad in enumerate(adatas)]\n",
    "    \n",
    "    # Initialize environment\n",
    "    env = celltrip.environment.EnvironmentBase(\n",
    "        torch.tensor(m1), torch.tensor(m2), target_modalities=[1], compute_rewards=False, dim=8).eval(time_scale=1).to('cuda')\n",
    "    \n",
    "    # Simulate to steady state\n",
    "    env.reset()\n",
    "    celltrip.train.simulate_until_completion(env, policy)\n",
    "    steady_pos, steady_vel = (env.pos, env.vel)\n",
    "\n",
    "    # Run control\n",
    "    reset_env(env, steady_pos, steady_vel)\n",
    "    run_and_record(samples, env, policy, preprocessing, 'Control', dev, [])\n",
    "\n",
    "    # Perturb\n",
    "    for gene in tqdm.tqdm(genes_to_survey, desc=dev, miniters=10, maxinterval=30):\n",
    "        # Get gene idx and reset environment\n",
    "        gene_idx = np.argwhere(adatas[0].var_names==gene).flatten()\n",
    "        reset_env(env, steady_pos, steady_vel)  # {0: torch.tensor(m1).cuda()}\n",
    "\n",
    "        # Apply knockdown\n",
    "        # # iso_modality, = preprocessing.transform(raw_m1, subset_features=gene_idx, subset_modality=0)\n",
    "        # iso_modality = celltrip.utility.processing.chunk(\n",
    "        #     raw_m1, chunk_size=2_000, func=lambda x: preprocessing.transform(x, subset_features=gene_idx, subset_modality=0)[0])\n",
    "        # iso_modality = torch.tensor(iso_modality).to(env.device)\n",
    "        # modal_change = (iso_modality - 0*iso_modality)  # Coeff is for overexp anal, NOTE: if `pre_log`, this method will not work for overexp\n",
    "        # env.modalities[0] = env.modalities[0] - modal_change\n",
    "\n",
    "        # Simulate and record\n",
    "        run_and_record(samples, env, policy, preprocessing, gene, dev, gene_idx)\n",
    "        # env.modalities[0] = env.modalities[0] + modal_change\n",
    "\n",
    "# Convert and save\n",
    "pd.DataFrame(results).to_csv('../plots/flysta/knockdown.csv', index=None)\n",
    "\n",
    "# .5s run on 20 genes (opposite order)\n",
    "# E14-16h_a: 100%|██████████| 20/20 [01:02<00:00,  3.11s/it]\n",
    "# E16-18h_a: 100%|██████████| 20/20 [00:56<00:00,  2.84s/it]\n",
    "# L1_a: 100%|██████████| 20/20 [01:08<00:00,  3.41s/it]\n",
    "# L2_a: 100%|██████████| 20/20 [04:32<00:00, 13.61s/it]\n",
    "# L3_b: 100%|██████████| 20/20 [02:55<00:00,  8.78s/it]\n",
    "\n",
    "# 1s run on 20 genes (40m)\n",
    "# E14-16h_a: 100%|██████████| 20/20 [01:47<00:00,  5.36s/it]\n",
    "# E16-18h_a: 100%|██████████| 20/20 [01:40<00:00,  5.05s/it]\n",
    "# L1_a: 100%|██████████| 20/20 [01:54<00:00,  5.72s/it]\n",
    "# L2_a: 100%|██████████| 20/20 [07:43<00:00, 23.16s/it]\n",
    "# L3_b: 100%|██████████| 20/20 [05:04<00:00, 15.21s/it]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celltrip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
