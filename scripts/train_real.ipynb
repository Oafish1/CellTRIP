{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.util.collective as col\n",
    "import torch\n",
    "\n",
    "import celltrip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init(\n",
    "    address='ray://127.0.0.1:10001',\n",
    "    runtime_env={\n",
    "        'env_vars': {\n",
    "            'RAY_DEDUP_LOGS': '0',\n",
    "            # Irregular node fixes\n",
    "            # NOTE: Important, NCCL will timeout if network device is non-standard\n",
    "            # 'CUDA_LAUNCH_BLOCKING': '1',  # Slow, only for compatibility with X windows\n",
    "            # 'NCCL_SOCKET_IFNAME': 'tailscale',  # lo,en,wls,docker,tailscale\n",
    "            # 'NCCL_IB_DISABLE': '1',\n",
    "            # 'NCCL_CUMEM_ENABLE': '0',\n",
    "            # 'NCCL_DEBUG': 'INFO',\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_init(local=False):\n",
    "    # Create dataloader\n",
    "    fnames = ['./data/MERFISH/expression.h5ad', './data/MERFISH/spatial.h5ad']\n",
    "    if local: fnames = ['.' + f for f in fnames]\n",
    "    partition_cols = None  # 'layer'\n",
    "    adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "    celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "    dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "        *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "    # modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "    # Return env\n",
    "    return celltrip.environment.EnvironmentBase(dataloader, dim=3, penalty_bound=1)\n",
    "\n",
    "policy_init = lambda env: celltrip.policy.PPO(\n",
    "    2*env.dim, env.dataloader.modal_dims, env.dim) # minibatch_size=3e3,\n",
    "    \n",
    "\n",
    "memory_init = lambda policy: celltrip.memory.AdvancedMemoryBuffer(\n",
    "    sum(policy.modal_dims),\n",
    "    split_args=policy.split_args)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = env_init(local=True).to('cuda')\n",
    "# policy = policy_init(env).to('cuda')\n",
    "# memory = memory_init(policy)\n",
    "# celltrip.train.simulate_until_completion(policy, env, memory)\n",
    "# memory.propagate_rewards()\n",
    "# memory.normalize_rewards()\n",
    "# # for _ in range(5):\n",
    "# #     memory.append_memory(memory)\n",
    "# len(memory)\n",
    "# # memory.fast_sample(10_000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "class Worker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        policy_init,\n",
    "        env_init,\n",
    "        memory_init=lambda: None,\n",
    "        world_size=1,\n",
    "        rank=0,\n",
    "    ):\n",
    "        # Detect device\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # Parameters\n",
    "        self.env = env_init().to(device)\n",
    "        self.policy = policy_init(self.env).to(device)\n",
    "        self.memory = memory_init(self.policy)\n",
    "        self.rank = rank\n",
    "\n",
    "        # World initialization\n",
    "        col.init_collective_group(world_size, rank, 'nccl')\n",
    "\n",
    "        # Policy parameters\n",
    "        self.sync_policy()\n",
    "        self.policy_iteration = 0\n",
    "\n",
    "        # Memory parameters\n",
    "        self.memory_buffer = []\n",
    "\n",
    "    @celltrip.decorator.metrics(append_to_dict=True)\n",
    "    # @celltrip.decorator.profile(time_annotation=True)\n",
    "    def rollout(self):\n",
    "        # Perform rollout\n",
    "        result = celltrip.train.simulate_until_completion(\n",
    "            self.policy, self.env, self.memory, dummy=False)\n",
    "        self.memory.propagate_rewards()\n",
    "        env_nodes = self.env.num_nodes\n",
    "        self.env.reset()\n",
    "\n",
    "        # Clean memory\n",
    "        self.memory.cleanup()\n",
    "\n",
    "        # Record\n",
    "        timestep, reward, itemized_reward = result\n",
    "        ret = {\n",
    "            'Event Type': 'Rollout',\n",
    "            'Policy Iteration': self.policy_iteration,\n",
    "            'Rank': self.rank,\n",
    "            'Timesteps': timestep,\n",
    "            'Memories': timestep*env_nodes,\n",
    "            'Reward': reward,\n",
    "            'Itemized Reward': itemized_reward}\n",
    "        return ret\n",
    "\n",
    "    def rollout_until_new(self, num_new, condition='steps'):\n",
    "        # Parameters\n",
    "        if condition == 'memories': measure = self.memory.get_new_len\n",
    "        elif condition == 'steps': measure = self.memory.get_new_steps\n",
    "        else: raise ValueError(f'Condition `{condition}` not found.')\n",
    "\n",
    "        # Compute rollouts\n",
    "        ret = []\n",
    "        while measure() < num_new:\n",
    "            ret.append(self.rollout())\n",
    "        return ret\n",
    "\n",
    "    @celltrip.decorator.metrics(append_to_dict=True, dict_index=1)\n",
    "    def send_memory(self, **kwargs):\n",
    "        # Put in object store\n",
    "        mem = self.memory.get_storage(**kwargs)\n",
    "        ref = ray.put(mem)\n",
    "\n",
    "        # Record\n",
    "        ret = {\n",
    "            'Event Type': 'Send Memory',\n",
    "            'Rank': self.rank,\n",
    "            'Memories': sum([s.shape[0] for s in mem[0]['states']])}\n",
    "        return ref, ret\n",
    "    \n",
    "    @celltrip.decorator.metrics(append_to_dict=True)\n",
    "    def recv_memories(self, new_memories):\n",
    "        # Append memories\n",
    "        num_memories = 0\n",
    "        for new_memory in new_memories:\n",
    "            new_memory = ray.get(new_memory)\n",
    "            self.memory.append_memory(*new_memory)\n",
    "            num_memories += sum([s.shape[0] for s in new_memory[0]['states']])\n",
    "\n",
    "        # Clean memory\n",
    "        self.memory.cleanup()\n",
    "\n",
    "        # Record\n",
    "        ret = {\n",
    "            'Event Type': 'Receive Memories',\n",
    "            'Rank': self.rank,\n",
    "            'Memories': num_memories}\n",
    "        return ret\n",
    "        \n",
    "    @celltrip.decorator.metrics(append_to_dict=True)\n",
    "    @celltrip.decorator.profile(time_annotation=True)\n",
    "    def update(self):\n",
    "        # TODO: Update time grows for some unknown reason with memory size\n",
    "        # Perform update\n",
    "        self.memory.normalize_rewards()\n",
    "        self.policy.update(self.memory, verbose=True)\n",
    "\n",
    "        # Annotate\n",
    "        self.policy_iteration += 1\n",
    "        num_new_memories = self.memory.get_new_len()\n",
    "        num_replay_memories = self.memory.get_replay_len()\n",
    "\n",
    "        # Clean\n",
    "        self.memory.mark_sampled()\n",
    "        self.memory.cleanup()\n",
    "\n",
    "        # Record\n",
    "        # TODO: Fix num_* being incorrect (seems like `get_new_len` does half? Test others too)\n",
    "        ret = {\n",
    "            'Event Type': 'Update',\n",
    "            'Policy Iteration': self.policy_iteration,\n",
    "            'Rank': self.rank,\n",
    "            'New Memories': num_new_memories,\n",
    "            'Replay Memories': num_replay_memories,\n",
    "            'Total Memories': len(self.memory)}\n",
    "        return ret\n",
    "    \n",
    "    def sync_policy(self):\n",
    "        world_size = col.get_collective_group_size()\n",
    "        for k, w in self.policy.state_dict().items():\n",
    "            col.allreduce(w)\n",
    "            w /= world_size\n",
    "\n",
    "    def destroy(self):\n",
    "        col.destroy_collective_group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train(num_workers, updates):\n",
    "    workers = [Worker.remote(\n",
    "        policy_init, env_init, memory_init,\n",
    "        world_size=num_workers, rank=i) for i in range(num_workers)]\n",
    "    # TODO: Learners and workers, maybe multiple workers per learner?\n",
    "\n",
    "    records = []\n",
    "    for _ in range(updates):\n",
    "        # Rollouts\n",
    "        num_records = len(records)\n",
    "        new_records = ray.get([w.rollout_until_new.remote(5e3/num_workers) for w in workers])\n",
    "        records += sum(new_records, [])\n",
    "        for record in records[-(len(records)-num_records):]: print(record)\n",
    "\n",
    "        # Collect memories\n",
    "        num_records = len(records)\n",
    "        ret = ray.get([w.send_memory.remote(new=True) for w in workers])\n",
    "        new_memories, new_records = [[r[i] for r in ret] for i in range(2)]\n",
    "        records += new_records\n",
    "        for record in records[-(len(records)-num_records):]: print(record)\n",
    "\n",
    "        # Broadcast memories\n",
    "        num_records = len(records)\n",
    "        new_records = []\n",
    "        for i, w in enumerate(workers):\n",
    "            new_memories_w = [ref for j, ref in enumerate(new_memories) if i!=j]\n",
    "            future = w.recv_memories.remote(new_memories=new_memories_w)\n",
    "            new_records.append(future)\n",
    "        new_records = ray.get(new_records)\n",
    "        records += new_records\n",
    "        for record in records[-(len(records)-num_records):]: print(record)\n",
    "\n",
    "        # Updates\n",
    "        num_records = len(records)\n",
    "        new_records = ray.get([w.update.remote() for w in workers])\n",
    "        records += new_records\n",
    "        for record in records[-(len(records)-num_records):]: print(record)\n",
    "\n",
    "    # Destroy\n",
    "    # workers[0].destroy.remote()\n",
    "    # [ray.kill(w) for w in workers]\n",
    "\n",
    "    # Return\n",
    "    return workers\n",
    "\n",
    "workers = ray.get(train.remote(2, 50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# num_runners = 4\n",
    "# num_learners = 2\n",
    "\n",
    "# # Create placement groups\n",
    "# pg_runners = ray.util.placement_group(num_runners*[{'CPU': 1e-4, 'GPU': 1e-4}], strategy='SPREAD')\n",
    "# pg_learners = ray.util.placement_group(num_learners*[{'CPU': 1e-4, 'GPU': 1e-4}], strategy='STRICT_SPREAD')\n",
    "# ray.get([pg_runners.ready(), pg_learners.ready()], timeout=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.perf_counter() - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
