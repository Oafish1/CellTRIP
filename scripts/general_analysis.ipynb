{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39948518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac9b79",
   "metadata": {},
   "source": [
    "- Two major problems\n",
    "  - Spatial data (and others) has no fixed reference. There should be a transform/rot/scale lstsq after main pinning\n",
    "  - There is no current incentive for cells to interact with an absolute env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e547400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import manim as ma\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import torch\n",
    "import umap\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# No verbose cred grab\n",
    "logging.getLogger('aiobotocore').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('fsspec').setLevel(logging.CRITICAL)\n",
    "# logging.Logger.manager.loggerDict\n",
    "\n",
    "# Environment\n",
    "os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "mpl.rcParams['pdf.fonttype'] = mpl.rcParams['ps.fonttype'] = 42\n",
    "sns.set_theme(context='paper', style='dark', palette='colorblind')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c218233",
   "metadata": {},
   "source": [
    "# Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d704097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/dyngen/logcounts.h5ad',\n",
    "#     's3://nkalafut-celltrip/dyngen/counts_protein.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should contain .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/dyngen-250825', 400\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# samples = adatas[0].obs.index\n",
    "# m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), target_modalities=None, dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(env).eval().to('cuda')  # pinning_modal_dims=None for lstq pinning\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fe1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/MERFISH/expression.h5ad',\n",
    "#     's3://nkalafut-celltrip/MERFISH/spatial.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should contain .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/MERFISH-250825', 400\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# samples = adatas[0].obs.index\n",
    "# m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), target_modalities=[1], dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(env, pinning_spatial=[1]).eval().to('cuda')  # pinning_modal_dims=None for lstq pinning\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights', strict=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/MERFISH_Bench/expression.h5ad',\n",
    "#     's3://nkalafut-celltrip/MERFISH_Bench/spatial.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should contain .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/MERFISH_Bench-250807', 300\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# samples = adatas[0].obs.index\n",
    "# m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), target_modalities=[1], dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(env).eval().to('cuda')  # pinning_modal_dims=None for lstq pinning\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a43d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/MERFISH30k/comb.h5ad',\n",
    "#     's3://nkalafut-celltrip/MERFISH30k/spatial.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should contain .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/MERFISH30k-250830', 800\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# np.random.seed(42)\n",
    "# slice_id = np.random.choice(adatas[0].obs['slice_id'])\n",
    "# samples = adatas[0].obs.loc[adatas[0].obs['slice_id'] == slice_id].index\n",
    "# samples = samples[np.random.choice(samples.shape[0], min(samples.shape[0], 2_000), replace=False)]  # Subsample\n",
    "# m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), target_modalities=[1], dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(env, pinning_spatial=[1], actor_critic_kwargs=dict(heads=4, blocks=2, hidden_dim=64)).eval().to('cuda')  # pinning_modal_dims=None for lstq pinning\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights', strict=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "adatas = [\n",
    "    celltrip.utility.processing.merge_adatas(\n",
    "        *celltrip.utility.processing.read_adatas(*[\n",
    "            f's3://nkalafut-celltrip/Flysta3D/{p}_{m}.h5ad'\n",
    "            for p in ('E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b')\n",
    "            # for p in ('L2_a',)\n",
    "        ], backed=True), backed=True)\n",
    "    for m in ('expression', 'spatial')]\n",
    "# Model location and name (should be prefix for .weights, .pre, and .mask file)\n",
    "prefix, training_step = 's3://nkalafut-celltrip/checkpoints/flysta-250901', 800\n",
    "# Generate or load preprocessing\n",
    "preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "    mask = np.loadtxt(f).astype(bool)\n",
    "# Subset and preprocess the data (Use partition cols here to select data)\n",
    "samples = adatas[0].obs.index[adatas[0].obs['development']=='L2_a']\n",
    "np.random.seed(42)\n",
    "samples = samples[np.random.choice(samples.shape[0], 2_000, replace=False)]  # Subsample\n",
    "m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# Initialize environment and policy\n",
    "env = celltrip.environment.EnvironmentBase(\n",
    "    torch.tensor(m1), torch.tensor(m2), target_modalities=[1], dim=8).eval().to('cuda')\n",
    "# env.set_modalities(...); env.reset()  # Change modalities\n",
    "policy = celltrip.policy.create_agent_from_env(\n",
    "    env, forward_batch_size=2_000, vision_size=2_000, pinning_spatial=[1]).eval().to('cuda')  # Doesn't eval log_std now\n",
    "policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7592a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/VirtualCell/vcc_flt_data.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should be prefix for .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/VCC-250822-1', 800\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# samples = adatas[0].obs.index[adatas[0].obs['target_gene']=='non-targeting']  # Only non-targeting\n",
    "# np.random.seed(42)\n",
    "# samples = samples[np.random.choice(samples.shape[0], 1_000, replace=False)]  # Subsample\n",
    "# m1, = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), target_modalities=None, dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(\n",
    "#     env, forward_batch_size=1_000, vision_size=1_000).eval().to('cuda')  # Doesn't eval log_std now\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee36af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data files\n",
    "# adatas = celltrip.utility.processing.read_adatas(\n",
    "#     's3://nkalafut-celltrip/CancerVel/expression.h5ad',\n",
    "#     backed=True)\n",
    "# # Model location and name (should be prefix for .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/CancerVel-250831', 800\n",
    "# # Generate or load preprocessing\n",
    "# preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "#     mask = np.loadtxt(f).astype(bool)\n",
    "# # Subset and preprocess the data (Use partition cols here to select data)\n",
    "# samples = adatas[0].obs.index\n",
    "# # samples = adatas[0].obs.index[(adatas[0].obs['sgAssign'] == 'None') * (adatas[0].obs['days'] == 'D3')]\n",
    "# np.random.seed(42)\n",
    "# samples = samples[np.random.choice(samples.shape[0], min(1_000, samples.shape[0]), replace=False)]  # Subsample\n",
    "# m1, = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), target_modalities=None, dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(  # heads=4, blocks=2, hidden_dim=64\n",
    "#     env, forward_batch_size=1_000, vision_size=1_000).eval().to('cuda')  # Doesn't eval log_std now\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfbcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.train()\n",
    "# env.train() equivalent:\n",
    "# steady_state = ret[-1][1280, :, :env.dim].cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_id = np.random.choice(adatas[0].obs['slice_id'])\n",
    "# samples = adatas[0].obs.loc[adatas[0].obs['slice_id'] == slice_id].index\n",
    "# samples = samples[np.random.choice(samples.shape[0], min(samples.shape[0], 2_000), replace=False)]  # Subsample\n",
    "# m1, m2 = preprocessing.transform([ad[samples].X for ad in adatas])\n",
    "# # Initialize environment and policy\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), target_modalities=[1], dim=8).eval().to('cuda')\n",
    "# # env.set_modalities(...); env.reset()  # Change modalities\n",
    "# policy = celltrip.policy.create_agent_from_env(env, pinning_spatial=[1]).eval().to('cuda')  # pinning_modal_dims=None for lstq pinning\n",
    "# policy.load_checkpoint(f'{prefix}-{training_step:04}.weights', strict=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92246261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run policy to convergence, and get pinning function\n",
    "env.reset()\n",
    "ret = celltrip.train.simulate_until_completion(env, policy, store_states=True)\n",
    "steady_state = ret[-1][-1, :, :env.dim].cpu()\n",
    "target_state = env.modalities[env.target_modalities[0]].cpu()\n",
    "for k, v in ret[3].items(): print(f'{k}: {v:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One/Two modality imputation (0)\n",
    "# pinning_function = lambda X: policy.pinning[0](X.to('cuda'), Y=target_state.to('cuda')).detach().cpu().numpy()\n",
    "# inverse_transform = lambda X: preprocessing.inverse_transform(X, subset_modality=0)[0]\n",
    "# reduction = lambda X: X\n",
    "\n",
    "# One modality imputation (1)\n",
    "pinning_function = lambda X: policy.pinning[0](X.to('cuda'), Y=target_state.to('cuda')).detach().cpu().numpy()\n",
    "inverse_transform = lambda X: preprocessing.inverse_transform(X, subset_modality=1)[0]\n",
    "reduction = lambda X: X\n",
    "\n",
    "# Two modality imputation (1)\n",
    "# pinning_function = lambda X: policy.pinning[1](X.to('cuda')).detach().cpu().numpy()\n",
    "# inverse_transform = lambda X: preprocessing.inverse_transform(X, subset_modality=1)[0]\n",
    "# reduction = lambda X: X\n",
    "# target_state = env.modalities[env.target_modalities[1]].cpu()\n",
    "\n",
    "# Identity\n",
    "# pinning_function = lambda X: X.numpy()\n",
    "# inverse_transform = lambda X: X\n",
    "# reduction = lambda X: X\n",
    "\n",
    "# Add reduction method\n",
    "# import sklearn; red = sklearn.decomposition.PCA(n_components=2).fit(inverse_transform(target_state.numpy()))  # PCA True\n",
    "# import umap; red = umap.UMAP().fit(inverse_transform(target_state.numpy()))  # UMAP True\n",
    "# import umap; red = umap.UMAP().fit(inverse_transform(pinning_function(steady_state)))  # UMAP Pred\n",
    "# reduction = lambda X: red.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8267bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.neural_network\n",
    "\n",
    "# train_mask = samples.isin(adatas[0].obs.loc[mask].index)\n",
    "# mlp = sklearn.neural_network.MLPRegressor().fit(env.modalities[0].cpu()[train_mask], env.modalities[1].cpu()[train_mask])\n",
    "# pred = mlp.predict(env.modalities[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot imputed vs actual\n",
    "df = pd.DataFrame(index=samples)\n",
    "# df[['X_pred', 'Y_pred']] = reduction(inverse_transform(pred))[..., :2]\n",
    "df[['X_pred', 'Y_pred']] = reduction(inverse_transform(pinning_function(steady_state)))[..., :2]\n",
    "df[['X_true', 'Y_true']] = reduction(inverse_transform(target_state.numpy()))[..., :2]\n",
    "df['Type'] = adatas[0].obs.loc[samples, 'annotation']  # 'target_gene', 'layer', 'pattern_gp_label', 'annotation', 'traj_sim', 'label', 'subclass, 'days', 'sgAssign'\n",
    "df['Validation'] = ~pd.DataFrame(mask, index=adatas[0].obs.index).loc[samples]\n",
    "# df = df.loc[df['Validation']]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "sns.scatterplot(df, x='X_pred', y='Y_pred', hue='Type', style='Validation', legend=False, ax=axs[0])\n",
    "sns.scatterplot(df, x='X_true', y='Y_true', hue='Type', style='Validation', legend=True, ax=axs[1])\n",
    "axs[1].legend(ncols=np.ceil(len(df['Type'].unique())/15), loc='center left', bbox_to_anchor=(1.04, 0.5), borderaxespad=0)\n",
    "for i in np.random.choice(df.shape[0], min(50, df.shape[0]), replace=False):\n",
    "    patch = ConnectionPatch(\n",
    "        xyA=df.iloc[i][['X_pred', 'Y_pred']].to_numpy(), xyB=df.iloc[i][['X_true', 'Y_true']].to_numpy(),\n",
    "        coordsA='data', coordsB='data', axesA=axs[0], axesB=axs[1],\n",
    "        color='blue' if not df.iloc[i]['Validation'] else 'red', lw=.5, alpha=.25)\n",
    "    axs[1].add_patch(patch)\n",
    "axs[0].set(title='CellTRIP', xlabel='X', ylabel='Y')\n",
    "axs[1].set(title='Actual', xlabel='X')\n",
    "axs[0].set_box_aspect(1)\n",
    "axs[1].set_box_aspect(1)\n",
    "# axs[1].set(xlim=[-10, 10], ylim=[-10, 10])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intra-type Error\n",
    "# df['MSE'] = np.mean(np.square(inverse_transform(pred) - inverse_transform(target_state.numpy())), axis=-1)\n",
    "df['MSE'] = np.mean(np.square(inverse_transform(pinning_function(steady_state)) - inverse_transform(target_state.numpy())), axis=-1)\n",
    "df_mse = df[['Type', 'MSE']].groupby('Type', observed=True).mean()\n",
    "df_mse['Validation MSE'] = df.loc[df['Validation'], ['Type', 'MSE']].groupby('Type', observed=True).mean()\n",
    "df_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d42079",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%manim -qm -v WARNING LatentSpaceVisualization\n",
    "\n",
    "positions = (\n",
    "    sklearn.decomposition\n",
    "    .PCA(n_components=2)\n",
    "    .fit(steady_state)\n",
    "    .transform(\n",
    "        ret[-1].cpu()[..., :env.dim]\n",
    "        .reshape((-1, env.dim)))\n",
    "    .reshape((*ret[-1].shape[:-1], 2)))\n",
    "speedup = 100\n",
    "\n",
    "class LatentSpaceVisualization(ma.Scene):\n",
    "    def construct(self):\n",
    "        # Axes\n",
    "        spread = 50\n",
    "        ax = ma.Axes(\n",
    "            x_range=[-spread, spread, 10], y_range=[-spread, spread, 10],\n",
    "            x_length=7, y_length=7, tips=False)\n",
    "        self.add(ax)\n",
    "\n",
    "        # Time\n",
    "        t = ma.ValueTracker(0)\n",
    "\n",
    "        # Dot\n",
    "        def dot_updater(i):\n",
    "            return lambda x: x.move_to(ax.c2p(*positions[int(t.get_value()), i]))\n",
    "        for i in range(positions.shape[1]):\n",
    "            dot = ma.Dot(\n",
    "                ax.c2p(*positions[0, i]),\n",
    "                radius=.02)\n",
    "            dot.add_updater(dot_updater(i))\n",
    "            self.add(dot)\n",
    "\n",
    "        # Animate\n",
    "        self.play(t.animate.set_value(ret[-1].shape[0]-1), rate_func=ma.linear, run_time=positions.shape[0]*env.delta/speedup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2736a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "Y_pred = inverse_transform(pinning_function(steady_state))\n",
    "Y_true = inverse_transform(target_state.numpy())\n",
    "record = {'gene': [], 'corr': [], 'p': []}\n",
    "for i in range(Y_true.shape[1]):\n",
    "    res = scipy.stats.pearsonr(Y_pred[:, i], Y_true[:, i])\n",
    "    corr, p = res.statistic, res.pvalue\n",
    "    record['gene'].append(adatas[0].var.index[i])\n",
    "    record['corr'].append(corr)\n",
    "    record['p'].append(p)\n",
    "df = pd.DataFrame(record)\n",
    "sig_frac = (df.dropna()['p'] <= 5e-2).mean()\n",
    "print(f'{100*sig_frac:.0f}% significant correlations')\n",
    "\n",
    "# Distribution plot\n",
    "df_sort = df.dropna().sort_values('corr', ascending=False)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 4), sharex=True)\n",
    "axs[0].plot(df_sort['gene'], df_sort['corr'], color='black')\n",
    "axs[0].set(ylabel='Pearson')\n",
    "axs[1].plot(df_sort['gene'], df_sort['p'], color='black')\n",
    "axs[1].set(ylabel='p-value', xlabel='Gene', xticks=[])\n",
    "axs[1].axhline(y=5e-2, ls='--', color='black')\n",
    "\n",
    "# Specific scatter\n",
    "# idx = df['corr'].sort_values().dropna().iloc[::-1].index[0]\n",
    "idx = np.argwhere(df['gene'] == 'TMSB4X').flatten()[0]\n",
    "# idx = np.argwhere(df['gene'] == 'TADA1').flatten()[0]\n",
    "# idx = np.argwhere(df['gene'] == 'PRCP').flatten()[0]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "# Main scatter\n",
    "ax.scatter(Y_true[:, idx], Y_pred[:, idx], s=1, color='black')\n",
    "# Extra text\n",
    "corr, p = df.iloc[idx][['corr', 'p']]\n",
    "ax.text(.01, .99, f'Pearson: {corr:.3f}\\np-value: {p:.2e}', ha='left', va='top', transform=ax.transAxes)\n",
    "# Add y=x line\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()])]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.set(title=adatas[0].var.index[idx], xlabel='Observed', ylabel='CellTRIP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94152cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[-1][-1][..., env.dim:].mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f585800",
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d942fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_perturbation(adata, steady_state, genes_to_perturb, preprocessing, modality=0, factor=0):  # adatas[0][samples_flt1], max_steps=1_000\n",
    "    # Set up env\n",
    "    env.reset()\n",
    "    env.set_positions(steady_state.to(env.device))\n",
    "    env.set_velocities(0*env.get_velocities())\n",
    "    # Find feature\n",
    "    features = [np.argwhere(adata.var.index == gene).flatten()[0] for gene in genes_to_perturb]\n",
    "    # Get knockdowns\n",
    "    iso_modality = preprocessing.transform(adata.X[:], subset_features=features, subset_modality=modality)[0]  # TODO: Send to pramod with [:] addition\n",
    "    iso_modality = torch.tensor(iso_modality).to(env.device)\n",
    "    env.modalities[modality] -= iso_modality - factor*iso_modality\n",
    "    # Simulate\n",
    "    ret = celltrip.train.simulate_until_completion(env, policy, store_states=True)\n",
    "\n",
    "    return ret[-1]\n",
    "\n",
    "# Permute\n",
    "group_pert = gene_perturbation(adatas[0][samples], steady_state, ['TMSB4X'], preprocessing, modality=0, factor=0)\n",
    "\n",
    "# Plot imputed vs actual\n",
    "df = pd.DataFrame(index=samples)\n",
    "df[['X_init', 'Y_init']] = reduction(inverse_transform(pinning_function(group_pert[0, :, :env.dim])))[..., :2]\n",
    "df[['X_final', 'Y_final']] = reduction(inverse_transform(pinning_function(group_pert[-1, :, :env.dim])))[..., :2]\n",
    "df['Type'] = adatas[0].obs.loc[samples, 'target_gene']  # 'target_gene', 'layer', 'pattern_gp_label', 'annotation'\n",
    "df['Validation'] = ~pd.DataFrame(mask, index=adatas[0].obs.index).loc[samples]\n",
    "# df = df.loc[df['Validation']]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "sns.scatterplot(df, x='X_init', y='Y_init', hue='Type', style='Validation', legend=False, ax=axs[0])\n",
    "sns.scatterplot(df, x='X_final', y='Y_final', hue='Type', style='Validation', legend=True, ax=axs[1])\n",
    "for i in np.random.choice(df.shape[0], min(50, df.shape[0]), replace=False):\n",
    "    patch = ConnectionPatch(\n",
    "        xyA=df.iloc[i][['X_init', 'Y_init']].to_numpy(), xyB=df.iloc[i][['X_final', 'Y_final']].to_numpy(),\n",
    "        coordsA='data', coordsB='data', axesA=axs[0], axesB=axs[1],\n",
    "        color='blue' if not df.iloc[i]['Validation'] else 'red', lw=.5, alpha=.25)\n",
    "    axs[1].add_patch(patch)\n",
    "axs[0].set(title='Steady State', xlabel='X', ylabel='Y')\n",
    "axs[1].set(title='Perturbed (TMSB4X)', xlabel='X')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permute\n",
    "start_state = steady_state.clone()\n",
    "start_state[0] = start_state[600]  # 600 for VCC, 1 for MERFISH\n",
    "# Set to steady state\n",
    "env.reset()  # .store_vals().set_termination_conds(exclusive=True, max_time=True) ; env.max_time = 10\n",
    "env.set_velocities(0*env.get_velocities())\n",
    "env.set_positions(start_state.to('cuda'))\n",
    "# Run and reset\n",
    "ret = celltrip.train.simulate_until_completion(env, policy, store_states=True)\n",
    "transition_states = ret[-1][..., :env.dim].cpu()\n",
    "\n",
    "# Convert select points to feature space\n",
    "use_states = list(map(int, np.linspace(0, transition_states.shape[0]-1, 9)))\n",
    "filtered_transition_states = transition_states[use_states]\n",
    "pinned_transition_states = reduction(\n",
    "    inverse_transform(\n",
    "        pinning_function(\n",
    "            filtered_transition_states.reshape((-1, env.dim))\n",
    "        )\n",
    "    )\n",
    ").reshape((*filtered_transition_states.shape[:-1], -1))\n",
    "\n",
    "# Get timepoints\n",
    "dfs = []\n",
    "for i, timepoint in enumerate(use_states):\n",
    "    timepoint = int(timepoint)\n",
    "    dfs.append(pd.DataFrame(index=samples))\n",
    "    dfs[-1][['X', 'Y']] = pinned_transition_states[i]\n",
    "    dfs[-1]['Type'] = adatas[0].obs.loc[samples, 'target_gene']\n",
    "    dfs[-1]['Timepoint'] = timepoint\n",
    "    dfs[-1]['Perturbed'] = False\n",
    "    dfs[-1].loc[samples[0], 'Perturbed'] = True\n",
    "df = pd.concat(dfs, axis=0)\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 6), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "unique_timepoints = df['Timepoint'].unique()\n",
    "target_point = 0; target_point_positions = []\n",
    "for i, timepoint in enumerate(unique_timepoints):\n",
    "    df_filter = df.loc[df['Timepoint'] == timepoint]\n",
    "    target_point_positions.append(df_filter.loc[[samples[target_point]]])\n",
    "    sns.scatterplot(df_filter, x='X', y='Y', hue='Type', alpha=.4, legend=False, ax=axs[i])\n",
    "    for j in range(i):\n",
    "        axs[i].arrow(\n",
    "            *target_point_positions[j][['X', 'Y']].to_numpy().flatten(),\n",
    "            *(target_point_positions[j+1][['X', 'Y']].to_numpy() - target_point_positions[j][['X', 'Y']].to_numpy()).flatten(),\n",
    "            color='red', lw=1)\n",
    "    sns.scatterplot(df_filter.loc[[samples[target_point]]], x='X', y='Y', color='blue', alpha=1., legend=False, ax=axs[i])\n",
    "    axs[i].set(title=f'{timepoint*env.delta:.1f}s', xlabel='X', ylabel='Y')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f5814",
   "metadata": {},
   "source": [
    "# Running out-of-scope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92850808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the external dataset\n",
    "adata = celltrip.utility.processing.read_adatas(\n",
    "    # 's3://nkalafut-celltrip/MERFISH_Bench/expression.h5ad', backed=True)[0]\n",
    "    '../data/MERFISH_Bench/sc_data.h5ad', backed=True)[0]\n",
    "# Generate or load preprocessing\n",
    "preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "# Subset and preprocess the data (Use partition cols here to select data)\n",
    "samples = adata.obs.index\n",
    "m1, = preprocessing.transform(adata[samples].X, subset_modality=0)\n",
    "# Initialize environment and policy\n",
    "env = celltrip.environment.EnvironmentBase(\n",
    "    torch.tensor(m1), target_modalities=None, dim=8).eval().to('cuda')\n",
    "# env.set_modalities(...); env.reset()  # Change modalities\n",
    "policy = celltrip.policy.create_agent_from_env(env, pinning_modal_dims=[2]).eval().to('cuda')  # pinning=False for lstq pinning\n",
    "policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb176f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run policy to convergence\n",
    "env.disable_rewards(); env.reset()\n",
    "ret = celltrip.train.simulate_until_completion(env, policy, store_states=True)\n",
    "steady_state = ret[-1][-1][:, :env.dim].cpu()\n",
    "# Get pinning and inverse\n",
    "pinning_function = lambda X: policy.pinning[0](X.to('cuda')).detach().cpu().numpy()\n",
    "inverse_transform = lambda X: preprocessing.inverse_transform(X, subset_modality=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a261570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_transform = lambda X: X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot imputed\n",
    "df = pd.DataFrame(index=samples)\n",
    "df[['X_pred', 'Y_pred']] = inverse_transform(pinning_function(steady_state))[..., :2]\n",
    "df[['X_true', 'Y_true']] = adata.obs['spot'].str.split('x', expand=True).astype(float)\n",
    "df['Type'] = adata.obs['cellType']  # pattern_gp_label, HMRF_k3_b.40\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "sns.scatterplot(df, x='X_pred', y='Y_pred', hue='Type', legend=False, ax=axs[0])\n",
    "sns.scatterplot(df, x='X_true', y='Y_true', hue='Type', legend=True, ax=axs[1])\n",
    "axs[0].set(title='CellTRIP', xlabel='X', ylabel='Y')\n",
    "axs[1].set(title='Actual', xlabel='X')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
