{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6db96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:26:15.587100Z",
     "iopub.status.busy": "2025-10-26T16:26:15.586937Z",
     "iopub.status.idle": "2025-10-26T16:26:15.601399Z",
     "shell.execute_reply": "2025-10-26T16:26:15.600758Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2754518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:26:15.603323Z",
     "iopub.status.busy": "2025-10-26T16:26:15.603126Z",
     "iopub.status.idle": "2025-10-26T16:26:18.870949Z",
     "shell.execute_reply": "2025-10-26T16:26:18.870377Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import torch\n",
    "import tqdm\n",
    "import umap\n",
    "\n",
    "import celltrip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1aac9c",
   "metadata": {},
   "source": [
    "# Load Data and Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367c9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:26:18.873108Z",
     "iopub.status.busy": "2025-10-26T16:26:18.872922Z",
     "iopub.status.idle": "2025-10-26T16:26:23.404946Z",
     "shell.execute_reply": "2025-10-26T16:26:23.404361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data files\n",
    "# adata_prefix = 's3://nkalafut-celltrip/Dyngen'\n",
    "adata_prefix = '../data/Dyngen'\n",
    "adatas = celltrip.utility.processing.read_adatas(\n",
    "    's3://nkalafut-celltrip/dyngen/logcounts.h5ad',\n",
    "    's3://nkalafut-celltrip/dyngen/counts_protein.h5ad',\n",
    "    backed=True)\n",
    "# Model location and name (should be prefix for .weights, .pre, and .mask file)\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/Dyngen-250920', 800  # 8 dim\n",
    "# prefix, training_step = 's3://nkalafut-celltrip/checkpoints/Dyngen-251015', 800  # 32 dim\n",
    "prefix, training_step = 's3://nkalafut-celltrip/checkpoints/Dyngen-251025', 800  # 32 dim, extra feature processing hidden layer\n",
    "# Generate or load preprocessing\n",
    "preprocessing = celltrip.utility.processing.Preprocessing().load(f'{prefix}.pre')\n",
    "with celltrip.utility.general.open_s3_or_local(f'{prefix}.mask', 'rb') as f:\n",
    "    mask = np.loadtxt(f).astype(bool)\n",
    "adatas[0].obs['Training'] = mask\n",
    "# Create sample env (kind of a dumb workaround, TODO)\n",
    "m1, m2 = [preprocessing.transform(ad[:2].X, subset_modality=i)[0] for i, ad in enumerate(adatas)]\n",
    "env = celltrip.environment.EnvironmentBase(\n",
    "    torch.tensor(m1), torch.tensor(m2), compute_rewards=False, dim=32).eval().to('cuda')\n",
    "# Load policy\n",
    "policy = celltrip.policy.create_agent_from_env(\n",
    "    env, forward_batch_size=1_000, vision_size=1_000).eval().to('cuda')\n",
    "policy.load_checkpoint(f'{prefix}-{training_step:04}.weights');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804b400",
   "metadata": {},
   "source": [
    "# Plot Steady State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1, m2 = [preprocessing.transform(ad.X[:], subset_modality=i)[0] for i, ad in enumerate(adatas)]\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), compute_rewards=False, dim=32).eval(time_scale=1).to('cuda')\n",
    "# ret = celltrip.train.simulate_until_completion(env, policy, skip_states=100, store_states='cpu', progress_bar=True)\n",
    "# steady_state = ret[-1][-1, :, :env.dim]\n",
    "\n",
    "# # GEX\n",
    "# with torch.no_grad():\n",
    "#     imputed_steady_state_0 = policy.pinning[0](steady_state.to('cuda')).detach().cpu().numpy()\n",
    "# imputed_steady_state_0, = preprocessing.inverse_transform(imputed_steady_state_0, subset_modality=0)\n",
    "\n",
    "# # Protein\n",
    "# with torch.no_grad():\n",
    "#     imputed_steady_state_1 = policy.pinning[1](steady_state.to('cuda')).detach().cpu().numpy()\n",
    "# imputed_steady_state_1, = preprocessing.inverse_transform(imputed_steady_state_1, subset_modality=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b67316",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate data GEX\n",
    "# X0 = adatas[0].X[:]\n",
    "# X0_pred = imputed_steady_state_0\n",
    "# red = umap.UMAP()  # random_state=42\n",
    "# Y0 = red.fit_transform(X0)\n",
    "# Y0_pred = red.transform(X0_pred)\n",
    "\n",
    "# # Generate data protein\n",
    "# X1 = adatas[1].X[:]\n",
    "# X1_pred = imputed_steady_state_1\n",
    "# red = umap.UMAP()  # random_state=42\n",
    "# Y1 = red.fit_transform(X1)\n",
    "# Y1_pred = red.transform(X1_pred)\n",
    "\n",
    "# # Plot figure\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# for i, j in itertools.product(*[np.arange(2) for _ in range(2)]):\n",
    "#     # Get axis\n",
    "#     ax = axs[i, j]\n",
    "\n",
    "#     # Get data\n",
    "#     df = pd.DataFrame(index=adatas[0].obs_names)\n",
    "#     df[['x', 'y']] = [Y0, Y0_pred, Y1, Y1_pred][2*i+j]\n",
    "#     df['Trajectory'] = adatas[0].obs['traj_sim']\n",
    "#     df['Validation'] = ~adatas[0].obs['Training']\n",
    "\n",
    "#     # Plot\n",
    "#     legend = (i==0)*(j==1)\n",
    "#     sns.scatterplot(df, x='x', y='y', hue='Trajectory', style='Validation', edgecolor='black', legend=legend, ax=ax)\n",
    "#     if legend: sns.move_legend(ax, 'upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "#     # Format\n",
    "#     ax.set(xlabel=None, ylabel=None)\n",
    "#     sns.despine(ax=ax)\n",
    "#     if j == 1:\n",
    "#         # Set xlim\n",
    "#         ax_alt = axs[i, 0]\n",
    "#         ax_alt_xlim = ax_alt.get_xlim()\n",
    "#         ax_xlim = ax.get_xlim()\n",
    "#         xlim = np.stack([ax_xlim, ax_alt_xlim], axis=0).max(axis=0)\n",
    "#         ax.set_xlim(xlim)\n",
    "        \n",
    "#         # Set ylim\n",
    "#         ax_alt = axs[i, 0]\n",
    "#         ax_alt_ylim = ax_alt.get_ylim()\n",
    "#         ax_ylim = ax.get_ylim()\n",
    "#         ylim = np.stack([ax_ylim, ax_alt_ylim], axis=0).max(axis=0)\n",
    "#         ax.set_ylim(ylim)\n",
    "\n",
    "#     # Title\n",
    "#     if i == 0:\n",
    "#         if j == 0: ax.set_title('Observed')\n",
    "#         if j == 1: ax.set_title('Reconstructed')\n",
    "#     if j == 0:\n",
    "#         if i == 0: ax.set_ylabel('Gene Expression', fontsize='large')\n",
    "#         if i == 1: ax.set_ylabel('Protein Counts', fontsize='large')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37705ce",
   "metadata": {},
   "source": [
    "# Perform Significance Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca63f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:26:23.407709Z",
     "iopub.status.busy": "2025-10-26T16:26:23.406994Z",
     "iopub.status.idle": "2025-10-26T16:26:23.452619Z",
     "shell.execute_reply": "2025-10-26T16:26:23.451955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "np.random.seed(42)\n",
    "genes_to_survey = adatas[0].var_names\n",
    "sim_time = 1.\n",
    "\n",
    "# Mute warnings (array wrap and indexing)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Create anndata\n",
    "ad_pert = ad.AnnData(obs=adatas[0].obs, var=pd.DataFrame(index=[f'Feature {i}' for i in range(env.dim)]))\n",
    "# ad_pert0 = ad.AnnData(obs=adatas[0].obs, var=adatas[0].var)\n",
    "# ad_pert1 = ad.AnnData(obs=adatas[1].obs, var=adatas[1].var)\n",
    "def add_layers(states, gene):\n",
    "    ad_pert.layers[gene] = states\n",
    "    # ad_pert0.layers[gene] = states_0\n",
    "    # ad_pert1.layers[gene] = states_1\n",
    "\n",
    "# Add results\n",
    "results = []\n",
    "def add_record(states, states_0, states_1, gene, ct):\n",
    "    results.append({\n",
    "        'Gene': gene, 'Cell Type': ct,\n",
    "        'Effect Size (Latent)': np.square(states[-1] - states[0]).mean(),\n",
    "        'Trajectory Length (Latent)': np.square(states[1:] - states[:-1]).mean(axis=(-2, -1)).sum(),\n",
    "        'Effect Size (Modality 0)': np.square(states_0[-1] - states_0[0]).mean(),\n",
    "        'Trajectory Length (Modality 0)': np.square(states_0[1:] - states_0[:-1]).mean(axis=(-2, -1)).sum(),\n",
    "        'Effect Size (Modality 1)': np.square(states_1[-1] - states_1[0]).mean(),\n",
    "        'Trajectory Length (Modality 1)': np.square(states_1[1:] - states_1[:-1]).mean(axis=(-2, -1)).sum()})\n",
    "    \n",
    "# Reset function\n",
    "def reset_env(env, steady_pos, steady_vel, modal_dict={}):\n",
    "    env.set_max_time(sim_time).reset()  # TODO: Maybe longer?, early stopping?\n",
    "    env.set_positions(steady_pos)\n",
    "    env.set_velocities(steady_vel)  # Maybe 0 manually?\n",
    "    for k, v in modal_dict.items():\n",
    "        env.modalities[k] = v\n",
    "\n",
    "# Running function\n",
    "def run_and_record(samples, env, policy, preprocessing, gene, gene_idx):\n",
    "    # Run and impute\n",
    "    states = celltrip.train.simulate_until_completion(\n",
    "        env, policy,\n",
    "        env_hooks=[\n",
    "            celltrip.utility.hooks.clamp_inverted_features_hook(\n",
    "                gene_idx, preprocessing, feature_targets=0., modality_idx=0),\n",
    "        ],\n",
    "        action_hooks=[\n",
    "            celltrip.utility.hooks.move_toward_targets_hook(\n",
    "                gene_idx, feature_targets=0., pinning=policy.pinning[0],\n",
    "                preprocessing=preprocessing, modality_idx=0,\n",
    "                factor=1, device=env.device),\n",
    "        ],\n",
    "        store_states='cpu')[-1]\n",
    "    states_pos = states[..., :env.dim]\n",
    "    with torch.no_grad():\n",
    "        imputed_states_0 = policy.pinning[0](states_pos.to('cuda')).detach().cpu().numpy()\n",
    "        imputed_states_1 = policy.pinning[1](states_pos.to('cuda')).detach().cpu().numpy()\n",
    "    imputed_states_0, = preprocessing.inverse_transform(imputed_states_0, subset_modality=0)\n",
    "    imputed_states_1, = preprocessing.inverse_transform(imputed_states_1, subset_modality=1)\n",
    "    # Record\n",
    "    add_layers(states_pos.numpy()[-1], gene)  # , imputed_states_0[-1], imputed_states_1[-1]\n",
    "    add_record(states_pos.numpy(), imputed_states_0, imputed_states_1, gene, 'All')\n",
    "    for ct in adatas[0][samples].obs['traj_sim'].unique():\n",
    "        add_record(\n",
    "            states_pos[:, adatas[0][samples].obs['traj_sim']==ct].numpy(),\n",
    "            imputed_states_0[:, adatas[0][samples].obs['traj_sim']==ct],\n",
    "            imputed_states_1[:, adatas[0][samples].obs['traj_sim']==ct],\n",
    "            gene, ct)\n",
    "\n",
    "# Subset and preprocess the data\n",
    "samples = adatas[0].obs.index\n",
    "raw_m1 = celltrip.utility.processing.chunk_X(adatas[0][samples], chunk_size=2_000)\n",
    "m1, m2 = [\n",
    "    celltrip.utility.processing.chunk_X(\n",
    "        ad[samples], chunk_size=2_000,\n",
    "        func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "        for i, ad in enumerate(adatas)]\n",
    "\n",
    "# Initialize environment\n",
    "env = celltrip.environment.EnvironmentBase(\n",
    "    torch.tensor(m1), torch.tensor(m2), compute_rewards=False, dim=env.dim).eval(time_scale=1).to('cuda')\n",
    "\n",
    "# Simulate to steady state\n",
    "env.reset()\n",
    "celltrip.train.simulate_until_completion(env, policy)\n",
    "steady_pos, steady_vel = (env.pos, env.vel)\n",
    "\n",
    "# Run control\n",
    "reset_env(env, steady_pos, steady_vel)\n",
    "add_layers(steady_pos.cpu().numpy(), 'Steady')\n",
    "run_and_record(samples, env, policy, preprocessing, 'Control', [])\n",
    "\n",
    "# Perturb\n",
    "for gene in tqdm.tqdm(genes_to_survey, miniters=10, maxinterval=30):\n",
    "    # Get gene idx and run\n",
    "    gene_idx = np.argwhere(adatas[0].var_names==gene).flatten()\n",
    "    reset_env(env, steady_pos, steady_vel)  # {0: torch.tensor(m1).cuda()}\n",
    "    run_and_record(samples, env, policy, preprocessing, gene, gene_idx)\n",
    "\n",
    "# Convert and save\n",
    "pd.DataFrame(results).to_csv('../plots/dyngen/knockdown.csv', index=None)\n",
    "ad_pert.write_h5ad('../plots/dyngen/knockdown_results.h5ad')\n",
    "# ad_pert0.write_h5ad('../plots/dyngen/knockdown_results_modality_0.csv')\n",
    "# ad_pert1.write_h5ad('../plots/dyngen/knockdown_results_modality_1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be87cd6",
   "metadata": {},
   "source": [
    "# Perform Module Knockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd0a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:26:23.455184Z",
     "iopub.status.busy": "2025-10-26T16:26:23.454756Z",
     "iopub.status.idle": "2025-10-26T16:56:34.496677Z",
     "shell.execute_reply": "2025-10-26T16:56:34.495976Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load modules\n",
    "# with celltrip.utility.general.open_s3_or_local('../plots/dyngen/dyngen_tfs.json', 'rb') as f:\n",
    "#     tf_modules = json.load(f)\n",
    "#     tf_modules.pop('NaN')\n",
    "\n",
    "# # Params\n",
    "# np.random.seed(42)\n",
    "# sim_time = 128.\n",
    "\n",
    "# # Mute warnings (array wrap and indexing)\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "# # Create anndata\n",
    "# ad_pert = ad.AnnData(obs=adatas[0].obs, var=pd.DataFrame(index=[f'Feature {i}' for i in range(env.dim)]))\n",
    "# # ad_pert0 = ad.AnnData(obs=adatas[0].obs, var=adatas[0].var)\n",
    "# # ad_pert1 = ad.AnnData(obs=adatas[1].obs, var=adatas[1].var)\n",
    "# def add_layers(states, gene):\n",
    "#     ad_pert.layers[gene] = states\n",
    "#     # ad_pert0.layers[gene] = states_0\n",
    "#     # ad_pert1.layers[gene] = states_1\n",
    "\n",
    "# # Add results\n",
    "# results = []\n",
    "# def add_record(states, states_0, states_1, gene, ct):\n",
    "#     results.append({\n",
    "#         'Gene': gene, 'Cell Type': ct,\n",
    "#         'Effect Size (Latent)': np.square(states[-1] - states[0]).mean(),\n",
    "#         'Trajectory Length (Latent)': np.square(states[1:] - states[:-1]).mean(axis=(-2, -1)).sum(),\n",
    "#         'Effect Size (Modality 0)': np.square(states_0[-1] - states_0[0]).mean(),\n",
    "#         'Trajectory Length (Modality 0)': np.square(states_0[1:] - states_0[:-1]).mean(axis=(-2, -1)).sum(),\n",
    "#         'Effect Size (Modality 1)': np.square(states_1[-1] - states_1[0]).mean(),\n",
    "#         'Trajectory Length (Modality 1)': np.square(states_1[1:] - states_1[:-1]).mean(axis=(-2, -1)).sum()})\n",
    "    \n",
    "# # Reset function\n",
    "# def reset_env(env, steady_pos, steady_vel, modal_dict={}):\n",
    "#     env.set_max_time(sim_time).reset()  # TODO: Maybe longer?, early stopping?\n",
    "#     env.set_positions(steady_pos)\n",
    "#     env.set_velocities(steady_vel)  # Maybe 0 manually?\n",
    "#     for k, v in modal_dict.items():\n",
    "#         env.modalities[k] = v\n",
    "\n",
    "# # Running function\n",
    "# def run_and_record(samples, env, policy, preprocessing, gene, gene_idx):\n",
    "#     # Run and impute\n",
    "#     states = celltrip.train.simulate_until_completion(\n",
    "#         env, policy,\n",
    "#         env_hooks=[\n",
    "#             celltrip.utility.hooks.clamp_inverted_features_hook(\n",
    "#                 gene_idx, preprocessing, feature_targets=0., modality_idx=0),\n",
    "#         ],\n",
    "#         action_hooks=[\n",
    "#             celltrip.utility.hooks.move_toward_targets_hook(\n",
    "#                 gene_idx, feature_targets=0., pinning=policy.pinning[0],\n",
    "#                 preprocessing=preprocessing, modality_idx=0,\n",
    "#                 factor=1, device=env.device),\n",
    "#         ],\n",
    "#         skip_states=100, store_states='cpu')[-1]\n",
    "#     states_pos = states[..., :env.dim]\n",
    "#     with torch.no_grad():\n",
    "#         imputed_states_0 = policy.pinning[0](states_pos.to('cuda')).detach().cpu().numpy()\n",
    "#         imputed_states_1 = policy.pinning[1](states_pos.to('cuda')).detach().cpu().numpy()\n",
    "#     imputed_states_0, = preprocessing.inverse_transform(imputed_states_0, subset_modality=0)\n",
    "#     imputed_states_1, = preprocessing.inverse_transform(imputed_states_1, subset_modality=1)\n",
    "#     # Record\n",
    "#     add_layers(states_pos.numpy()[-1], gene)  # , imputed_states_0[-1], imputed_states_1[-1]\n",
    "#     add_record(states_pos.numpy(), imputed_states_0, imputed_states_1, gene, 'All')\n",
    "#     for ct in adatas[0][samples].obs['traj_sim'].unique():\n",
    "#         add_record(\n",
    "#             states_pos[:, adatas[0][samples].obs['traj_sim']==ct].numpy(),\n",
    "#             imputed_states_0[:, adatas[0][samples].obs['traj_sim']==ct],\n",
    "#             imputed_states_1[:, adatas[0][samples].obs['traj_sim']==ct],\n",
    "#             gene, ct)\n",
    "\n",
    "# # Subset and preprocess the data\n",
    "# samples = adatas[0].obs.index\n",
    "# raw_m1 = celltrip.utility.processing.chunk_X(adatas[0][samples], chunk_size=2_000)\n",
    "# m1, m2 = [\n",
    "#     celltrip.utility.processing.chunk_X(\n",
    "#         ad[samples], chunk_size=2_000,\n",
    "#         func=lambda x: preprocessing.transform(x, subset_modality=i)[0])\n",
    "#         for i, ad in enumerate(adatas)]\n",
    "\n",
    "# # Initialize environment\n",
    "# env = celltrip.environment.EnvironmentBase(\n",
    "#     torch.tensor(m1), torch.tensor(m2), compute_rewards=False, dim=env.dim).eval(time_scale=5).to('cuda')\n",
    "\n",
    "# # Simulate to steady state\n",
    "# env.reset()\n",
    "# celltrip.train.simulate_until_completion(env, policy)\n",
    "# steady_pos, steady_vel = (env.pos, env.vel)\n",
    "\n",
    "# # Run control\n",
    "# reset_env(env, steady_pos, steady_vel)\n",
    "# add_layers(steady_pos.cpu().numpy(), 'Steady')\n",
    "# run_and_record(samples, env, policy, preprocessing, 'Control', [])\n",
    "\n",
    "# # Perturb\n",
    "# for module, genes in (pbar := tqdm.tqdm(tf_modules.items())):\n",
    "#     # Get gene idx and run\n",
    "#     pbar.set_description(module)\n",
    "#     gene_idx = np.argwhere(np.isin(adatas[0].var_names, genes)).flatten()\n",
    "#     reset_env(env, steady_pos, steady_vel)  # {0: torch.tensor(m1).cuda()}\n",
    "#     run_and_record(samples, env, policy, preprocessing, module, gene_idx)\n",
    "\n",
    "# # Convert and save\n",
    "# pd.DataFrame(results).to_csv('../plots/dyngen/knockdown_full.csv', index=None)\n",
    "# ad_pert.write_h5ad('../plots/dyngen/knockdown_full_results.h5ad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2f84a",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109e867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:56:34.572324Z",
     "iopub.status.busy": "2025-10-26T16:56:34.571972Z",
     "iopub.status.idle": "2025-10-26T16:56:39.622342Z",
     "shell.execute_reply": "2025-10-26T16:56:39.621697Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load modules\n",
    "# with celltrip.utility.general.open_s3_or_local('../plots/dyngen/dyngen_tfs.json', 'rb') as f:\n",
    "#     tf_modules = json.load(f)\n",
    "#     tf_modules.pop('NaN')\n",
    "\n",
    "# # Load perturbations\n",
    "# ad_pert = ad.read_h5ad('../plots/dyngen/knockdown_full_results.h5ad')\n",
    "# control_gex, = preprocessing.inverse_transform(policy.pinning[0](torch.tensor(ad_pert.layers['Control']).cuda()).detach().cpu().numpy(), subset_modality=0)\n",
    "\n",
    "# # Load module\n",
    "# module_pivot = []\n",
    "# for module in tf_modules.keys():\n",
    "#     pert_gex, = preprocessing.inverse_transform(policy.pinning[0](torch.tensor(ad_pert.layers[module]).cuda()).detach().cpu().numpy(), subset_modality=0)\n",
    "#     effect_sizes = pd.DataFrame(index=adatas[0].obs.index)\n",
    "#     effect_sizes['Trajectory'] = adatas[0].obs['traj_sim']\n",
    "#     effect_sizes['Effect Size'] = np.sqrt(np.square(pert_gex - control_gex).mean(axis=-1))\n",
    "#     # tf_mask, tg_mask = adatas[0].var['is_tf'], ~adatas[0].var['is_tf']\n",
    "#     tf_mask, tg_mask, hk_mask = adatas[0].var['is_tf']*~adatas[0].var['is_hk'], ~adatas[0].var['is_tf']*~adatas[0].var['is_hk'], adatas[0].var['is_hk']\n",
    "#     effect_sizes['TF Effect Size'] = np.sqrt(np.square(pert_gex[..., tf_mask] - control_gex[..., tf_mask]).mean(axis=-1))\n",
    "#     effect_sizes['TG Effect Size'] = np.sqrt(np.square(pert_gex[..., tg_mask] - control_gex[..., tg_mask]).mean(axis=-1))\n",
    "#     effect_sizes['HK Effect Size'] = np.sqrt(np.square(pert_gex[..., hk_mask] - control_gex[..., hk_mask]).mean(axis=-1))\n",
    "#     effect_sizes_pivot = effect_sizes[['Trajectory', 'TF Effect Size', 'TG Effect Size', 'HK Effect Size']].melt(id_vars='Trajectory', var_name='Type', value_name='Effect Size')\n",
    "#     effect_sizes_pivot['Type'] = effect_sizes_pivot['Type'].str.split(' ').apply(lambda a: a[0])\n",
    "#     effect_sizes_pivot['Module'] = module\n",
    "#     module_pivot.append(effect_sizes_pivot)\n",
    "# module_pivot = pd.concat(module_pivot, axis=0)\n",
    "# module_pivot = module_pivot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfc827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:56:39.624805Z",
     "iopub.status.busy": "2025-10-26T16:56:39.624593Z",
     "iopub.status.idle": "2025-10-26T16:56:39.663042Z",
     "shell.execute_reply": "2025-10-26T16:56:39.662608Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Get means and stds\n",
    "# group_cols = ['Module', 'Type']\n",
    "# grouped_means = module_pivot.groupby(group_cols, observed=True)[['Effect Size']].mean()\n",
    "# grouped_stds = module_pivot.groupby(group_cols, observed=True)[['Effect Size']].std()\n",
    "\n",
    "# # Normalize mean\n",
    "# module_pivot[['Effect Size']] = (\n",
    "#     module_pivot[['Effect Size']]\n",
    "#     - grouped_means.loc[\n",
    "#         list(\n",
    "#             module_pivot[group_cols]\n",
    "#                 .itertuples(name=None, index=False))].reset_index(drop=True))\n",
    "\n",
    "# # Normalize std\n",
    "# module_pivot[['Effect Size']] = (\n",
    "#     module_pivot[['Effect Size']]\n",
    "#     / grouped_stds.loc[\n",
    "#         list(\n",
    "#             module_pivot[group_cols]\n",
    "#                 .itertuples(name=None, index=False))].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fd112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T16:56:39.665008Z",
     "iopub.status.busy": "2025-10-26T16:56:39.664816Z",
     "iopub.status.idle": "2025-10-26T16:56:40.489604Z",
     "shell.execute_reply": "2025-10-26T16:56:40.489019Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# df = module_pivot.loc[module_pivot['Module'] == 'A1']\n",
    "# # df = df.groupby(['Trajectory', 'Type'], observed=True)[['Effect Size']].mean().reset_index()\n",
    "# sns.violinplot(df, x='Trajectory', y='Effect Size', hue='Type', split=False, inner='quart', ax=ax)\n",
    "# # sns.boxplot(df, x='Trajectory', y='Effect Size', hue='Type', ax=ax)\n",
    "# # sns.barplot(df, x='Trajectory', y='Effect Size', hue='Type', ax=ax)\n",
    "# ax.set_xticks(ax.get_xticks())\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\n",
    "# # ax.set_ylim(bottom=0, top=2)\n",
    "# # ax.set_ylim(-.5, .5)\n",
    "# sns.despine(ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celltrip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
