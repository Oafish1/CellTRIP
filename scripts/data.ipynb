{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.179704Z",
     "iopub.status.busy": "2025-03-03T23:00:01.179430Z",
     "iopub.status.idle": "2025-03-03T23:00:01.191933Z",
     "shell.execute_reply": "2025-03-03T23:00:01.191605Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.193397Z",
     "iopub.status.busy": "2025-03-03T23:00:01.193249Z",
     "iopub.status.idle": "2025-03-03T23:00:03.690845Z",
     "shell.execute_reply": "2025-03-03T23:00:03.690439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools as ft\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import scanpy as sc\n",
    "\n",
    "import celltrip\n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:03.711280Z",
     "iopub.status.busy": "2025-03-03T23:00:03.711129Z",
     "iopub.status.idle": "2025-03-03T23:00:21.605190Z",
     "shell.execute_reply": "2025-03-03T23:00:21.604778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "fnames = ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:21.606821Z",
     "iopub.status.busy": "2025-03-03T23:00:21.606663Z",
     "iopub.status.idle": "2025-03-03T23:01:15.117620Z",
     "shell.execute_reply": "2025-03-03T23:01:15.117143Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:01:15.148335Z",
     "iopub.status.busy": "2025-03-03T23:01:15.148128Z",
     "iopub.status.idle": "2025-03-03T23:04:06.070987Z",
     "shell.execute_reply": "2025-03-03T23:04:06.070582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "# NOTE: Each file still takes >1Gb for whatever reason\n",
    "fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)][:4]\n",
    "partition_cols = ['sample', 'plate']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "adatas = [celltrip.utility.processing.merge_adatas(*adatas, backed=True)]\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:04:06.072565Z",
     "iopub.status.busy": "2025-03-03T23:04:06.072408Z",
     "iopub.status.idle": "2025-03-03T23:09:00.999877Z",
     "shell.execute_reply": "2025-03-03T23:09:00.999459Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.001357Z",
     "iopub.status.busy": "2025-03-03T23:09:01.001183Z",
     "iopub.status.idle": "2025-03-03T23:09:01.099492Z",
     "shell.execute_reply": "2025-03-03T23:09:01.099122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "fnames = ['../data/MERFISH/s3_mapped_cell_table.csv', '../data/MERFISH/s3_cell_by_gene.csv']\n",
    "outfiles = ['../data/MERFISH/spatial.h5ad', '../data/MERFISH/expression.h5ad']\n",
    "\n",
    "# Spatial\n",
    "fname = fnames[0]\n",
    "df = pd.read_csv(fname, index_col=0, header=0).set_index('sample_name')\n",
    "df_obs = df[['area', 'experiment', 'layer']]\n",
    "df = df[['xc_adjusted', 'yc_adjusted']]\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# Gene expression\n",
    "fname = fnames[1]\n",
    "df = pd.read_csv(fname, index_col=0, header=1)\n",
    "df.index.name = 'sample_name'\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.100793Z",
     "iopub.status.busy": "2025-03-03T23:09:01.100645Z",
     "iopub.status.idle": "2025-03-03T23:09:01.152506Z",
     "shell.execute_reply": "2025-03-03T23:09:01.152090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = 'layer'\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, pca_dim=128)  # , mask=.8, seed=42\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Brain\n",
    "import rds2py\n",
    "fnames = ['../data/temporalBrain/GSE204683_count_matrix.RDS', '../data/temporalBrain/GSE204682_count_matrix.RDS']\n",
    "barcodes = ['../data/temporalBrain/GSE204683_barcodes.tsv', '../data/temporalBrain/GSE204682_barcodes.tsv']\n",
    "outfiles = ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "\n",
    "# Load RNA\n",
    "rdata = rds2py.parse_rds(fnames[0])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M1, F1, C1 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B1 = pd.read_csv(barcodes[0], delimiter='\\t')\n",
    "\n",
    "# Load ATAC\n",
    "rdata = rds2py.parse_rds(fnames[1])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M2, F2, C2 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B2 = pd.read_csv(barcodes[1], delimiter='\\t')\n",
    "\n",
    "# Get sample ids\n",
    "uniq_col, count_col = np.unique([e.split('_')[0] for e in C1], return_counts=True)\n",
    "assert np.unique(count_col, return_counts=True)[1].max() == 1  # No duplicate counts, otherwise manual annotation is needed\n",
    "# Get donor ids\n",
    "uniq_donor, count_donor = np.unique(B1['Donor ID'], return_counts=True)\n",
    "assert (np.sort(count_col) == np.sort(count_donor)).all()\n",
    "# Convert (aided by `preprocessing.R`)\n",
    "name_to_id = {d: c for c, d in zip(uniq_col[np.argsort(count_col)], uniq_donor[np.argsort(count_donor)])}\n",
    "# Set indices\n",
    "B1['Cell ID'] = B1.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "B2['Cell ID'] = B2.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "assert (B1.set_index('Cell ID') == B1.set_index('Cell ID').loc[C1]).all().all()  # For some reason, `barcodes2` doesn't line up with `C2`, so we assume both meta are the correct order\n",
    "B2['Cell ID'] = B1['Cell ID']  # Set Cell IDs to be the same\n",
    "\n",
    "# RNA AnnData\n",
    "adata = ad.AnnData(M1, obs=B1.set_index('Cell ID').loc[C1])\n",
    "adata.var_names = F1\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# ATAC AnnData\n",
    "adata = ad.AnnData(M2, obs=B2.set_index('Cell ID'))\n",
    "adata.var_names = F2\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flysta3D\n",
    "periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']  # [4:]\n",
    "fnames = [f'../data/Flysta3D/{p}_count_normal_stereoseq.h5ad' for p in periods]\n",
    "adatas_rna = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "# Annotate development\n",
    "for p, adata in zip(periods, adatas_rna):\n",
    "    adata.obs['development'] = p\n",
    "# Resave expression adatas\n",
    "# NOTE: Flysta doesn't have `encoding-type` under attributes for whatever reason, which necessitates this\n",
    "for p, adata in zip(periods, adatas_rna):\n",
    "    adata = ad.AnnData(adata.X, obs=adata.obs, var=adata.var)\n",
    "    adata.write_h5ad(f'../data/Flysta3D/{p}_expression.h5ad')\n",
    "# Create spatial adatas\n",
    "adatas_spatial = [ad.AnnData(adata.obsm['spatial'], obs=adata.obs) for adata in adatas_rna]\n",
    "for p, adata in zip(periods, adatas_spatial):\n",
    "    adata.write_h5ad(f'../data/Flysta3D/{p}_spatial.h5ad')\n",
    "\n",
    "# Test\n",
    "# periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']\n",
    "# fnames_1 = [f'../data/Flysta3D/{p}_expression.h5ad' for p in periods]\n",
    "# fnames_2 = [f'../data/Flysta3D/{p}_spatial.h5ad' for p in periods]\n",
    "# adatas_rna = celltrip.utility.processing.read_adatas(*fnames_1, backed=True)\n",
    "# adatas_spatial = celltrip.utility.processing.read_adatas(*fnames_2, backed=True)\n",
    "# adatas_rna = celltrip.utility.processing.merge_adatas(*adatas_rna, backed=True)\n",
    "# adatas_spatial = celltrip.utility.processing.merge_adatas(*adatas_spatial, backed=True)\n",
    "# adatas = [adatas_rna, adatas_spatial]\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas, partition_cols='slice_ID')\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scMultiSim\n",
    "fnames = ['../data/scMultiSim/scMultiSim_RNA_counts_1250_genes.csv', '../data/scMultiSim/scMultiSim_ATAC_seq_1250_genes_new.csv']\n",
    "fname_meta = '../data/scMultiSim/cell_meta_1250_genes.csv'\n",
    "outfiles = ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "meta = pd.read_csv(fname_meta, index_col=0).T\n",
    "for fname, out_fname in zip(fnames, outfiles):\n",
    "    X = pd.read_csv(fnames[0])\n",
    "    adata = ad.AnnData(X)\n",
    "    adata.obs = meta\n",
    "    adata.write_h5ad(out_fname)\n",
    "\n",
    "# Test\n",
    "# fnames = ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "# adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas)\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERFISH CMAP Benchmark\n",
    "fnames = ['../data/MERFISH_Bench/sim.cmap.spatial_location.csv', '../data/MERFISH_Bench/sim.cmap.spatial_count.csv']\n",
    "outfiles = ['../data/MERFISH_Bench/spatial.h5ad', '../data/MERFISH_Bench/expression.h5ad']\n",
    "adatas = []\n",
    "\n",
    "# Spatial\n",
    "fname = fnames[0]\n",
    "df = pd.read_csv(fname)\n",
    "df_obs = df[['pattern_gp_label', 'x_round', 'y_round', 'HMRF_k3_b.40']]\n",
    "df = df[['x', 'y']]\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# Expression\n",
    "fname = fnames[1]\n",
    "df = pd.read_csv(fname).T\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[1])\n",
    "\n",
    "# Test\n",
    "# fnames = ['../data/MERFISH_Bench/expression.h5ad', '../data/MERFISH_Bench/spatial.h5ad']\n",
    "# partition_cols = None\n",
    "# adatas = celltrip.utility.processing.read_adatas(*fnames, backed=False)\n",
    "# celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "#     *adatas, partition_cols=partition_cols, pca_dim=128)  # , mask=.8, seed=42\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dyngen simulation data\n",
    "fnames = ['../data/dyngen/dyngen_sim.h5ad']\n",
    "outfile_prefix = '../data/dyngen/'\n",
    "outfiles = []\n",
    "\n",
    "# Load and separate layers\n",
    "adata, = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "for layer in adata.layers:\n",
    "    outfile = os.path.join(outfile_prefix, f'{layer}.h5ad')\n",
    "    new_adata = ad.AnnData(adata.layers[layer], obs=adata.obs, var=adata.var)\n",
    "    new_adata.write_h5ad(outfile)\n",
    "    outfiles.append(outfile)\n",
    "print(outfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CancerVel simulation data\n",
    "fname = '../data/CancerVel/K562_cancer_data.h5ad'\n",
    "outfile = '../data/CancerVel/expression.h5ad'\n",
    "\n",
    "# Load and transpose\n",
    "adata, = celltrip.utility.processing.read_adatas(fname)  # Must be read into memory for transpose\n",
    "new_adata = adata.T\n",
    "for col in ['sgAssign', 'sgAssign2', 'sgAssign3', 'sgAssignNew']:  # NA values are not supported for partitions\n",
    "    new_adata.obs[col] = new_adata.obs[col].cat.add_categories('None').fillna('None')\n",
    "new_adata.write_h5ad(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERFISH30k simulation data\n",
    "fname = '../data/MERFISH30k/comb.h5ad'\n",
    "outfile = '../data/MERFISH30k/spatial.h5ad'\n",
    "outfiles = []\n",
    "\n",
    "# Load and separate layers\n",
    "adata, = celltrip.utility.processing.read_adatas(fname, backed=True)\n",
    "spatial_adata = ad.AnnData(X=adata.obs[['x', 'y']], obs=adata.obs)\n",
    "spatial_adata.write_h5ad(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate files to upload\n",
    "fnames = []; folders = []\n",
    "\n",
    "# scGLUE\n",
    "# fnames += ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "# folders += len(fnames)*['scGLUE']\n",
    "# partition_cols = None\n",
    "\n",
    "# MERFISH\n",
    "# fnames += ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH']\n",
    "# partition_cols = None\n",
    "\n",
    "# Temporal Brain ('Donor ID')\n",
    "# fnames += ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "# folders += len(fnames)*['TemporalBrain']\n",
    "# partition_cols = None\n",
    "\n",
    "# TAHOE-100M ('sample')\n",
    "# fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)]\n",
    "# folders += len(fnames)*['Tahoe']\n",
    "# partition_cols = None\n",
    "\n",
    "# Flysta3D ('slice_ID')\n",
    "# periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']\n",
    "# fnames += (\n",
    "#     # [f'../data/Flysta3D/{p}_count_normal_stereoseq.h5ad' for p in periods]\n",
    "#     [f'../data/Flysta3D/{p}_expression.h5ad' for p in periods]\n",
    "#     + [f'../data/Flysta3D/{p}_spatial.h5ad' for p in periods])\n",
    "# folders += len(fnames)*['Flysta3D']\n",
    "\n",
    "# scMultiSim\n",
    "# fnames += ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "# folders += len(fnames)*['scMultiSim']\n",
    "\n",
    "# MERFISH CMAP Benchmark\n",
    "# fnames += ['../data/MERFISH_Bench/expression.h5ad', '../data/MERFISH_Bench/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH_Bench']\n",
    "\n",
    "# Virtual Cell Challenge\n",
    "# fnames += ['../data/VirtualCell/vcc_flt_data.h5ad']\n",
    "# folders += len(fnames)*['VirtualCell']\n",
    "\n",
    "# dyngen\n",
    "# fnames += [\n",
    "#     '../data/dyngen/counts_protein.h5ad', '../data/dyngen/counts_spliced.h5ad',\n",
    "#     '../data/dyngen/counts_unspliced.h5ad', '../data/dyngen/logcounts.h5ad',\n",
    "#     '../data/dyngen/rna_velocity.h5ad']\n",
    "# folders += len(fnames)*['dyngen']\n",
    "\n",
    "# CancerVel\n",
    "# fnames += ['../data/CancerVel/expression.h5ad']\n",
    "# folders += len(fnames)*['CancerVel']\n",
    "\n",
    "# MERFISH30k\n",
    "# fnames += ['../data/MERFISH30k/comb.h5ad', '../data/MERFISH30k/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH30k']\n",
    "\n",
    "# Upload\n",
    "for fname, folder in zip(fnames, folders): s3.put(fname, os.path.join(os.path.join('s3://nkalafut-celltrip', folder), os.path.basename(fname)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturb or Knock Features in Processed Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gene knockdown in processed data\n",
    "modality_to_test = 0\n",
    "features_to_test = [200, 150]\n",
    "adatas, _, adata_vars = dataloader.get_transformables()\n",
    "iso_modality = dataloader.preprocessing.transform(\n",
    "    adatas[modality_to_test][adata_obs[modality_to_test].index].X,\n",
    "    # force_filter=True,\n",
    "    subset_features=features_to_test,\n",
    "    subset_modality=modality_to_test)[0]\n",
    "knocked_modality = modalities[modality_to_test] - iso_modality\n",
    "\n",
    "# Verify the knockdown works\n",
    "orig_modality, = dataloader.preprocessing.inverse_transform(modalities[modality_to_test], subset_modality=modality_to_test)\n",
    "inv_modality, = dataloader.preprocessing.inverse_transform(knocked_modality, subset_modality=modality_to_test)\n",
    "change = np.abs(orig_modality - inv_modality).sum(axis=0) / dataloader.preprocessing.standardize_std[modality_to_test]\n",
    "most_changed_idx = dataloader.preprocessing.filter_mask[modality_to_test][np.argsort(change).flatten()[-len(features_to_test):]]\n",
    "print(f'Targets: {np.array(features_to_test)}, Most Changed: {most_changed_idx}, should be the same elements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.153843Z",
     "iopub.status.busy": "2025-03-03T23:09:01.153691Z",
     "iopub.status.idle": "2025-03-03T23:09:01.194871Z",
     "shell.execute_reply": "2025-03-03T23:09:01.194513Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
