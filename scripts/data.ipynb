{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.179704Z",
     "iopub.status.busy": "2025-03-03T23:00:01.179430Z",
     "iopub.status.idle": "2025-03-03T23:00:01.191933Z",
     "shell.execute_reply": "2025-03-03T23:00:01.191605Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.193397Z",
     "iopub.status.busy": "2025-03-03T23:00:01.193249Z",
     "iopub.status.idle": "2025-03-03T23:00:03.690845Z",
     "shell.execute_reply": "2025-03-03T23:00:03.690439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools as ft\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import scanpy as sc\n",
    "\n",
    "import celltrip\n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:03.711280Z",
     "iopub.status.busy": "2025-03-03T23:00:03.711129Z",
     "iopub.status.idle": "2025-03-03T23:00:21.605190Z",
     "shell.execute_reply": "2025-03-03T23:00:21.604778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "fnames = ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:21.606821Z",
     "iopub.status.busy": "2025-03-03T23:00:21.606663Z",
     "iopub.status.idle": "2025-03-03T23:01:15.117620Z",
     "shell.execute_reply": "2025-03-03T23:01:15.117143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling takes ~5.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:01:15.148335Z",
     "iopub.status.busy": "2025-03-03T23:01:15.148128Z",
     "iopub.status.idle": "2025-03-03T23:04:06.070987Z",
     "shell.execute_reply": "2025-03-03T23:04:06.070582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "# NOTE: Each file still takes >1Gb for whatever reason\n",
    "fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)][:4]\n",
    "partition_cols = ['sample', 'plate']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "adatas = celltrip.utility.processing.merge_adatas(*adatas, backed=True)\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:04:06.072565Z",
     "iopub.status.busy": "2025-03-03T23:04:06.072408Z",
     "iopub.status.idle": "2025-03-03T23:09:00.999877Z",
     "shell.execute_reply": "2025-03-03T23:09:00.999459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling takes ~11.80 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.001357Z",
     "iopub.status.busy": "2025-03-03T23:09:01.001183Z",
     "iopub.status.idle": "2025-03-03T23:09:01.099492Z",
     "shell.execute_reply": "2025-03-03T23:09:01.099122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/envs/celltrip/lib/python3.12/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/thema/miniconda3/envs/celltrip/lib/python3.12/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "fnames = ['../data/MERFISH/s3_mapped_cell_table.csv', '../data/MERFISH/s3_cell_by_gene.csv']\n",
    "outfiles = ['../data/MERFISH/spatial.h5ad', '../data/MERFISH/expression.h5ad']\n",
    "partition_cols = 'experiment'\n",
    "adatas = []\n",
    "\n",
    "# Spatial\n",
    "fname = fnames[0]\n",
    "df = pd.read_csv(fname, index_col=0, header=0).set_index('sample_name')\n",
    "df_obs = df[['area', 'experiment', 'layer']]\n",
    "df = df[['xc_adjusted', 'yc_adjusted']]\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# Gene expression\n",
    "fname = fnames[1]\n",
    "df = pd.read_csv(fname, index_col=0, header=1)\n",
    "df.index.name = 'sample_name'\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.100793Z",
     "iopub.status.busy": "2025-03-03T23:09:01.100645Z",
     "iopub.status.idle": "2025-03-03T23:09:01.152506Z",
     "shell.execute_reply": "2025-03-03T23:09:01.152090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/utility/processing.py:109: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Read\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = 'layer'\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, pca_dim=128)  # , mask=.8, seed=42\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Brain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rds2py\n",
    "fnames = ['../data/temporalBrain/GSE204683_count_matrix.RDS', '../data/temporalBrain/GSE204682_count_matrix.RDS']\n",
    "barcodes = ['../data/temporalBrain/GSE204683_barcodes.tsv', '../data/temporalBrain/GSE204682_barcodes.tsv']\n",
    "outfiles = ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "\n",
    "# Load RNA\n",
    "rdata = rds2py.parse_rds(fnames[0])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M1, F1, C1 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B1 = pd.read_csv(barcodes[0], delimiter='\\t')\n",
    "\n",
    "# Load ATAC\n",
    "rdata = rds2py.parse_rds(fnames[1])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M2, F2, C2 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B2 = pd.read_csv(barcodes[1], delimiter='\\t')\n",
    "\n",
    "# Get sample ids\n",
    "uniq_col, count_col = np.unique([e.split('_')[0] for e in C1], return_counts=True)\n",
    "assert np.unique(count_col, return_counts=True)[1].max() == 1  # No duplicate counts, otherwise manual annotation is needed\n",
    "# Get donor ids\n",
    "uniq_donor, count_donor = np.unique(B1['Donor ID'], return_counts=True)\n",
    "assert (np.sort(count_col) == np.sort(count_donor)).all()\n",
    "# Convert (aided by `preprocessing.R`)\n",
    "name_to_id = {d: c for c, d in zip(uniq_col[np.argsort(count_col)], uniq_donor[np.argsort(count_donor)])}\n",
    "# Set indices\n",
    "B1['Cell ID'] = B1.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "B2['Cell ID'] = B2.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "assert (B1.set_index('Cell ID') == B1.set_index('Cell ID').loc[C1]).all().all()  # For some reason, `barcodes2` doesn't line up with `C2`, so we assume both meta are the correct order\n",
    "\n",
    "# RNA AnnData\n",
    "adata = ad.AnnData(M1, obs=B1.set_index('Cell ID').loc[C1])\n",
    "adata.var_names = F1\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# ATAC AnnData\n",
    "adata = ad.AnnData(M2, obs=B2.set_index('Cell ID'))\n",
    "adata.var_names = F2\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate files to upload\n",
    "fnames = []; folders = []\n",
    "\n",
    "# scGLUE\n",
    "# fnames += ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "# folders += 2*['scGLUE']\n",
    "\n",
    "# MERFISH\n",
    "# fnames += ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "# folders += 2*['MERFISH']\n",
    "\n",
    "# Temporal Brain\n",
    "fnames += ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "folders += 2*['TemporalBrain']\n",
    "\n",
    "# TAHOE-100M\n",
    "# fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)]\n",
    "# folders += 2*['Tahoe']\n",
    "\n",
    "# Upload\n",
    "for folder, fname in zip(folders, fnames): s3.put(fname, os.path.join(os.path.join('s3://nkalafut-celltrip', folder), os.path.basename(fname)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturb or Knock Features in Processed Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: [200 150], Most Changed: [150 200], should be the same elements\n"
     ]
    }
   ],
   "source": [
    "# Perform gene knockdown in processed data\n",
    "modality_to_test = 0\n",
    "features_to_test = [200, 150]\n",
    "adatas, _, adata_vars = dataloader.get_transformables()\n",
    "iso_modality = dataloader.preprocessing.transform(\n",
    "    adatas[modality_to_test][adata_obs[modality_to_test].index].X,\n",
    "    # force_filter=True,\n",
    "    subset_features=features_to_test,\n",
    "    subset_modality=modality_to_test)[0]\n",
    "knocked_modality = modalities[modality_to_test] - iso_modality\n",
    "\n",
    "# Verify the knockdown works\n",
    "orig_modality, = dataloader.preprocessing.inverse_transform(modalities[modality_to_test], subset_modality=modality_to_test)\n",
    "inv_modality, = dataloader.preprocessing.inverse_transform(knocked_modality, subset_modality=modality_to_test)\n",
    "change = np.abs(orig_modality - inv_modality).sum(axis=0) / dataloader.preprocessing.standardize_std[modality_to_test]\n",
    "most_changed_idx = dataloader.preprocessing.filter_mask[modality_to_test][np.argsort(change).flatten()[-len(features_to_test):]]\n",
    "print(f'Targets: {np.array(features_to_test)}, Most Changed: {most_changed_idx}, should be the same elements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.153843Z",
     "iopub.status.busy": "2025-03-03T23:09:01.153691Z",
     "iopub.status.idle": "2025-03-03T23:09:01.194871Z",
     "shell.execute_reply": "2025-03-03T23:09:01.194513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling takes ~0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
