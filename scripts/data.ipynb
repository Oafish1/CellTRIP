{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.179704Z",
     "iopub.status.busy": "2025-03-03T23:00:01.179430Z",
     "iopub.status.idle": "2025-03-03T23:00:01.191933Z",
     "shell.execute_reply": "2025-03-03T23:00:01.191605Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:01.193397Z",
     "iopub.status.busy": "2025-03-03T23:00:01.193249Z",
     "iopub.status.idle": "2025-03-03T23:00:03.690845Z",
     "shell.execute_reply": "2025-03-03T23:00:03.690439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools as ft\n",
    "import warnings\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import scanpy as sc\n",
    "\n",
    "import celltrip\n",
    "\n",
    "os.environ['AWS_PROFILE'] = 'waisman-admin'\n",
    "s3 = s3fs.S3FileSystem(skip_instance_cache=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:03.711280Z",
     "iopub.status.busy": "2025-03-03T23:00:03.711129Z",
     "iopub.status.idle": "2025-03-03T23:00:21.605190Z",
     "shell.execute_reply": "2025-03-03T23:00:21.604778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "fnames = ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:00:21.606821Z",
     "iopub.status.busy": "2025-03-03T23:00:21.606663Z",
     "iopub.status.idle": "2025-03-03T23:01:15.117620Z",
     "shell.execute_reply": "2025-03-03T23:01:15.117143Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:01:15.148335Z",
     "iopub.status.busy": "2025-03-03T23:01:15.148128Z",
     "iopub.status.idle": "2025-03-03T23:04:06.070987Z",
     "shell.execute_reply": "2025-03-03T23:04:06.070582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "# NOTE: Each file still takes >1Gb for whatever reason\n",
    "fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)][:4]\n",
    "partition_cols = ['sample', 'plate']\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "adatas = [celltrip.utility.processing.merge_adatas(*adatas, backed=True)]\n",
    "celltrip.utility.processing.test_adatas(*adatas)\n",
    "\n",
    "# Sample data\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:04:06.072565Z",
     "iopub.status.busy": "2025-03-03T23:04:06.072408Z",
     "iopub.status.idle": "2025-03-03T23:09:00.999877Z",
     "shell.execute_reply": "2025-03-03T23:09:00.999459Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.001357Z",
     "iopub.status.busy": "2025-03-03T23:09:01.001183Z",
     "iopub.status.idle": "2025-03-03T23:09:01.099492Z",
     "shell.execute_reply": "2025-03-03T23:09:01.099122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "fnames = ['../data/MERFISH/s3_mapped_cell_table.csv', '../data/MERFISH/s3_cell_by_gene.csv']\n",
    "outfiles = ['../data/MERFISH/spatial.h5ad', '../data/MERFISH/expression.h5ad']\n",
    "\n",
    "# Spatial\n",
    "fname = fnames[0]\n",
    "df = pd.read_csv(fname, index_col=0, header=0).set_index('sample_name')\n",
    "df_obs = df[['area', 'experiment', 'layer']]\n",
    "df = df[['xc_adjusted', 'yc_adjusted']]\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# Gene expression\n",
    "fname = fnames[1]\n",
    "df = pd.read_csv(fname, index_col=0, header=1)\n",
    "df.index.name = 'sample_name'\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.100793Z",
     "iopub.status.busy": "2025-03-03T23:09:01.100645Z",
     "iopub.status.idle": "2025-03-03T23:09:01.152506Z",
     "shell.execute_reply": "2025-03-03T23:09:01.152090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = 'layer'\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, backed=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, pca_dim=128)  # , mask=.8, seed=42\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Brain\n",
    "import rds2py\n",
    "fnames = ['../data/temporalBrain/GSE204683_count_matrix.RDS', '../data/temporalBrain/GSE204682_count_matrix.RDS']\n",
    "barcodes = ['../data/temporalBrain/GSE204683_barcodes.tsv', '../data/temporalBrain/GSE204682_barcodes.tsv']\n",
    "outfiles = ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "\n",
    "# Load RNA\n",
    "rdata = rds2py.parse_rds(fnames[0])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M1, F1, C1 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B1 = pd.read_csv(barcodes[0], delimiter='\\t')\n",
    "\n",
    "# Load ATAC\n",
    "rdata = rds2py.parse_rds(fnames[1])\n",
    "rdata['attributes']['dimnames'] = rdata['attributes']['Dimnames']\n",
    "wrapper = rds2py.generics._dispatcher(rdata)\n",
    "M2, F2, C2 = wrapper.matrix.T, *[np.array(sl) for sl in wrapper.dimnames]\n",
    "B2 = pd.read_csv(barcodes[1], delimiter='\\t')\n",
    "\n",
    "# Get sample ids\n",
    "uniq_col, count_col = np.unique([e.split('_')[0] for e in C1], return_counts=True)\n",
    "assert np.unique(count_col, return_counts=True)[1].max() == 1  # No duplicate counts, otherwise manual annotation is needed\n",
    "# Get donor ids\n",
    "uniq_donor, count_donor = np.unique(B1['Donor ID'], return_counts=True)\n",
    "assert (np.sort(count_col) == np.sort(count_donor)).all()\n",
    "# Convert (aided by `preprocessing.R`)\n",
    "name_to_id = {d: c for c, d in zip(uniq_col[np.argsort(count_col)], uniq_donor[np.argsort(count_donor)])}\n",
    "# Set indices\n",
    "B1['Cell ID'] = B1.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "B2['Cell ID'] = B2.apply(lambda r: f'{name_to_id[r[\"Donor ID\"]]}_{r[\"Barcode\"]}', axis=1)\n",
    "assert (B1.set_index('Cell ID') == B1.set_index('Cell ID').loc[C1]).all().all()  # For some reason, `barcodes2` doesn't line up with `C2`, so we assume both meta are the correct order\n",
    "B2['Cell ID'] = B1['Cell ID']  # Set Cell IDs to be the same\n",
    "\n",
    "# RNA AnnData\n",
    "adata = ad.AnnData(M1, obs=B1.set_index('Cell ID').loc[C1])\n",
    "adata.var_names = F1\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# ATAC AnnData\n",
    "adata = ad.AnnData(M2, obs=B2.set_index('Cell ID'))\n",
    "adata.var_names = F2\n",
    "adata.write_h5ad(outfiles[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flysta3D\n",
    "periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']  # [4:]\n",
    "fnames = [f'../data/Flysta3D/{p}_count_normal_stereoseq.h5ad' for p in periods]\n",
    "adatas_rna = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "# Annotate development\n",
    "for p, adata in zip(periods, adatas_rna):\n",
    "    adata.obs['development'] = p\n",
    "# Resave expression adatas\n",
    "# NOTE: Flysta doesn't have `encoding-type` under attributes for whatever reason, which necessitates this\n",
    "for p, adata in zip(periods, adatas_rna):\n",
    "    adata = ad.AnnData(adata.X, obs=adata.obs, var=adata.var)\n",
    "    adata.write_h5ad(f'../data/Flysta3D/{p}_expression.h5ad')\n",
    "# Create spatial adatas\n",
    "adatas_spatial = [ad.AnnData(adata.obsm['spatial'], obs=adata.obs) for adata in adatas_rna]\n",
    "for p, adata in zip(periods, adatas_spatial):\n",
    "    adata.write_h5ad(f'../data/Flysta3D/{p}_spatial.h5ad')\n",
    "\n",
    "# Test\n",
    "# periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']\n",
    "# fnames_1 = [f'../data/Flysta3D/{p}_expression.h5ad' for p in periods]\n",
    "# fnames_2 = [f'../data/Flysta3D/{p}_spatial.h5ad' for p in periods]\n",
    "# adatas_rna = celltrip.utility.processing.read_adatas(*fnames_1, backed=True)\n",
    "# adatas_spatial = celltrip.utility.processing.read_adatas(*fnames_2, backed=True)\n",
    "# adatas_rna = celltrip.utility.processing.merge_adatas(*adatas_rna, backed=True)\n",
    "# adatas_spatial = celltrip.utility.processing.merge_adatas(*adatas_spatial, backed=True)\n",
    "# adatas = [adatas_rna, adatas_spatial]\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas, partition_cols='slice_ID')\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scMultiSim\n",
    "fnames = ['../data/scMultiSim/scMultiSim_RNA_counts_1250_genes.csv', '../data/scMultiSim/scMultiSim_ATAC_seq_1250_genes_new.csv']\n",
    "fname_meta = '../data/scMultiSim/cell_meta_1250_genes.csv'\n",
    "outfiles = ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "meta = pd.read_csv(fname_meta, index_col=0).T\n",
    "for fname, out_fname in zip(fnames, outfiles):\n",
    "    X = pd.read_csv(fnames[0])\n",
    "    adata = ad.AnnData(X)\n",
    "    adata.obs = meta\n",
    "    adata.write_h5ad(out_fname)\n",
    "\n",
    "# Test\n",
    "# fnames = ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "# adatas = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(*adatas)\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERFISH CMAP Benchmark\n",
    "fnames = ['../data/MERFISH_Bench/sim.cmap.spatial_location.csv', '../data/MERFISH_Bench/sim.cmap.spatial_count.csv']\n",
    "outfiles = ['../data/MERFISH_Bench/spatial.h5ad', '../data/MERFISH_Bench/expression.h5ad']\n",
    "adatas = []\n",
    "\n",
    "# Spatial\n",
    "fname = fnames[0]\n",
    "df = pd.read_csv(fname)\n",
    "df_obs = df[['pattern_gp_label', 'x_round', 'y_round', 'HMRF_k3_b.40']]\n",
    "df = df[['x', 'y']]\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[0])\n",
    "\n",
    "# Expression\n",
    "fname = fnames[1]\n",
    "df = pd.read_csv(fname).T\n",
    "adata = ad.AnnData(df, obs=df_obs)\n",
    "adata.write_h5ad(outfiles[1])\n",
    "\n",
    "# Test\n",
    "# fnames = ['../data/MERFISH_Bench/expression.h5ad', '../data/MERFISH_Bench/spatial.h5ad']\n",
    "# partition_cols = None\n",
    "# adatas = celltrip.utility.processing.read_adatas(*fnames, backed=False)\n",
    "# celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "# dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "#     *adatas, partition_cols=partition_cols, pca_dim=128)  # , mask=.8, seed=42\n",
    "# modalities, adata_obs, adata_vars = dataloader.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dyngen simulation data\n",
    "fnames = ['../data/dyngen/dyngen_sim.h5ad']\n",
    "outfile_prefix = '../data/dyngen/'\n",
    "outfiles = []\n",
    "\n",
    "# Load and separate layers\n",
    "adata, = celltrip.utility.processing.read_adatas(*fnames, backed=True)\n",
    "for layer in adata.layers:\n",
    "    outfile = os.path.join(outfile_prefix, f'{layer}.h5ad')\n",
    "    new_adata = ad.AnnData(adata.layers[layer], obs=adata.obs, var=adata.var)\n",
    "    new_adata.write_h5ad(outfile)\n",
    "    outfiles.append(outfile)\n",
    "print(outfiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CancerVel simulation data\n",
    "fname = '../data/CancerVel/K562_cancer_data.h5ad'\n",
    "outfile = '../data/CancerVel/expression.h5ad'\n",
    "\n",
    "# Load and transpose\n",
    "adata, = celltrip.utility.processing.read_adatas(fname)  # Must be read into memory for transpose\n",
    "new_adata = adata.T\n",
    "for col in ['sgAssign', 'sgAssign2', 'sgAssign3', 'sgAssignNew']:  # NA values are not supported for partitions\n",
    "    new_adata.obs[col] = new_adata.obs[col].cat.add_categories('None').fillna('None')\n",
    "new_adata.obs['known_not_d6'] = (new_adata.obs['days'] != 'D6') * (new_adata.obs['sgAssignNew'] != 'UNK')  # Mask for known and not D6\n",
    "new_adata.write_h5ad(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERFISH30k simulation data\n",
    "fname = '../data/MERFISH30k/comb.h5ad'\n",
    "outfile = ['../data/MERFISH30k/expression.h5ad', '../data/MERFISH30k/spatial.h5ad']\n",
    "outfiles = []\n",
    "\n",
    "# Load and separate layers\n",
    "adata, = celltrip.utility.processing.read_adatas(fname, backed=True)\n",
    "adata.obs['is_slice153'] = adata.obs['slice_id'] == 'mouse1_slice153'\n",
    "adata.write_h5ad(outfile[0])\n",
    "spatial_adata = ad.AnnData(X=adata.obs[['x', 'y']], obs=adata.obs)\n",
    "spatial_adata.write_h5ad(outfile[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerturbMM simulation data\n",
    "fname = '../data/PerturbMM/RNA_scaled_crispr_screen_20240615.h5ad'\n",
    "outfile = ['../data/PerturbMM/expression.h5ad', '../data/PerturbMM/spatial.h5ad']\n",
    "\n",
    "# Load\n",
    "adata, = celltrip.utility.processing.read_adatas(fname, backed=True)\n",
    "\n",
    "# Annotate slices with dbscan\n",
    "import sklearn.cluster\n",
    "adata.obs['batch_clusters'] = '-1'\n",
    "for batch in adata.obs['batch'].unique():\n",
    "    obs_mask = adata.obs['batch']==batch\n",
    "    if batch == '10': min_samples = 50  # `min_samples` is important for the batch 10 overlapping slices\n",
    "    else: min_samples = 5\n",
    "    dbscan = sklearn.cluster.DBSCAN(eps=100, min_samples=min_samples)\n",
    "    cluster_ids = dbscan.fit_predict(adata.obs.loc[obs_mask, ['x', 'y']].to_numpy())\n",
    "    unique_cluster_ids, unique_cluster_sizes = np.unique(cluster_ids, return_counts=True)\n",
    "    min_cluster_size = 2_000\n",
    "    cluster_ids[np.isin(cluster_ids, unique_cluster_ids[unique_cluster_sizes<min_cluster_size])] = -1  # Erase clusters below threshold\n",
    "    cluster_ids = list(map(str, cluster_ids))  # Stringify\n",
    "    adata.obs.loc[obs_mask, 'batch_clusters'] = cluster_ids\n",
    "\n",
    "# Seed\n",
    "np.random.seed(42)\n",
    "# Annotate valid slices and slice identifiers\n",
    "adata.obs['slice_identified'] = adata.obs['batch_clusters'] != '-1'\n",
    "adata.obs['slice_id'] = adata.obs.apply(lambda r: f'{r[\"batch\"]}-{r[\"batch_clusters\"]}' if r['slice_identified'] else 'None', axis=1)\n",
    "unique_slice_ids = adata.obs['slice_id'].unique()\n",
    "train_slices = np.random.choice(unique_slice_ids, int(.8*len(unique_slice_ids)), replace=False)\n",
    "train_slices = train_slices[train_slices != 'None']\n",
    "adata.obs['slice_train'] = adata.obs['slice_id'].isin(train_slices)\n",
    "# Annotate bc1 training\n",
    "unique_pert = adata.obs['bc1'].unique()\n",
    "train_pert = np.random.choice(unique_pert, int(.8*len(unique_pert)), replace=False)\n",
    "if 'control' not in train_pert: train_pert = np.concat([train_pert, ['control']])\n",
    "adata.obs['bc1_train'] = adata.obs['bc1'].isin(train_pert)\n",
    "# Annotate intersection\n",
    "adata.obs['slice_bc1_train'] = adata.obs['slice_train'] * adata.obs['bc1_train']\n",
    "\n",
    "# Save spatial and regular\n",
    "expression_adata = ad.AnnData(X=adata.X, obs=adata.obs, var=adata.var)\n",
    "expression_adata.write_h5ad(outfile[0])\n",
    "# adata.write_h5ad(outfile[0])\n",
    "spatial_adata = ad.AnnData(X=adata.obs[['x', 'y']], obs=adata.obs)\n",
    "spatial_adata.write_h5ad(outfile[1])\n",
    "\n",
    "# Plot\n",
    "# # adata, = celltrip.utility.processing.read_adatas('../data/PerturbMM/spatial.h5ad', backed=True)\n",
    "# import seaborn as sns\n",
    "# df_filt = adata.obs.loc[adata.obs['batch'] == '3']\n",
    "# sns.scatterplot(df_filt, x='x', y='y', s=5., hue='cell_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply neighbor clustering\n",
    "# # Params\n",
    "# batch_size = 64\n",
    "# dist_threshold = 100\n",
    "# # Loop\n",
    "# batch = '5'\n",
    "# # Filter data\n",
    "# df = adata.obs.loc[adata.obs['batch']==batch]\n",
    "# # np.random.seed(42)\n",
    "# # samples = np.random.choice(df.index, 30_000, replace=False)\n",
    "# # df = df.loc[samples]\n",
    "# data = df[['x', 'y']].to_numpy()\n",
    "# # Get links\n",
    "# class UnionFind:\n",
    "#     def __init__(self, n):\n",
    "#         self.parent = list(range(n))\n",
    "#     def get_root(self, i):\n",
    "#         if self.parent[i] == i: return i\n",
    "#         else: return self.get_root(self.parent[i])\n",
    "#     def union(self, i, j):\n",
    "#         root_i = self.get_root(i)\n",
    "#         root_j = self.get_root(j)\n",
    "#         self.parent[root_j] = root_i\n",
    "# clusters = UnionFind(data.shape[0])\n",
    "# batches = np.ceil(data.shape[0] / batch_size).astype(int)\n",
    "# for batch in tqdm.tqdm(range(batches), mininterval=1., total=batches):\n",
    "#     # Get links under threshold for batch\n",
    "#     batch_slice = slice(batch*batch_size, (batch+1)*batch_size)\n",
    "#     batch_data = data[batch_slice]\n",
    "#     pdist = sklearn.metrics.pairwise_distances(batch_data, data)\n",
    "#     links = np.argwhere(pdist < dist_threshold)\n",
    "#     links[:, 0] += batch*batch_size\n",
    "#     # Record new clusters\n",
    "#     for row in links:\n",
    "#         if row[0] >= row[1]: continue  # # Skip if equal or duplicate\n",
    "#         clusters.union(*row)  # Record\n",
    "# # Get clusters by node\n",
    "# cluster_ids = [f'{clusters.get_root(i)}' for i in range(data.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102414/1473344914.py:19: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n",
      "  adata_st.X = scale_factor * adata_st.X / adata_st.X.sum(keepdims=True, axis=1)\n",
      "/tmp/ipykernel_102414/1473344914.py:20: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n",
      "  adata_sc.X = scale_factor * adata_sc.X / adata_sc.X.sum(keepdims=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Cortex single-slice data\n",
    "# fnames = ['../data/Cortex/brain_st_cortex.h5ad', '../data/Cortex/brain_sc.h5ad']  # Inconsistent normalization from orig. paper\n",
    "fnames = ['../data/Cortex/brain_st_cortex_raw.h5ad', '../data/Cortex/brain_sc_raw.h5ad']  # Raw data\n",
    "outfiles = [\n",
    "    '../data/Cortex/brain_st_cortex_expression.h5ad',\n",
    "    '../data/Cortex/brain_st_cortex_spatial.h5ad',\n",
    "    '../data/Cortex/brain_sc_expression.h5ad']\n",
    "\n",
    "# Read files\n",
    "adata_st, adata_sc = celltrip.utility.processing.read_adatas(*fnames, backed=False)  # Must be read into memory for writing\n",
    "\n",
    "# Filter to common genes\n",
    "feats_to_keep = np.intersect1d(adata_st.var.index, adata_sc.var.index)\n",
    "adata_st = adata_st[:, feats_to_keep]\n",
    "adata_sc = adata_sc[:, feats_to_keep]\n",
    "\n",
    "# Normalize cell counts\n",
    "# NOTE: Throws warnings since X is technically view\n",
    "scale_factor = 10_000\n",
    "adata_st.X = scale_factor * adata_st.X / adata_st.X.sum(keepdims=True, axis=1)\n",
    "adata_sc.X = scale_factor * adata_sc.X / adata_sc.X.sum(keepdims=True, axis=1)\n",
    "\n",
    "# Save all adatas\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    adata_st.write_h5ad(outfiles[0])\n",
    "    adata_st_spatial = ad.AnnData(X=adata_st.obs[['x', 'y']], obs=adata_st.obs)\n",
    "    adata_st_spatial.write_h5ad(outfiles[1])\n",
    "    adata_sc.write_h5ad(outfiles[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate files to upload\n",
    "fnames = []; folders = []\n",
    "\n",
    "# scGLUE\n",
    "# fnames += ['../data/scglue/Chen-2019-RNA.h5ad', '../data/scglue/Chen-2019-ATAC.h5ad']\n",
    "# folders += len(fnames)*['scGLUE']\n",
    "# partition_cols = None\n",
    "\n",
    "# MERFISH\n",
    "# fnames += ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH']\n",
    "# partition_cols = None\n",
    "\n",
    "# Temporal Brain ('Donor ID')\n",
    "# fnames += ['../data/temporalBrain/expression.h5ad', '../data/temporalBrain/peaks.h5ad']\n",
    "# folders += len(fnames)*['TemporalBrain']\n",
    "# partition_cols = None\n",
    "\n",
    "# TAHOE-100M ('sample')\n",
    "# fnames = [f'../data/tahoe/plate{i}_filt_Vevo_Tahoe100M_WServicesFrom_ParseGigalab.h5ad' for i in range(1, 15)]\n",
    "# folders += len(fnames)*['Tahoe']\n",
    "# partition_cols = None\n",
    "\n",
    "# Flysta3D ('slice_ID')\n",
    "# periods = ['E14-16h_a', 'E16-18h_a', 'L1_a', 'L2_a', 'L3_b']\n",
    "# fnames += (\n",
    "#     # [f'../data/Flysta3D/{p}_count_normal_stereoseq.h5ad' for p in periods]\n",
    "#     [f'../data/Flysta3D/{p}_expression.h5ad' for p in periods]\n",
    "#     + [f'../data/Flysta3D/{p}_spatial.h5ad' for p in periods])\n",
    "# folders += len(fnames)*['Flysta3D']\n",
    "\n",
    "# scMultiSim\n",
    "# fnames += ['../data/scMultiSim/expression.h5ad', '../data/scMultiSim/peaks.h5ad']\n",
    "# folders += len(fnames)*['scMultiSim']\n",
    "\n",
    "# MERFISH CMAP Benchmark\n",
    "# fnames += ['../data/MERFISH_Bench/expression.h5ad', '../data/MERFISH_Bench/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH_Bench']\n",
    "\n",
    "# Virtual Cell Challenge\n",
    "# fnames += ['../data/VirtualCell/vcc_flt_data.h5ad']\n",
    "# folders += len(fnames)*['VirtualCell']\n",
    "\n",
    "# dyngen\n",
    "# fnames += [\n",
    "#     '../data/dyngen/counts_protein.h5ad', '../data/dyngen/counts_spliced.h5ad',\n",
    "#     '../data/dyngen/counts_unspliced.h5ad', '../data/dyngen/logcounts.h5ad',\n",
    "#     '../data/dyngen/rna_velocity.h5ad']\n",
    "# folders += len(fnames)*['dyngen']\n",
    "\n",
    "# CancerVel ('days', 'sgAssignNew)\n",
    "# fnames += ['../data/CancerVel/expression.h5ad']\n",
    "# folders += len(fnames)*['CancerVel']\n",
    "\n",
    "# MERFISH30k\n",
    "# fnames += ['../data/MERFISH30k/expression.h5ad', '../data/MERFISH30k/spatial.h5ad']\n",
    "# folders += len(fnames)*['MERFISH30k']\n",
    "\n",
    "# PerturbMM\n",
    "# fnames += ['../data/PerturbMM/expression.h5ad', '../data/PerturbMM/spatial.h5ad']\n",
    "# folders += len(fnames)*['PerturbMM']\n",
    "\n",
    "# Cortex\n",
    "# fnames += [\n",
    "#     '../data/Cortex/brain_st_cortex_expression.h5ad', '../data/Cortex/brain_st_cortex_spatial.h5ad',\n",
    "#     '../data/Cortex/brain_sc_expression.h5ad']\n",
    "# folders += len(fnames)*['Cortex']\n",
    "\n",
    "# Upload\n",
    "for fname, folder in zip(fnames, folders): s3.put(fname, os.path.join(os.path.join('s3://nkalafut-celltrip', folder), os.path.basename(fname)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturb or Knock Features in Processed Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gene knockdown in processed data\n",
    "modality_to_test = 0\n",
    "features_to_test = [200, 150]\n",
    "adatas, _, adata_vars = dataloader.get_transformables()\n",
    "iso_modality = dataloader.preprocessing.transform(\n",
    "    adatas[modality_to_test][adata_obs[modality_to_test].index].X,\n",
    "    # force_filter=True,\n",
    "    subset_features=features_to_test,\n",
    "    subset_modality=modality_to_test)[0]\n",
    "knocked_modality = modalities[modality_to_test] - iso_modality\n",
    "\n",
    "# Verify the knockdown works\n",
    "orig_modality, = dataloader.preprocessing.inverse_transform(modalities[modality_to_test], subset_modality=modality_to_test)\n",
    "inv_modality, = dataloader.preprocessing.inverse_transform(knocked_modality, subset_modality=modality_to_test)\n",
    "change = np.abs(orig_modality - inv_modality).sum(axis=0) / dataloader.preprocessing.standardize_std[modality_to_test]\n",
    "most_changed_idx = dataloader.preprocessing.filter_mask[modality_to_test][np.argsort(change).flatten()[-len(features_to_test):]]\n",
    "print(f'Targets: {np.array(features_to_test)}, Most Changed: {most_changed_idx}, should be the same elements')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T23:09:01.153843Z",
     "iopub.status.busy": "2025-03-03T23:09:01.153691Z",
     "iopub.status.idle": "2025-03-03T23:09:01.194871Z",
     "shell.execute_reply": "2025-03-03T23:09:01.194513Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "for _ in range(10): dataloader.sample()\n",
    "print(f'Sampling takes ~{(time.perf_counter()-start)/10:.2f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
