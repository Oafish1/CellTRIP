{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:05:39.243074Z",
     "iopub.status.busy": "2024-12-11T22:05:39.242732Z",
     "iopub.status.idle": "2024-12-11T22:05:41.357756Z",
     "shell.execute_reply": "2024-12-11T22:05:41.357292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=analysis.ipynb\n",
      "env: WANDB_SILENT=true\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env WANDB_NOTEBOOK_NAME analysis.ipynb\n",
    "%env WANDB_SILENT true\n",
    "%matplotlib agg\n",
    "# ipympl\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.collections as mpl_col\n",
    "import matplotlib.gridspec as mpl_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import mpl_toolkits.mplot3d as mp3d\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import data\n",
    "import inept\n",
    "\n",
    "# Get args\n",
    "# import sys\n",
    "# run_id_idx = int(sys.argv[1])\n",
    "# analysis_key_idx = int(sys.argv[2])\n",
    "\n",
    "# Set params\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "BASE_FOLDER = os.path.abspath('')\n",
    "DATA_FOLDER = os.path.join(BASE_FOLDER, '../data')\n",
    "PLOT_FOLDER = os.path.join(BASE_FOLDER, '../plots')\n",
    "\n",
    "# Style\n",
    "sns.set_context('paper', font_scale=1.25)\n",
    "sns.set_style('white')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# MPL params\n",
    "mpl.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "# Disable gradients\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HIGH PRIORITY\n",
    "  - Extent `get_present_func` to class with full state-altering capabilities\n",
    "  - Add more accuracy metrics\n",
    "  - Perturbation analysis with inverse transform\n",
    "  - Add 2D functionality\n",
    "  - Add optional UMAP\n",
    "\n",
    "- LOW PRIORITY\n",
    "  - Switch to `mayavi` instead of mpl to have true 3d and proper layering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:05:41.360205Z",
     "iopub.status.busy": "2024-12-11T22:05:41.359978Z",
     "iopub.status.idle": "2024-12-11T22:05:43.035550Z",
     "shell.execute_reply": "2024-12-11T22:05:43.035032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy found at stage 14\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "run_id = (\n",
    "    'brf6n6sn',  # TemporalBrain Random 100 Max\n",
    "    'rypltvk5',  # MMD-MA Random 100 Max\n",
    "    '32jqyk54',  # MERFISH Random 100 Max\n",
    "    'c8zsunc9',  # ISS Random 100 Max\n",
    "    'maofk1f2',  # ExSeq NR\n",
    "    'f6ajo2am',  # smFish NR\n",
    "    'vb1x7bae',  # MERFISH NR\n",
    "    '473vyon2',  # ISS NR\n",
    ")[1]\n",
    "stage_override = None  # Manually override policy stage selection\n",
    "num_nodes_override = None\n",
    "max_batch_override = 500\n",
    "max_nodes_override = None\n",
    "seed_override = None\n",
    "\n",
    "# Load run\n",
    "api = wandb.Api()\n",
    "run = api.run(f'oafish/INEPT/{run_id}')\n",
    "config = defaultdict(lambda: {})\n",
    "for k, v in run.config.items():\n",
    "    dict_name, key = k.split('/')\n",
    "    config[dict_name][key] = v\n",
    "config = dict(config)\n",
    "\n",
    "# Reproducibility\n",
    "seed = seed_override if seed_override is not None else config['note']['seed']\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load data\n",
    "modalities, types, features = data.load_data(config['data']['dataset'], DATA_FOLDER)\n",
    "# config['data'] = inept.utilities.overwrite_dict(config['data'], {'standardize': True})  # Old model compatibility\n",
    "if num_nodes_override is not None: config['data'] = inept.utilities.overwrite_dict(config['data'], {'num_nodes': num_nodes_override})\n",
    "if max_batch_override is not None: config['train'] = inept.utilities.overwrite_dict(config['train'], {'max_batch': max_batch_override})\n",
    "ppc = inept.utilities.Preprocessing(**config['data'], device=DEVICE)\n",
    "modalities, features = ppc.fit_transform(modalities, features)\n",
    "modalities, types = ppc.subsample(modalities, types)\n",
    "modalities = ppc.cast(modalities)\n",
    "\n",
    "# Get latest policy\n",
    "latest_mdl = [-1, None]  # Pkl\n",
    "latest_wgt = [-1, None]  # State dict\n",
    "for file in run.files():\n",
    "    # Find mdl files\n",
    "    matches = re.findall(f'^(?:models|trained_models)/policy_(\\w+).(mdl|wgt)$', file.name)\n",
    "    if len(matches) > 0: stage = int(matches[0][0]); ftype = matches[0][1]\n",
    "    else: continue\n",
    "\n",
    "    # Record\n",
    "    latest_known_stage = latest_mdl[0] if ftype == 'mdl' else latest_wgt[0]\n",
    "    if (stage_override is None and stage > latest_known_stage) or (stage_override is not None and stage == stage_override):\n",
    "        if ftype == 'mdl': latest_mdl = [stage, file]\n",
    "        elif ftype == 'wgt': latest_wgt = [stage, file]\n",
    "print(f'Policy found at stage {latest_mdl[0]}')\n",
    "\n",
    "# Load env\n",
    "env = inept.environments.trajectory(*modalities, **config['env'], **config['stages']['env'][0], device=DEVICE)\n",
    "for weight_stage in config['stages']['env'][1:latest_mdl[0]+1]:\n",
    "    env.set_rewards(weight_stage)\n",
    "\n",
    "# Load file\n",
    "load_type = 'wgt'\n",
    "if load_type == 'mdl':\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        latest_mdl[1].download(tmpdir, replace=True)\n",
    "        policy = torch.load(os.path.join(tmpdir, latest_mdl[1].name))\n",
    "elif load_type == 'wgt':\n",
    "    # Mainly used in the case of old argument names, also generally more secure\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        latest_wgt[1].download(tmpdir, replace=True)\n",
    "        # config['policy'] = inept.utilities.overwrite_dict(config['policy'], {'positional_dim': 6, 'modal_dims': [76]})  # Old model compatibility\n",
    "        if max_nodes_override is not None: config['policy'] = inept.utilities.overwrite_dict(config['policy'], {'max_nodes': max_nodes_override})\n",
    "        policy = inept.models.PPO(**config['policy'])\n",
    "        # incompatible_keys = policy.load_state_dict(torch.load(os.path.join(tmpdir, latest_wgt[1].name), weights_only=True))\n",
    "policy = policy.to(DEVICE).eval()\n",
    "policy.actor.set_action_std(1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:05:43.037838Z",
     "iopub.status.busy": "2024-12-11T22:05:43.037560Z",
     "iopub.status.idle": "2024-12-11T22:05:43.058961Z",
     "shell.execute_reply": "2024-12-11T22:05:43.058520Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Standardize implementation\n",
    "labels = types[0][:, 0]\n",
    "times = types[0][:, -1]  # Temporary time annotation, will change per-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:05:43.060936Z",
     "iopub.status.busy": "2024-12-11T22:05:43.060791Z",
     "iopub.status.idle": "2024-12-11T22:05:43.081784Z",
     "shell.execute_reply": "2024-12-11T22:05:43.081376Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Choose key\n",
    "# TODO: Calculate all, plot one (?)\n",
    "analysis_key_idx = 0\n",
    "discovery_key = 0  # Auto\n",
    "temporal_key = 0  # Auto\n",
    "perturbation_features = [np.random.choice(len(fs), 10, replace=False) for fs in features]\n",
    "\n",
    "analysis_key, state_manager_class = [\n",
    "    ('integration', inept.utilities.IntegrationStateManager),\n",
    "    ('discovery', inept.utilities.DiscoveryStateManager),\n",
    "    ('temporal', inept.utilities.TemporalStateManager),\n",
    "    ('perturbation', inept.utilities.PerturbationStateManager),\n",
    "][analysis_key_idx]\n",
    "\n",
    "# Discovery list\n",
    "discovery = []\n",
    "# Reverse alphabetical (ExSeq, MERFISH, smFISH, ISS, MouseVisual)\n",
    "type_order = np.unique(labels)[::-1]\n",
    "discovery_general = {\n",
    "    'labels': list(type_order),\n",
    "    'delay': 50*np.arange(len(type_order)),\n",
    "    'rates': [1] + [.015]*(len(type_order)-1),\n",
    "    'origins': [None] + list(type_order[:-1])}\n",
    "discovery += [discovery_general]\n",
    "# Choose Discovery\n",
    "discovery = discovery[discovery_key]\n",
    "\n",
    "# Stage order list\n",
    "temporal = []\n",
    "# Reverse alphabetical (ExSeq, MERFISH, smFISH, ISS, MouseVisual)\n",
    "temporal_general = {'stages': [[l] for l in np.unique(labels)[::-1]]}\n",
    "temporal += [temporal_general]\n",
    "# Choose stage order\n",
    "temporal = temporal[temporal_key]\n",
    "\n",
    "# Perturbation feature names\n",
    "perturbation_feature_names = [fnames[pf] for pfs, fnames in zip(perturbation_features, features) for pf in pfs]\n",
    "\n",
    "# Initialize memories\n",
    "memories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:05:43.206564Z",
     "iopub.status.busy": "2024-12-11T22:05:43.206409Z",
     "iopub.status.idle": "2024-12-11T22:06:56.467532Z",
     "shell.execute_reply": "2024-12-11T22:06:56.467046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose state manager\n",
    "state_manager = state_manager_class(\n",
    "    device=DEVICE,\n",
    "    discovery=discovery,\n",
    "    temporal=temporal,\n",
    "    perturbation_features=perturbation_features,\n",
    "    num_nodes=modalities[0].shape[0],\n",
    ")\n",
    "get_current_stage = lambda: state_manager.current_stage if state_manager_class in (inept.utilities.TemporalStateManager, inept.utilities.PerturbationStateManager) else -1\n",
    "\n",
    "# Initialize\n",
    "env.reset(); memories[analysis_key] = defaultdict(lambda: [])\n",
    "\n",
    "# Modify\n",
    "state_vars, end = state_manager(\n",
    "    # present=present,\n",
    "    state=env.get_state(),\n",
    "    modalities=ppc.cast(ppc.inverse_transform(ppc.inverse_cast(env.get_modalities()))),\n",
    "    labels=labels,\n",
    "    times=times,\n",
    ")\n",
    "present = state_vars['present']\n",
    "env.set_state(state_vars['state'])\n",
    "raw_modalities = state_vars['modalities']\n",
    "env.set_modalities(ppc.cast(ppc.transform(ppc.inverse_cast(raw_modalities))))\n",
    "\n",
    "# Continue initializing\n",
    "memories[analysis_key]['present'].append(present)\n",
    "memories[analysis_key]['states'].append(env.get_state())\n",
    "memories[analysis_key]['stages'].append(get_current_stage())\n",
    "memories[analysis_key]['rewards'].append(torch.zeros(modalities[0].shape[0], device=DEVICE))\n",
    "\n",
    "# Simulate\n",
    "timestep = 1\n",
    "while True:\n",
    "    # CLI\n",
    "    if timestep % 20 == 0:\n",
    "        cli_out = f'Timestep: {timestep}'\n",
    "        cli_out += f' - Stage: {get_current_stage()}'\n",
    "        print(cli_out, end='\\r')\n",
    "\n",
    "    # Step\n",
    "    state = env.get_state(include_modalities=True)\n",
    "    actions = torch.zeros((modalities[0].shape[0], env.dim), device=DEVICE)\n",
    "    actions[present] = policy.act_macro(\n",
    "        state[present],\n",
    "        keys=torch.arange(modalities[0].shape[0], device=DEVICE)[present],\n",
    "        max_batch=config['train']['max_batch'],\n",
    "    )\n",
    "    rewards = torch.zeros(modalities[0].shape[0])\n",
    "    # TODO: Currently, rewards factor in non-present nodes\n",
    "    rewards, _, _ = env.step(actions, return_itemized_rewards=True)\n",
    "    new_state = env.get_state()\n",
    "    new_state[~present] = state[~present, :2*env.dim]  # Don't move un-spawned nodes\n",
    "    env.set_state(new_state)\n",
    "\n",
    "    # Modify\n",
    "    state_vars, end = state_manager(\n",
    "        present=present,\n",
    "        state=env.get_state(),\n",
    "        modalities=raw_modalities,\n",
    "        labels=labels,\n",
    "        times=times,\n",
    "    )\n",
    "    present = state_vars['present']\n",
    "    env.set_state(state_vars['state'])\n",
    "    # Only modify if changes\n",
    "    if torch.tensor([(rm != svm).any() for rm, svm in zip(raw_modalities, state_vars['modalities'])]).any():\n",
    "        raw_modalities = state_vars['modalities']\n",
    "        env.set_modalities(ppc.cast(ppc.transform(ppc.inverse_cast(raw_modalities))))\n",
    "\n",
    "    # Record\n",
    "    memories[analysis_key]['present'].append(present)\n",
    "    memories[analysis_key]['states'].append(env.get_state())\n",
    "    memories[analysis_key]['stages'].append(get_current_stage())\n",
    "    memories[analysis_key]['rewards'].append(rewards)\n",
    "\n",
    "    # End\n",
    "    if end: break\n",
    "    timestep += 1\n",
    "\n",
    "# Stack\n",
    "memories[analysis_key]['present'] = torch.stack(memories[analysis_key]['present'])\n",
    "memories[analysis_key]['states'] = torch.stack(memories[analysis_key]['states'])\n",
    "memories[analysis_key]['stages'] = torch.tensor(memories[analysis_key]['stages'])\n",
    "memories[analysis_key]['rewards'] = torch.stack(memories[analysis_key]['rewards'])\n",
    "memories[analysis_key] = dict(memories[analysis_key])\n",
    "\n",
    "# CLI\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per Stage:\n",
      "0: 1000\n",
      "1: 4\n",
      "2: 52\n",
      "3: 2\n",
      "4: 72\n",
      "5: 63\n",
      "6: 82\n",
      "7: 103\n",
      "8: 55\n",
      "9: 3\n",
      "10: 85\n",
      "11: 173\n",
      "12: 4\n",
      "13: 129\n",
      "14: 65\n",
      "15: 2\n",
      "16: 300\n",
      "17: 138\n",
      "18: 198\n",
      "19: 92\n",
      "20: 180\n"
     ]
    }
   ],
   "source": [
    "stages, counts = np.unique(memories[analysis_key]['stages'], return_counts=True)\n",
    "print('Counts per Stage:')\n",
    "for s, c in zip(stages, counts):\n",
    "    print(f'{s}: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[analysis_key]['rewards'].cpu().mean()  # TODO: Why not the same as WANDB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T22:06:56.469638Z",
     "iopub.status.busy": "2024-12-11T22:06:56.469496Z",
     "iopub.status.idle": "2024-12-11T22:41:20.427142Z",
     "shell.execute_reply": "2024-12-11T22:41:20.426352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 / 28\n",
      "\n",
      "0 / 28\r"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "skip = 20\n",
    "present = memories[analysis_key]['present'].cpu()[::skip]\n",
    "states = memories[analysis_key]['states'].cpu()[::skip]\n",
    "stages = memories[analysis_key]['stages'].cpu()[::skip]\n",
    "rewards = memories[analysis_key]['rewards'].cpu()[::skip]\n",
    "env.set_modalities(modalities)\n",
    "env.reset()\n",
    "env.get_distance_match()\n",
    "modal_dist = env.dist\n",
    "\n",
    "# Parameters\n",
    "interval = 1e3*env.delta/3  # Time between frames (3x speedup)\n",
    "min_max_vel = 1e-2 if analysis_key in ('integration', 'discovery') else -1  # Stop at first frame all vels are below target. 0 for full play\n",
    "frame_override = None  # Manually enter number of frames to draw\n",
    "num_lines = 25  # Number of attraction and repulsion lines\n",
    "rotations_per_second = .1  # Camera azimuthal rotations per second\n",
    "\n",
    "# Create plot based on key\n",
    "# NOTE: Standard 1-padding all around and between figures\n",
    "# NOTE: Left, bottom, width, height\n",
    "if analysis_key in ('integration', 'discovery'):\n",
    "    figsize = (15, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        inept.utilities.View3D,\n",
    "        inept.utilities.ViewTemporalScatter,\n",
    "        inept.utilities.ViewSilhouette,\n",
    "    ]\n",
    "\n",
    "elif analysis_key == 'temporal':\n",
    "    figsize = (15, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        inept.utilities.View3D,\n",
    "        inept.utilities.ViewTemporalScatter,\n",
    "        inept.utilities.ViewTemporalDiscrepancy,\n",
    "    ]\n",
    "\n",
    "elif analysis_key in ('perturbation',):\n",
    "    figsize = (20, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 8 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 3.5 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([14.5 /figsize[0], 1 /figsize[1], 3.5 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        inept.utilities.View3D,\n",
    "        inept.utilities.ViewPerturbationEffect,\n",
    "        inept.utilities.ViewTemporalScatter,\n",
    "        inept.utilities.ViewSilhouette,\n",
    "    ]\n",
    "\n",
    "# Initialize views\n",
    "arguments = {\n",
    "    # Data\n",
    "    'present': present,\n",
    "    'states': states,\n",
    "    'stages': stages,\n",
    "    'rewards': rewards,\n",
    "    'modalities': modalities,\n",
    "    'labels': labels,\n",
    "    # Data params\n",
    "    'dim': env.dim,\n",
    "    'modal_targets': env.reward_distance_target,\n",
    "    'temporal_stages': temporal['stages'] if analysis_key == 'temporal' else None,\n",
    "    'perturbation_features': perturbation_features,\n",
    "    'perturbation_feature_names': perturbation_feature_names,\n",
    "    # Arguments\n",
    "    'interval': interval,\n",
    "    'skip': skip,\n",
    "    'seed': 42,\n",
    "    # Styling\n",
    "    'ms': 5,  # 3\n",
    "    'lw': 1,\n",
    "}\n",
    "views = [view(**arguments, ax=ax) for view, ax in zip(views, axs)]\n",
    "\n",
    "# Update function\n",
    "def update(frame):\n",
    "    # Update views\n",
    "    for view in views:\n",
    "        # print(view)\n",
    "        view.update(frame)\n",
    "\n",
    "    # CLI\n",
    "    print(f'{frame} / {frames-1}', end='\\r')\n",
    "    if frame == frames-1: print()\n",
    "\n",
    "# Compile animation\n",
    "frames = states[..., env.dim:env.dim+3].square().sum(dim=-1).sqrt().max(dim=-1).values < min_max_vel\n",
    "frames = np.array([(frames[i] or frames[i+1]) if i != len(frames)-1 else frames[i] for i in range(len(frames))])  # Disregard interrupted sections of low movement\n",
    "frames = np.argwhere(frames)\n",
    "frames = frames[0, 0].item()+1 if len(frames) > 0 else states.shape[0]\n",
    "frames = frames if frame_override is None else frame_override\n",
    "\n",
    "# Test individual frames\n",
    "# for frame in range(frames):\n",
    "#     update(frame)\n",
    "#     # print()\n",
    "#     # print('saving')\n",
    "#     fig.savefig(os.path.join('temp/plots', f'frame_{frame}.png'), dpi=300)\n",
    "#     break\n",
    "\n",
    "# Initialize animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig,\n",
    "    func=update,\n",
    "    frames=frames,\n",
    "    interval=interval,\n",
    ")\n",
    "\n",
    "# Display animation as it renders\n",
    "# plt.show()\n",
    "\n",
    "# Display complete animation\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# Save animation\n",
    "file_type = 'mp4'\n",
    "if file_type == 'mp4': writer = animation.FFMpegWriter(fps=int(1e3/interval), extra_args=['-vcodec', 'libx264'], bitrate=8e3)  # Faster\n",
    "elif file_type == 'gif': writer = animation.FFMpegWriter(fps=int(1e3/interval))  # Slower\n",
    "ani.save(os.path.join(PLOT_FOLDER, f'{config[\"data\"][\"dataset\"]}_{analysis_key}.{file_type}'), writer=writer, dpi=300)\n",
    "\n",
    "# CLI\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
