{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:27:18.898240Z",
     "iopub.status.busy": "2025-01-15T18:27:18.897819Z",
     "iopub.status.idle": "2025-01-15T18:27:21.049625Z",
     "shell.execute_reply": "2025-01-15T18:27:21.049119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=analysis.ipynb\n",
      "env: WANDB_SILENT=true\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env WANDB_NOTEBOOK_NAME analysis.ipynb\n",
    "%env WANDB_SILENT true\n",
    "%matplotlib agg\n",
    "# ipympl\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.collections as mpl_col\n",
    "import matplotlib.gridspec as mpl_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import mpl_toolkits.mplot3d as mp3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "# Enable text output in notebooks\n",
    "import tqdm.auto\n",
    "import tqdm.notebook\n",
    "tqdm.notebook.tqdm = tqdm.auto.tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data\n",
    "import celltrip\n",
    "\n",
    "# Set params\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "BASE_FOLDER = os.path.abspath('')\n",
    "DATA_FOLDER = os.path.join(BASE_FOLDER, '../data')\n",
    "PLOT_FOLDER = os.path.join(BASE_FOLDER, '../plots')\n",
    "\n",
    "# Style\n",
    "sns.set_context('paper', font_scale=1.25)\n",
    "sns.set_style('white')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# MPL params\n",
    "mpl.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "# Disable gradients\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO\n",
    "  - Figure out why MMD-MA inter-cell distances are lower than usual\n",
    "  - Add imputation and perturbation to comparison analysis\n",
    "  - Add named memory saving\n",
    "  - Add PCA/UMAP\n",
    "  - Add arguments like wandb username/project, etc.\n",
    "  - Find out how wandb can be used locally\n",
    "  - Add bash script to loop through a script on files of a particular extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Create a video of the specified model')\n",
    "group = parser.add_argument_group('Main Parameters')\n",
    "group.add_argument(\n",
    "    'run_id',\n",
    "    type=str,\n",
    "    help='Run ID from WandB to use for processing')\n",
    "group.add_argument(\n",
    "    'analysis_key',\n",
    "    choices=('convergence', 'discovery', 'temporal', 'perturbation'),\n",
    "    type=str,\n",
    "    help='Type of analysis to perform')\n",
    "group.add_argument(\n",
    "    '-S', '--seed',\n",
    "    type=int,\n",
    "    help='Override simulation seed')\n",
    "group.add_argument(\n",
    "    '--gpu',\n",
    "    default='0',\n",
    "    type=str,\n",
    "    help='GPU(s) to use')\n",
    "\n",
    "# Model parameters\n",
    "group = parser.add_argument_group('Simulation Parameters')\n",
    "group.add_argument(\n",
    "    '-b', '--batch',\n",
    "    metavar='MAX_BATCH',\n",
    "    dest='max_batch',\n",
    "    type=int,\n",
    "    help='Override number of nodes which can calculate actions simultaneously')\n",
    "group.add_argument(\n",
    "    '--num',\n",
    "    metavar='NUM_NODES',\n",
    "    dest='num_nodes',\n",
    "    type=int,\n",
    "    help='Override number of nodes to take from data')\n",
    "group.add_argument(\n",
    "    '--nodes',\n",
    "    metavar='NUM_NEIGHBORS',\n",
    "    dest='max_nodes',\n",
    "    type=int,\n",
    "    help='Override neighbors considered by each node')\n",
    "group.add_argument(\n",
    "    '--stage',\n",
    "    type=int,\n",
    "    help='Override model stage to use. 0 is random initialization')\n",
    "\n",
    "# Simulation specific arguments\n",
    "group = parser.add_argument_group('Analysis Parameters')\n",
    "group.add_argument(\n",
    "    '--discovery_key',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='Type of discovery analysis (0: Auto)')\n",
    "group.add_argument(\n",
    "    '--temporal_key',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='Type of temporal analysis (0: Auto, 1: TemporalBrain)')\n",
    "\n",
    "# Video parameters\n",
    "group = parser.add_argument_group('Video Parameters')\n",
    "group.add_argument(\n",
    "    '-g', '--gif',\n",
    "    action='store_true',\n",
    "    help='Output as a GIF rather than MP4')\n",
    "group.add_argument(\n",
    "    '-s', '--skip',\n",
    "    type=int,\n",
    "    default=5,\n",
    "    help='Number of steps to advance each frame')\n",
    "group.add_argument(\n",
    "    '--reduction',\n",
    "    choices=('umap', 'pca', 'none'),\n",
    "    default='pca',\n",
    "    type=str,\n",
    "    dest='reduction_type',\n",
    "    help='Reduction type to use for high-dimensional projections in 3D visualization')\n",
    "group.add_argument(\n",
    "    '--force_reduction',\n",
    "    action='store_true',\n",
    "    help='Force reduction, even if unnecessary')\n",
    "group.add_argument(\n",
    "    '--reduction_batch',\n",
    "    type=int,\n",
    "    default=100_000,\n",
    "    help='Max number of states to reduce in one computation')\n",
    "\n",
    "# Legacy compatibility\n",
    "group = parser.add_argument_group('Legacy Compatiiblity Parameters')\n",
    "group.add_argument(\n",
    "    '--total_statistics',\n",
    "    action='store_true',\n",
    "    help='Compatibility argument to compute mean and variance over all samples')\n",
    "\n",
    "# List of common runs\n",
    "# 'brf6n6sn': TemporalBrain Random 100 Max\n",
    "# 'rypltvk5': MMD-MA Random 100 Max (requires `total_statistics`)\n",
    "# '32jqyk54': MERFISH Random 100 Max\n",
    "# 'c8zsunc9': ISS Random 100 Max\n",
    "# 'maofk1f2': ExSeq NR\n",
    "# 'f6ajo2am': smFish NR\n",
    "# 'vb1x7bae': MERFISH NR\n",
    "# '473vyon2': ISS NR\n",
    "\n",
    "# Defaults for notebook\n",
    "args = parser.parse_args('-s 20 rypltvk5 temporal'.split(' '))\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Set env vars\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=args.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data, Model, and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:27:21.052179Z",
     "iopub.status.busy": "2025-01-15T18:27:21.051926Z",
     "iopub.status.idle": "2025-01-15T18:27:24.431802Z",
     "shell.execute_reply": "2025-01-15T18:27:24.431274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading run rypltvk5\n",
      "\tFinding model\n",
      "\t\tMDL policy found at stage 14\n",
      "\t\tWGT policy found at stage 14\n",
      "\tLoading dataset MMD-MA\n",
      "\t\tLoading WGT model\n"
     ]
    }
   ],
   "source": [
    "# Load run\n",
    "print(f'Loading run {args.run_id}')\n",
    "api = wandb.Api()\n",
    "run = api.run(f'oafish/cellTRIP/{args.run_id}')\n",
    "config = defaultdict(lambda: {})\n",
    "for k, v in run.config.items():\n",
    "    dict_name, key = k.split('/')\n",
    "    config[dict_name][key] = v\n",
    "config = dict(config)\n",
    "\n",
    "# Reproducibility\n",
    "seed = args.seed if args.seed is not None else config['note']['seed']\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Get latest policy\n",
    "print('\\tFinding model')\n",
    "latest_mdl = [0, None]  # Pkl\n",
    "latest_wgt = [0, None]  # State dict\n",
    "# Compatibility with models of the previous naming convention\n",
    "# for file in run.files():\n",
    "#     matches = re.findall(f'^(?:models|trained_models)/policy_(\\w+).(mdl|wgt)$', file.name)\n",
    "#     if len(matches) > 0: stage = int(matches[0][0]); ftype = matches[0][1]\n",
    "#     else: continue\n",
    "#     if stage == 0: add_one = True; break\n",
    "# else: add_one = False\n",
    "# Iterate through model files\n",
    "for file in run.files():\n",
    "    matches = re.findall(f'^(?:models|trained_models)/policy_(\\w+).(mdl|wgt)$', file.name)\n",
    "    if len(matches) > 0: stage = int(matches[0][0]); ftype = matches[0][1]\n",
    "    else: continue\n",
    "    # if add_one: stage += 1\n",
    "\n",
    "    # Record\n",
    "    latest_known_stage = latest_mdl[0] if ftype == 'mdl' else latest_wgt[0]\n",
    "    if (args.stage is None and stage > latest_known_stage) or (args.stage is not None and stage == args.stage):\n",
    "        if ftype == 'mdl': latest_mdl = [stage, file]\n",
    "        elif ftype == 'wgt': latest_wgt = [stage, file]\n",
    "print(f'\\t\\tMDL policy found at stage {latest_mdl[0]}')\n",
    "print(f'\\t\\tWGT policy found at stage {latest_wgt[0]}')\n",
    "\n",
    "# Load data\n",
    "print(f'\\tLoading dataset {config[\"data\"][\"dataset\"]}')\n",
    "modalities, types, features = data.load_data(config['data']['dataset'], DATA_FOLDER)\n",
    "# config['data'] = celltrip.utilities.overwrite_dict(config['data'], {'standardize': True})  # Old model compatibility\n",
    "# config['data'] = celltrip.utilities.overwrite_dict(config['data'], {'top_variant': config['data']['pca_dim'], 'pca_dim': None})  # Swap PCA with top variant (testing)\n",
    "if args.num_nodes is not None: config['data'] = celltrip.utilities.overwrite_dict(config['data'], {'num_nodes': args.num_nodes})\n",
    "if args.max_batch is not None: config['train'] = celltrip.utilities.overwrite_dict(config['train'], {'max_batch': args.max_batch})\n",
    "ppc = celltrip.utilities.Preprocessing(**config['data'], device=DEVICE)\n",
    "modalities, features = ppc.fit_transform(modalities, features, total_statistics=args.total_statistics)\n",
    "modalities, types = ppc.subsample(modalities, types)\n",
    "modalities = ppc.cast(modalities)\n",
    "labels = types[0][:, 0]\n",
    "times = types[0][:, -1]\n",
    "\n",
    "# Load env\n",
    "env = celltrip.environments.trajectory(*modalities, **config['env'], **config['stages']['env'][0], device=DEVICE)\n",
    "for weight_stage in config['stages']['env'][1:latest_mdl[0]+1]:\n",
    "    env.set_rewards(weight_stage)\n",
    "\n",
    "# Load model file\n",
    "load_type = 'WGT'\n",
    "if load_type == 'MDL' and latest_mdl[0] != 0:\n",
    "    print('\\t\\tLoading MDL model')\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        latest_mdl[1].download(tmpdir, replace=True)\n",
    "        policy = torch.load(os.path.join(tmpdir, latest_mdl[1].name))\n",
    "elif load_type == 'WGT' and latest_wgt[0] != 0:\n",
    "    print('\\t\\tLoading WGT model')\n",
    "    # Mainly used in the case of old argument names, also generally more secure\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        latest_wgt[1].download(tmpdir, replace=True)\n",
    "        # config['policy'] = celltrip.utilities.overwrite_dict(config['policy'], {'positional_dim': 6, 'modal_dims': [76]})  # Old model compatibility\n",
    "        if args.max_nodes is not None: config['policy'] = celltrip.utilities.overwrite_dict(config['policy'], {'max_nodes': args.max_nodes})\n",
    "        policy = celltrip.models.PPO(**config['policy'])\n",
    "        incompatible_keys = policy.load_state_dict(torch.load(os.path.join(tmpdir, latest_wgt[1].name), weights_only=True))\n",
    "else:\n",
    "    print('\\t\\tUsing random model')\n",
    "    # Use random model\n",
    "    policy = celltrip.models.PPO(**config['policy'])\n",
    "policy = policy.to(DEVICE).eval()\n",
    "policy.actor.set_action_std(1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:27:25.129441Z",
     "iopub.status.busy": "2025-01-15T18:27:25.129271Z",
     "iopub.status.idle": "2025-01-15T18:27:25.155699Z",
     "shell.execute_reply": "2025-01-15T18:27:25.155265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose key\n",
    "# TODO: Calculate all, plot one\n",
    "optimize_memory = True  # Saves memory by shrinking env based on present, also fixes reward calculation for non-full present mask\n",
    "perturbation_features = [np.random.choice(len(fs), 10, replace=False) for i, fs in enumerate(features) if (i not in env.reward_distance_target) or (len(env.reward_distance_target) == len(modalities))]\n",
    "\n",
    "state_manager_class = {\n",
    "    'convergence': celltrip.utilities.ConvergenceStateManager,\n",
    "    'discovery': celltrip.utilities.DiscoveryStateManager,\n",
    "    'temporal': celltrip.utilities.TemporalStateManager,\n",
    "    'perturbation': celltrip.utilities.PerturbationStateManager,\n",
    "}[args.analysis_key]\n",
    "\n",
    "# Discovery list\n",
    "discovery = []\n",
    "# Reverse alphabetical (ExSeq, MERFISH, smFISH, ISS, MouseVisual)\n",
    "type_order = np.unique(labels)[::-1]\n",
    "discovery_general = {\n",
    "    'labels': list(type_order),\n",
    "    'delay': 50*np.arange(len(type_order)),\n",
    "    'rates': [1] + [.015]*(len(type_order)-1),\n",
    "    'origins': [None] + list(type_order[:-1])}\n",
    "discovery += [discovery_general]\n",
    "# Choose Discovery\n",
    "discovery = discovery[args.discovery_key]\n",
    "\n",
    "# Stage order list\n",
    "temporal = []\n",
    "# Reverse alphabetical (ExSeq, MERFISH, smFISH, ISS, MouseVisual)\n",
    "temporal_general = {'stages': [[l] for l in np.unique(times)[::-1]]}\n",
    "temporal_temporalBrain = {'stages': [\n",
    "    ['EaFet1'],\n",
    "    ['EaFet2'],\n",
    "    ['LaFet1'],\n",
    "    ['LaFet2'],\n",
    "    ['Inf1'],\n",
    "    ['Inf2'],\n",
    "    ['Child1'],\n",
    "    ['Child2'],\n",
    "    ['Adol1'],\n",
    "    ['Adol2'],\n",
    "    ['Adult1'],\n",
    "    ['Adult2'],\n",
    "]}\n",
    "temporal += [temporal_general]\n",
    "temporal += [temporal_temporalBrain]\n",
    "# Choose stage order\n",
    "temporal = temporal[args.temporal_key]\n",
    "\n",
    "# Perturbation feature names\n",
    "perturbation_feature_names = [[fnames[pf] for pf in pfs] for pfs, fnames in zip(perturbation_features, features)]\n",
    "\n",
    "# Initialize memories\n",
    "memories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:27:25.157740Z",
     "iopub.status.busy": "2025-01-15T18:27:25.157597Z",
     "iopub.status.idle": "2025-01-15T18:27:48.169953Z",
     "shell.execute_reply": "2025-01-15T18:27:48.169487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTimestep 1040, Stage 2/3: : 1040it [00:08, 124.57it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Running simulation')\n",
    "\n",
    "# Profiling\n",
    "profile = False\n",
    "if profile: torch.cuda.memory._record_memory_history(max_entries=100000)\n",
    "\n",
    "# Choose state manager\n",
    "state_manager = state_manager_class(\n",
    "    device=DEVICE,\n",
    "    discovery=discovery,\n",
    "    temporal=temporal,\n",
    "    perturbation_features=perturbation_features,\n",
    "    modal_targets=env.reward_distance_target,\n",
    "    num_nodes=modalities[0].shape[0],\n",
    "    dim=env.dim,\n",
    "    # vel_threshold=1e-1,  # Temporal testing\n",
    ")\n",
    "\n",
    "# Utility parameters\n",
    "get_current_stage = lambda: (\n",
    "    state_manager.current_stage\n",
    "    if np.array([isinstance(state_manager, cl) for cl in (celltrip.utilities.TemporalStateManager, celltrip.utilities.PerturbationStateManager)]).any()\n",
    "    else -1\n",
    ")\n",
    "get_max_stage = lambda: (\n",
    "    len(temporal['stages']) if isinstance(state_manager, celltrip.utilities.TemporalStateManager)\n",
    "    else sum([len(pf) for pf in perturbation_features])+1 if isinstance(state_manager, celltrip.utilities.PerturbationStateManager)\n",
    "    else -1\n",
    ")\n",
    "# TODO: Make perturbation more memory-efficient\n",
    "use_modalities = np.array([isinstance(state_manager, cl) for cl in (celltrip.utilities.PerturbationStateManager,)]).any()\n",
    "\n",
    "# Initialize\n",
    "env.set_modalities(modalities); env.reset(); memories[args.analysis_key] = defaultdict(lambda: [])\n",
    "\n",
    "# Modify\n",
    "state_vars, end = state_manager(\n",
    "    # present=present,\n",
    "    state=env.get_state(),\n",
    "    modalities=ppc.cast(ppc.inverse_transform(ppc.inverse_cast(modalities)), device='cpu') if use_modalities else modalities,\n",
    "    labels=labels,\n",
    "    times=times,\n",
    ")\n",
    "present = state_vars['present']\n",
    "memory_mask = present if optimize_memory else torch.ones_like(present, device=DEVICE)\n",
    "full_state = state_vars['state']\n",
    "env.set_state(full_state[memory_mask])\n",
    "raw_modalities = state_vars['modalities']\n",
    "processed_modalities = [m[memory_mask.cpu()] for m in raw_modalities]\n",
    "if use_modalities: processed_modalities = ppc.cast(ppc.transform(ppc.inverse_cast(processed_modalities)))\n",
    "env.set_modalities(processed_modalities)\n",
    "\n",
    "# Continue initializing\n",
    "memories[args.analysis_key]['present'].append(present.cpu())\n",
    "memories[args.analysis_key]['states'].append(full_state.cpu())\n",
    "memories[args.analysis_key]['stages'].append(get_current_stage())\n",
    "memories[args.analysis_key]['rewards'].append(torch.zeros(modalities[0].shape[0]))\n",
    "\n",
    "# Simulate\n",
    "get_desc = lambda ts, st: f'\\tTimestep {ts}' + (f', Stage {st}/{get_max_stage()}' if st != -1 else '')\n",
    "timestep = 0; pbar = tqdm(ascii=True, desc=get_desc(timestep, get_current_stage()), ncols=100)  # CLI\n",
    "while True:\n",
    "    # Step\n",
    "    state = env.get_state(include_modalities=True)\n",
    "    actions = torch.zeros((modalities[0].shape[0], env.dim), device=DEVICE)\n",
    "    actions[present] = policy.act_macro(\n",
    "        state if optimize_memory else state[present],\n",
    "        keys=torch.arange(modalities[0].shape[0], device=DEVICE)[present],\n",
    "        max_batch=config['train']['max_batch'],\n",
    "    )\n",
    "    rewards = torch.zeros(modalities[0].shape[0], device=DEVICE)\n",
    "    new_rewards, _, _ = env.step(actions[present] if optimize_memory else actions, return_itemized_rewards=True)\n",
    "    if optimize_memory: rewards[present] = new_rewards\n",
    "    else: rewards = new_rewards\n",
    "    full_state[present] = env.get_state() if optimize_memory else env.get_state()[present]\n",
    "    if not optimize_memory: env.set_state(full_state)  # Don't move un-spawned nodes\n",
    "\n",
    "    # Modify\n",
    "    state_vars, end = state_manager(\n",
    "        present=present,\n",
    "        state=full_state,\n",
    "        modalities=raw_modalities,\n",
    "        labels=labels,\n",
    "        times=times,\n",
    "    )\n",
    "    present_change = (state_vars['present'] != present).any()\n",
    "    present = state_vars['present']\n",
    "    memory_mask = present if optimize_memory else torch.ones_like(present, device=DEVICE)\n",
    "    full_state = state_vars['state']\n",
    "    env.set_state(full_state[memory_mask])\n",
    "    # Only modify if changes\n",
    "    if (\n",
    "        torch.tensor([(rm != svm).any() for rm, svm in zip(raw_modalities, state_vars['modalities'])]).any()\n",
    "        or (optimize_memory and present_change)\n",
    "    ):\n",
    "        raw_modalities = state_vars['modalities']\n",
    "        processed_modalities = [m[memory_mask.cpu()] for m in raw_modalities]\n",
    "        if use_modalities: processed_modalities = ppc.cast(ppc.transform(ppc.inverse_cast(processed_modalities)))\n",
    "        env.set_modalities(processed_modalities)\n",
    "\n",
    "    # Record\n",
    "    memories[args.analysis_key]['present'].append(present.cpu())\n",
    "    memories[args.analysis_key]['states'].append(full_state.cpu())\n",
    "    memories[args.analysis_key]['stages'].append(get_current_stage())\n",
    "    memories[args.analysis_key]['rewards'].append(rewards.cpu())\n",
    "\n",
    "    # CLI\n",
    "    timestep += 1\n",
    "    update_timestep = 10\n",
    "    if timestep % update_timestep == 0:\n",
    "        pbar.set_description(get_desc(timestep, get_current_stage()))\n",
    "        pbar.update(update_timestep)\n",
    "\n",
    "    # End\n",
    "    if end: break\n",
    "\n",
    "# CLI\n",
    "pbar.close()\n",
    "\n",
    "# Stack\n",
    "memories[args.analysis_key]['present'] = torch.stack(memories[args.analysis_key]['present'])\n",
    "memories[args.analysis_key]['states'] = torch.stack(memories[args.analysis_key]['states'])\n",
    "memories[args.analysis_key]['stages'] = torch.tensor(memories[args.analysis_key]['stages'])\n",
    "memories[args.analysis_key]['rewards'] = torch.stack(memories[args.analysis_key]['rewards'])\n",
    "memories[args.analysis_key] = dict(memories[args.analysis_key])\n",
    "\n",
    "# Profiling\n",
    "if profile:\n",
    "    torch.cuda.memory._dump_snapshot('cuda_profile.pkl')\n",
    "    torch.cuda.memory._record_memory_history(enabled=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLI Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tStatistics\n",
      "\t\tSteps per Stage\n",
      "\t\t\t0: 300\n",
      "\t\t\t1: 362\n",
      "\t\t\t2: 388\n",
      "\t\tMemory Sizes\n",
      "\t\t\tpresent size: 0.000 Gb\n",
      "\t\t\tstates size: 0.007 Gb\n",
      "\t\t\tstages size: 0.000 Gb\n",
      "\t\t\trewards size: 0.001 Gb\n",
      "\t\tAverage Reward: 0.059\n"
     ]
    }
   ],
   "source": [
    "print('\\tStatistics')\n",
    "\n",
    "# Debug CLI\n",
    "## Stages\n",
    "stages, counts = np.unique(memories[args.analysis_key]['stages'], return_counts=True)\n",
    "print('\\t\\tSteps per Stage')\n",
    "for s, c in zip(stages, counts):\n",
    "    print(f'\\t\\t\\t{s}: {c}')\n",
    "    \n",
    "## Memory\n",
    "print('\\t\\tMemory Sizes')\n",
    "for k in memories[args.analysis_key]:\n",
    "    t_size = sum([t.element_size() * t.nelement() if isinstance(t, torch.Tensor) else 64/8 for t in memories[args.analysis_key][k]]) / 1024**3\n",
    "    print(f'\\t\\t\\t{k} size: {t_size:.3f} Gb')\n",
    "\n",
    "## Performance\n",
    "print(f'\\t\\tAverage Reward: {memories[args.analysis_key][\"rewards\"].cpu().mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSaving/loading memories...\n"
     ]
    }
   ],
   "source": [
    "print('\\tSaving/loading memories...')\n",
    "\n",
    "# Save memories - MMD-MA Integration 1k Benchmark\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# No compression (8,506 KB)\n",
    "# with open('memories.pkl', 'wb') as f: pickle.dump(memories, f)\n",
    "# with open('memories.pkl', 'rb') as f: memories = pickle.load(f)\n",
    "\n",
    "# Half-accuracy gzip (3,236 KB)\n",
    "compressed_type = torch.float16\n",
    "with gzip.open('memories.pkl.gzip', 'wb') as f:\n",
    "    func_attr = lambda attr: attr.type(compressed_type) if attr.dtype not in (torch.long, torch.bool) else attr\n",
    "    func_mem = lambda mem: celltrip.utilities.dict_map(mem, func_attr, inplace=True)\n",
    "    pickle.dump(celltrip.utilities.dict_map(memories, func_mem, inplace=True), f)\n",
    "with gzip.open('memories.pkl.gzip', 'rb') as f: memories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting static analyses\n"
     ]
    }
   ],
   "source": [
    "print('Plotting static analyses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining rewards\n"
     ]
    }
   ],
   "source": [
    "print('\\tTraining rewards')\n",
    "\n",
    "# Load history from wandb\n",
    "history = run.history(samples=2000)\n",
    "history['timestep'] = history['end_timestep']\n",
    "history['Runtime (h)'] = history['_runtime'] / 60**2\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 6), layout='constrained')\n",
    "def plot_without_zeros(x, y, **kwargs):\n",
    "    x, y = x[np.argwhere(y != 0).flatten()], y[np.argwhere(y != 0).flatten()]\n",
    "    ax.plot(x, y, **kwargs)\n",
    "ax.plot(history['timestep'], history['average_reward'], color='black', lw=3, label='Average Reward')\n",
    "plot_without_zeros(history['timestep'], history['rewards/bound'], color='red', alpha=.75, lw=2, label='Boundary Penalty')\n",
    "plot_without_zeros(history['timestep'], history['rewards/velocity'], color='goldenrod', alpha=.75, lw=2, label='Velocity Penalty')\n",
    "plot_without_zeros(history['timestep'], history['rewards/action'], color='green', alpha=.75, lw=2, label='Action Penalty')\n",
    "plot_without_zeros(history['timestep'], history['rewards/distance'], color='blue', alpha=.75, lw=2, label='Distance Reward')\n",
    "plot_without_zeros(history['timestep'], history['rewards/origin'], color='darkorange', alpha=.75, lw=2, label='Origin Reward')\n",
    "\n",
    "# Stage ticks\n",
    "unique, stage_idx = np.unique(history['stage'][::-1], return_index=True)\n",
    "stage_idx = len(history['stage']) - stage_idx\n",
    "stage_idx = stage_idx[:-1]\n",
    "[ax.axvline(x=history['timestep'][idx], color='black', alpha=.5, linestyle='dashed', lw=1) for idx in stage_idx]\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('Timestep')\n",
    "ax.set_ylabel('Reward')\n",
    "ax.legend(loc='lower right', ncols=3)\n",
    "\n",
    "# Styling\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.set_xlim([0, history['timestep'].max()])\n",
    "\n",
    "# Save plot\n",
    "fname = f'{args.run_id}_{config[\"data\"][\"dataset\"]}_performance.pdf'\n",
    "fig.savefig(os.path.join(PLOT_FOLDER, fname), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method comparison\n",
    "if 'convergence' in memories:\n",
    "    print('\\tIntegration comparison')\n",
    "    \n",
    "    # Comparison metrics\n",
    "    metric_rand = lambda X: np.random.rand()\n",
    "    metric_silhouette = lambda X: sklearn.metrics.silhouette_score(X, labels)\n",
    "    metric_ch_score = lambda X: sklearn.metrics.calinski_harabasz_score(X, labels)\n",
    "    def metric_knn_ami(X):\n",
    "        knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "        knn.fit(X, labels)\n",
    "        pred = knn.predict(X)\n",
    "        return sklearn.metrics.adjusted_mutual_info_score(labels, pred)\n",
    "\n",
    "    metric_tuples = {\n",
    "        'rand': (metric_rand, {'label': 'Random'}),\n",
    "        'sc': (metric_silhouette, {'label': 'Silhouette Coefficient'}),\n",
    "        'knn_ami': (metric_knn_ami, {'label': 'KNN Adjusted Mutual Information'}),\n",
    "        'ch': (metric_ch_score, {'label': 'Calinski Harabasz Index', 'scale': 'log'}),\n",
    "    }\n",
    "\n",
    "    # Select metrics\n",
    "    metric_x, kwargs_x = metric_tuples['ch']\n",
    "    metric_y, kwargs_y = metric_tuples['knn_ami']\n",
    "\n",
    "    # Get other methods\n",
    "    method_results = {}\n",
    "    try:\n",
    "        method_dir = os.path.join(BASE_FOLDER, '../other_methods/runs', config['data']['dataset'])\n",
    "        method_names = next(os.walk(method_dir))[1]\n",
    "    except: method_names = []\n",
    "    for name in method_names:\n",
    "        # Get output files\n",
    "        files = os.listdir(os.path.join(method_dir, name))\n",
    "        r = re.compile('^P\\d+.txt$')\n",
    "        files = list(filter(r.match, files))\n",
    "\n",
    "        # Record\n",
    "        for i, file in enumerate(files):\n",
    "            proj = np.loadtxt(os.path.join(method_dir, name, file))\n",
    "            method_results[(name, i)] = proj\n",
    "\n",
    "    # Add cellTRIP\n",
    "    method_results[('cellTRIP', -1)] = memories['convergence']['states'][-1].detach().cpu()\n",
    "\n",
    "    # Compile and calculate performances\n",
    "    performance = pd.DataFrame(columns=['Method', 'Modality', 'x', 'y'])\n",
    "    for key, data in method_results.items():\n",
    "        performance.loc[performance.shape[0]] = [key[0], key[1], metric_x(data), metric_y(data)]\n",
    "\n",
    "    # Plot with text\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6), sharex=True, layout='constrained')\n",
    "    method_colors = {}\n",
    "    annotations = []\n",
    "    for i, r in performance.iterrows():\n",
    "        # Set color\n",
    "        if r['Method'] not in method_colors: method_colors[r['Method']] = sns.color_palette()[len(method_colors)]\n",
    "        \n",
    "        # Plot\n",
    "        ax.scatter(\n",
    "            r['x'],\n",
    "            r['y'],\n",
    "            color=method_colors[r['Method']],\n",
    "            s=100,\n",
    "        )\n",
    "\n",
    "        # Cross lines\n",
    "        ax.axvline(x=r['x'], ls='--', alpha=.1, color='black', zorder=.3)\n",
    "        ax.axhline(y=r['y'], ls='--', alpha=.1, color='black', zorder=.3)\n",
    "\n",
    "        # Annotate\n",
    "        text = f'{r[\"Method\"]}' + (f' ({r[\"Modality\"]})' if r['Modality'] != -1 else '')\n",
    "        annotations.append(ax.text(\n",
    "            r['x'], r['y'], text,\n",
    "            ha='center', va='center', fontsize='large'))\n",
    "\n",
    "    # Styling\n",
    "    ax.spines[['right', 'top', 'bottom', 'left']].set_visible(False)\n",
    "    ax.set(\n",
    "        **{'x'+k: v for k, v in kwargs_x.items()},\n",
    "        **{'y'+k: v for k, v in kwargs_y.items()},\n",
    "    )\n",
    "    ax.axvline(x=0, ls='-', alpha=.6, color='black', zorder=.1)\n",
    "    ax.axhline(y=0, ls='-', alpha=.6, color='black', zorder=.1)\n",
    "\n",
    "    # Adjust Annotation Positions\n",
    "    from adjustText import adjust_text\n",
    "    adjust_text(\n",
    "        annotations,\n",
    "        expand=(1.2, 2),\n",
    "        arrowprops=dict(arrowstyle='->', color='black', zorder=.3),\n",
    "    )\n",
    "\n",
    "    # Save plot\n",
    "    fname =                                     f'{args.run_id}'\n",
    "    if args.stage is not None: fname +=         f'_{args.stage:02}'\n",
    "    fname +=                                    f'_{config[\"data\"][\"dataset\"]}'\n",
    "    fname +=                                    f'_comparison.pdf'\n",
    "    fig.savefig(os.path.join(PLOT_FOLDER, fname), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation significance analysis\n",
    "if 'perturbation' in memories:\n",
    "    print('\\tFeature effect size')\n",
    "    \n",
    "    # Get last idx for each stage\n",
    "    stages = memories['perturbation']['stages'].cpu().numpy()\n",
    "    unique_stages, unique_idx = np.unique(stages[::-1], return_index=True)\n",
    "    unique_idx = stages.shape[0] - unique_idx - 1\n",
    "    # unique_stages, unique_idx = unique_stages[::-1], unique_idx[::-1]\n",
    "\n",
    "    # Record perturbation feature pairs\n",
    "    perturbation_feature_triples = [(i, f, n) for i, (fs, ns) in enumerate(zip(perturbation_features, perturbation_feature_names)) for f, n in zip(fs, ns)]\n",
    "\n",
    "    # Compute effect sizes for each\n",
    "    effect_sizes = []\n",
    "    for stage, idx in zip(unique_stages, unique_idx):\n",
    "        # Get state\n",
    "        state = memories['perturbation']['states'][idx]\n",
    "\n",
    "        # Record steady state after convergence\n",
    "        if stage == 0:\n",
    "            steady_state = state\n",
    "            continue\n",
    "\n",
    "        # Get perturbed feature\n",
    "        m_idx, pf, pf_name = perturbation_feature_triples[stage-1]\n",
    "\n",
    "        # Compute effect size\n",
    "        effect_size = (state[:, :env.dim] - steady_state[:, :env.dim]).square().sum(dim=-1).sqrt().mean(dim=-1).item()\n",
    "        effect_sizes.append(effect_size)\n",
    "\n",
    "    # Print effect sizes\n",
    "    i = 0\n",
    "    for j, (pfs, pfns) in enumerate(zip(perturbation_features, perturbation_feature_names)):\n",
    "        print(f'\\t\\tModality {j}')\n",
    "        for pf, pfn in zip(pfs, pfns):\n",
    "            print(f'\\t\\t\\t{pfn:<15}{effect_sizes[i]:.02e}')\n",
    "            i += 1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:27:48.249939Z",
     "iopub.status.busy": "2025-01-15T18:27:48.249780Z",
     "iopub.status.idle": "2025-01-15T18:28:39.620056Z",
     "shell.execute_reply": "2025-01-15T18:28:39.619296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video plot\n",
      "\tReducing state dimensionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tProjecting (0/2):   0%|                                                | 0/315000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tProjecting (2/2): 100%|##############################| 315000/315000 [00:00<00:00, 2006201.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerating video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tRendering: 100%|##################################################| 54/54 [00:58<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Video plot')\n",
    "\n",
    "# Prepare data\n",
    "present = memories[args.analysis_key]['present'].cpu()\n",
    "states = memories[args.analysis_key]['states'].cpu()\n",
    "stages = memories[args.analysis_key]['stages'].cpu()\n",
    "rewards = memories[args.analysis_key]['rewards'].cpu()\n",
    "base_env = celltrip.environments.trajectory(*[torch.empty((0, 0)) for _ in range(len(modalities))], **config['env'])\n",
    "\n",
    "# Testing for portions of large datasets\n",
    "# sub_idx = np.random.choice(modalities[0].shape[0], 1_000, replace=False)\n",
    "# modalities, labels, times = [m[sub_idx] for m in modalities], labels[sub_idx], times[sub_idx]\n",
    "# present, states, rewards = present[:, sub_idx], states[:, sub_idx], rewards[:, sub_idx]\n",
    "\n",
    "# Testing for larger dims\n",
    "# states = torch.concatenate((states, states), dim=-1)\n",
    "# base_env.dim *= 2\n",
    "\n",
    "# Reduce dimensions\n",
    "if states.shape[-1] > 2*3 or args.force_reduction:\n",
    "    print('\\tReducing state dimensionality')\n",
    "    # Get idx of last state in designated stage\n",
    "    stage_unique, stage_idx = np.unique(stages.numpy()[::-1], return_index=True)\n",
    "    stage_idx = memories[args.analysis_key]['stages'].shape[0] - stage_idx - 1\n",
    "\n",
    "    # Choose reduction type\n",
    "    if args.reduction_type == 'umap':\n",
    "        import umap\n",
    "        fit_reducer = lambda data: umap.UMAP(n_components=3, random_state=args.seed).fit(data)\n",
    "        transform_reducer = lambda reducer, data: torch.Tensor(reducer.transform(data))\n",
    "    elif args.reduction_type == 'pca':\n",
    "        import sklearn.decomposition\n",
    "        fit_reducer = lambda data: sklearn.decomposition.PCA(n_components=3, random_state=args.seed).fit(data)\n",
    "        transform_reducer = lambda reducer, data: torch.Tensor(reducer.transform(data))\n",
    "    elif args.reduction_type is None or args.reduction_type == 'none':\n",
    "        initialize_reducer = lambda: None\n",
    "        transform_reducer = lambda reducer, data: data\n",
    "\n",
    "    # Get steady state\n",
    "    if args.analysis_key in ('convergence', 'discovery', 'perturbation',):\n",
    "        reducer = fit_reducer(states[stage_idx[0]])\n",
    "        get_reducer = lambda stage: reducer\n",
    "    elif args.analysis_key in ('temporal',):\n",
    "        get_reducer = lambda stage: fit_reducer(states[stage_idx[stage]])\n",
    "\n",
    "    # UMAP\n",
    "    states_3d = []; pbar = tqdm(total=states.shape[0]*states.shape[1], ascii=True, ncols=100)\n",
    "    for stage in stage_unique:\n",
    "        pbar.set_description(f'\\t\\tProjecting ({stage}/{stage_unique.max()})')\n",
    "        stage_states = states[stages==stage].reshape((-1, states.shape[-1]))\n",
    "        for i in range(0, stage_states.shape[0], args.reduction_batch):\n",
    "            states_3d.append(transform_reducer(get_reducer(stage), stage_states[i:i+args.reduction_batch]))\n",
    "            pbar.update(stage_states[i:i+args.reduction_batch].shape[0])\n",
    "    pbar.close()\n",
    "    states_3d = torch.concatenate(states_3d, dim=0).reshape((*states.shape[:-1], 3))\n",
    "    states_3d = torch.concatenate((states_3d, torch.zeros_like(states_3d)), dim=-1)\n",
    "else: states_3d = None\n",
    "\n",
    "# Skip data\n",
    "present, states, stages, rewards = present[::args.skip], states[::args.skip], stages[::args.skip], rewards[::args.skip]\n",
    "if states_3d is not None: states_3d = states_3d[::args.skip]\n",
    "\n",
    "# CLI\n",
    "print('\\tGenerating video')\n",
    "\n",
    "# Parameters\n",
    "interval = 1e3*env.delta/3  # Time between frames (3x speedup)\n",
    "min_max_vel = 1e-2 if args.analysis_key in ('convergence', 'discovery') else -1  # Stop at first frame all vels are below target. 0 for full play\n",
    "frame_override = None  # Manually enter number of frames to draw\n",
    "rotations_per_second = .1  # Camera azimuthal rotations per second\n",
    "num_lines = 100\n",
    "if args.analysis_key == 'temporal': num_lines *= len(temporal['stages'])**2\n",
    "\n",
    "# Create plot based on key\n",
    "# NOTE: Standard 1-padding all around and between figures\n",
    "# NOTE: Left, bottom, width, height\n",
    "if args.analysis_key in ('convergence', 'discovery'):\n",
    "    figsize = (15, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        celltrip.utilities.View3D,\n",
    "        celltrip.utilities.ViewTemporalScatter,\n",
    "        celltrip.utilities.ViewSilhouette,\n",
    "    ]\n",
    "\n",
    "elif args.analysis_key == 'temporal':\n",
    "    figsize = (15, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 4 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        celltrip.utilities.View3D,\n",
    "        celltrip.utilities.ViewTemporalScatter,\n",
    "        celltrip.utilities.ViewTemporalDiscrepancy,\n",
    "    ]\n",
    "\n",
    "elif args.analysis_key in ('perturbation',):\n",
    "    figsize = (20, 10)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axs = [\n",
    "        fig.add_axes([1 /figsize[0], 1 /figsize[1], 8 /figsize[0], 8 /figsize[1]], projection='3d'),\n",
    "        fig.add_axes([10 /figsize[0], 5.5 /figsize[1], 8 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([10 /figsize[0], 1 /figsize[1], 3.5 /figsize[0], 3.5 /figsize[1]]),\n",
    "        fig.add_axes([14.5 /figsize[0], 1 /figsize[1], 3.5 /figsize[0], 3.5 /figsize[1]]),\n",
    "    ]\n",
    "    views = [\n",
    "        celltrip.utilities.View3D,\n",
    "        celltrip.utilities.ViewPerturbationEffect,\n",
    "        celltrip.utilities.ViewTemporalScatter,\n",
    "        celltrip.utilities.ViewSilhouette,\n",
    "    ]\n",
    "\n",
    "# Initialize views\n",
    "arguments = {\n",
    "    # Data\n",
    "    'present': present,\n",
    "    'states': states,\n",
    "    'states_3d': states_3d,\n",
    "    'stages': stages,\n",
    "    'rewards': rewards,\n",
    "    'modalities': modalities,\n",
    "    'labels': labels,\n",
    "    # Data params\n",
    "    'dim': base_env.dim,\n",
    "    'modal_targets': base_env.reward_distance_target,\n",
    "    'temporal_stages': temporal['stages'],\n",
    "    'perturbation_features': perturbation_features,\n",
    "    'perturbation_feature_names': perturbation_feature_names,\n",
    "    'partitions': times if args.analysis_key in ('temporal',) else None,\n",
    "    # Arguments\n",
    "    'interval': interval,\n",
    "    'skip': args.skip,\n",
    "    'seed': 42,\n",
    "    # Styling\n",
    "    'num_lines': num_lines,\n",
    "    'ms': 5,  # 3\n",
    "    'lw': 1,\n",
    "}\n",
    "views = [view(**arguments, ax=ax) for view, ax in zip(views, axs)]\n",
    "\n",
    "# Compile animation\n",
    "frames = states[..., env.dim:env.dim+3].square().sum(dim=-1).sqrt().max(dim=-1).values < min_max_vel\n",
    "frames = np.array([(frames[i] or frames[i+1]) if i != len(frames)-1 else frames[i] for i in range(len(frames))])  # Disregard interrupted sections of low movement\n",
    "frames = np.argwhere(frames)\n",
    "frames = frames[0, 0].item()+1 if len(frames) > 0 else states.shape[0]\n",
    "frames = frames if frame_override is None else frame_override\n",
    "\n",
    "# Update function\n",
    "pbar = tqdm(ascii=True, total=frames+1, desc='\\t\\tRendering', ncols=100)  # CLI, runs frame 0 twice\n",
    "def update(frame):\n",
    "    # Update views\n",
    "    for view in views:\n",
    "        view.update(frame)\n",
    "\n",
    "    # CLI\n",
    "    update_timestep = 1\n",
    "    if frame % update_timestep == 0:\n",
    "        pbar.update(update_timestep)\n",
    "\n",
    "# Test individual frames\n",
    "# for frame in range(frames):\n",
    "#     update(frame)\n",
    "#     # print()\n",
    "#     # print('saving')\n",
    "#     fig.savefig(os.path.join('temp/plots', f'frame_{frame}.png'), dpi=300)\n",
    "#     break\n",
    "\n",
    "# Initialize animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig,\n",
    "    func=update,\n",
    "    frames=frames,\n",
    "    interval=interval,\n",
    ")\n",
    "\n",
    "# Display animation as it renders\n",
    "# plt.show()\n",
    "\n",
    "# Display complete animation\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# Save animation\n",
    "# NOTE: Requires `sudo apt-get install ffmpeg`\n",
    "file_type = 'mp4' if not args.gif else 'gif'\n",
    "if file_type == 'mp4': writer = animation.FFMpegWriter(fps=int(1e3/interval), extra_args=['-vcodec', 'libx264'], bitrate=8e3)  # Faster\n",
    "elif file_type == 'gif': writer = animation.FFMpegWriter(fps=int(1e3/interval))  # Slower\n",
    "fname =                                     f'{args.run_id}'\n",
    "if args.stage is not None: fname +=         f'_{args.stage:02}'\n",
    "fname +=                                    f'_{config[\"data\"][\"dataset\"]}'\n",
    "fname +=                                    f'_{args.analysis_key}'\n",
    "fname +=                                    f'.{file_type}'\n",
    "ani.save(os.path.join(PLOT_FOLDER, fname), writer=writer, dpi=300)\n",
    "\n",
    "# CLI\n",
    "pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
