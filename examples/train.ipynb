{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython is not active\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['RAY_DEDUP_LOGS'] = '0'\n",
    "import functools as ft\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import torch\n",
    "import tqdm.auto\n",
    "import tqdm.notebook\n",
    "tqdm.notebook.tqdm = tqdm.auto.tqdm  # Enable text output in notebooks\n",
    "\n",
    "import celltrip\n",
    "\n",
    "# Detect Cython\n",
    "CYTHON_ACTIVE = os.path.splitext(celltrip.utility.general.__file__)[1] in ('.c', '.so')\n",
    "print(f'Cython is{\" not\" if not CYTHON_ACTIVE else \"\"} active')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High priority\n",
    "  - Test Tahoe100M dataloader\n",
    "  - Add train/val to dataloader\n",
    "  - Arguments\n",
    "  - Partition detection in `train_policy`\n",
    "  - Implement stages\n",
    "  - Seed policy initialization, add reproducibility tag to wait for all rollouts before updating\n",
    "  - Add checkpoints\n",
    "  - Add model loading\n",
    "  - Add metric returns for updates\n",
    "  - Make ray init command for bash and add to README\n",
    "- Medium Priority\n",
    "  - Add state manager to env and then parallelize in analysis, maybe make `analyze` function\n",
    "  - Add parallelism on max_batch and update. With update, encase whole epoch as ray function so splitting occurs within ray function, using ray.remote inline API to allow for non-ray usage. Then, adjustable policy weight sync (i.e. 1 epoch, 10 epochs)\n",
    "- Low Priority\n",
    "  - Allow memory to pre-process keys and persistent storage\n",
    "  - Add hook for wandb, ex.\n",
    "  - Move preprocessing to manager\n",
    "  - Better split_state reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Train CellTRIP model', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "# # TODO: Figure out how to format arguments for appending h5ad files\n",
    "# parser.add_argument('datasets', type=str, required=False, help='.h5ad files to use for data')\n",
    "# parser.add_argument('--concatenate', type=str, required=False, help=\n",
    "#     '.h5ad files to concatenate as a single modality, may be used multiple times')\n",
    "\n",
    "# group = parser.add_argument_group('General')\n",
    "# group.add_argument('--seed', default=42, type=int, help='**Seed for random calls during training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/repos/inept/celltrip/utility/processing.py:97: RuntimeWarning: Modality 1 too small for PCA (2 features), skipping\n",
      "  warnings.warn(\n",
      "2025-03-05 17:59:23,736\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://192.168.0.119:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(wrapper pid=1695003)\u001b[0m Timestep 200 - Reward -0.667\n",
      "\u001b[36m(wrapper pid=1695003)\u001b[0m Timestep 400 - Reward 0.000\n",
      "\u001b[36m(wrapper pid=1695003)\u001b[0m Timestep 600 - Reward 0.000\n",
      "\u001b[36m(wrapper pid=1695003)\u001b[0m Timestep 800 - Reward -0.667\n",
      "\u001b[36m(wrapper pid=1695003)\u001b[0m Timestep 1000 - Reward -0.222\n",
      "\u001b[36m(wrapper pid=1695003)\u001b[0m {'Event Type': 'Rollout', 'Event Details': {'Episode timesteps': 1000, 'Episode reward': -0.31577903032302856, 'Episode itemized reward': {'distance': 0.0, 'origin': 0.0, 'bound': -0.31577903032302856, 'velocity': 0.0, 'action': 0.0}}, 'Policy Iteration': 0, 'Partition': ['L1']}\n",
      "Calibrated rollout memory (0.55 GiB) and VRAM (0.50 GiB)\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m Timestep 200 - Reward -0.325\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m Timestep 400 - Reward -0.082\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m Timestep 600 - Reward -0.150\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m Timestep 800 - Reward -0.304\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m Timestep 1000 - Reward -0.109\n",
      "\u001b[36m(wrapper pid=1695008)\u001b[0m {'Event Type': 'Rollout', 'Event Details': {'Episode timesteps': 1000, 'Episode reward': -0.14766156673431396, 'Episode itemized reward': {'distance': 0.0, 'origin': 0.0, 'bound': -0.14766156673431396, 'velocity': 0.0, 'action': 0.0}}, 'Policy Iteration': 0, 'Partition': ['L2/3']}\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0001 - Reward 0.000\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0001 - Reward 0.000\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0100 - Reward -0.040\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0100 - Reward -0.016\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0200 - Reward -0.369\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0200 - Reward -0.242\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0400 - Reward -0.096\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0400 - Reward -0.048\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0600 - Reward -0.293\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0600 - Reward -0.190\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 0800 - Reward -0.137\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 0800 - Reward -0.123\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m Timestep 1000 - Reward -0.084\n",
      "\u001b[36m(wrapper pid=1695006)\u001b[0m {'Event Type': 'Rollout', 'Event Details': {'Episode timesteps': 1000, 'Episode reward': -0.1830882728099823, 'Episode itemized reward': {'distance': 0.0, 'origin': 0.0, 'bound': -0.1830882728099823, 'velocity': 0.0, 'action': 0.0}}, 'Policy Iteration': 0, 'Partition': ['L6a']}\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m Timestep 1000 - Reward -0.091\n",
      "\u001b[36m(wrapper pid=1695007)\u001b[0m {'Event Type': 'Rollout', 'Event Details': {'Episode timesteps': 1000, 'Episode reward': -0.10294055938720703, 'Episode itemized reward': {'distance': 0.0, 'origin': 0.0, 'bound': -0.10294055938720703, 'velocity': 0.0, 'action': 0.0}}, 'Policy Iteration': 0, 'Partition': ['L5']}\n",
      "\u001b[36m(wrapper pid=1695010)\u001b[0m Epoch 01 - PPO 0.868, critic 1.664, entropy -0.027\n",
      "\u001b[36m(wrapper pid=1695010)\u001b[0m Epoch 05 - PPO 0.800, critic 1.328, entropy -0.027\n",
      "\u001b[36m(wrapper pid=1695010)\u001b[0m Epoch 10 - PPO 0.951, critic 1.433, entropy -0.027\n",
      "\u001b[36m(wrapper pid=1695010)\u001b[0m Epoch 20 - PPO 0.886, critic 1.259, entropy -0.027\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "fnames = ['../data/MERFISH/expression.h5ad', '../data/MERFISH/spatial.h5ad']\n",
    "partition_cols = None\n",
    "adatas = celltrip.utility.processing.read_adatas(*fnames, on_disk=False)\n",
    "celltrip.utility.processing.test_adatas(*adatas, partition_cols=partition_cols)\n",
    "\n",
    "# Construct dataloader\n",
    "dataloader = celltrip.utility.processing.PreprocessFromAnnData(\n",
    "    *adatas, partition_cols=partition_cols, num_nodes=200, pca_dim=128, seed=42)\n",
    "modalities, adata_obs, adata_vars = dataloader.sample()\n",
    "\n",
    "# Initialize Ray\n",
    "ray.shutdown()\n",
    "ray.init(\n",
    "    resources={'VRAM': torch.cuda.get_device_properties(0).total_memory},\n",
    "    dashboard_host='0.0.0.0')\n",
    "\n",
    "# Initialize distributed manager\n",
    "policy_init, memory_init = celltrip.train.get_train_initializers(\n",
    "    3, [m.shape[1] for m in modalities])\n",
    "distributed_manager = celltrip.train.DistributedManager(\n",
    "    # modalities=modalities, env_init=env_init,\n",
    "    policy_init=policy_init,\n",
    "    memory_init=memory_init)\n",
    "\n",
    "# Perform training\n",
    "celltrip.train.train_policy(distributed_manager, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cancel\n",
    "# # dm.cancel()\n",
    "# # dm.clean()\n",
    "# # dm.rollout(dummy=True)\n",
    "# # dm.wait()\n",
    "\n",
    "# # Clear locks\n",
    "# dm.policy_manager.release_locks.remote()\n",
    "\n",
    "# # Get policy\n",
    "# device = DEVICE\n",
    "# policy = policy_init().to(device)\n",
    "# celltrip.train.set_policy_state(policy, ray.get(dm.policy_manager.get_policy_state.remote()))\n",
    "\n",
    "# # Get memory\n",
    "# memory = memory_init(policy)\n",
    "# memory.append_memory(\n",
    "#     *ray.get(dm.policy_manager.get_memory_storage.remote()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.update(memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get state of job from ObjectRef\n",
    "# import ray.util.state\n",
    "# object_id = dm.futures['simulation'][0].hex()\n",
    "# object_state = ray.util.state.get_objects(object_id)[0]\n",
    "# object_state.task_status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celltrip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
